---
layout: post
related_posts:
  _
title: 
description: >
sitemap:
    changefreq: daily
    priority: 1.0
hide_last_modified: true
---

# Semi-Supervised Mean Estimation (Variance Reduction Technique)

- 일반적으로 $$\left\{X_i\right\}_{i=1}^n $$으로 $$\mathbb{E}[X]$$를 estimate할 때 sample mean $$\hat \theta = \bar{X}=\frac{1}{n} \sum_{i=1}^n X_i$$을 사용한다.
- 하지만 실제로는 소량의 labeled data $$\left\{X_i\right\}_{i=1}^n $$와 대량의 unlabeled data $$\left\{Y_i\right\}_{i=1}^N $$, $$n<<N$$이 존재한다.
- Motivation : 대량의 unlabeled data를 사용하여 $$\bar{X}=\frac{1}{n} \sum_{i=1}^n X_i$$보다 좋은 (분산이 작은) unbiased estimator를 찾자.
- **Consider an estimator** $$\widehat{\theta}=\frac{1}{n} \sum_{i=1}^n\left\{X_i-f\left(Y_i\right)\right\}+\frac{1}{N} \sum_{i=1}^N f\left(Y_i\right)$$​
  - $$f(Y)$$는  $$Y$$​로 만들 수 있는 estimator라고 생각하면 된다.
  - 지금은 $$f(Y)$$가 없는 부분이 unbiased이므로 $$f(Y)$$도 unbiased estimator이어야 한다.
  - 참고로 $$f(Y)=\mathbb E[X \mid Y]$$인 경우가 strong assumption이긴 하지만 optimal choice이다.

- Unbiased ? (proof)

: $$\begin{aligned} \mathbb{E}[\hat{\theta}] & =\mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n\left(X_i-f\left(Y_i\right)\right)\right]+\mathbb{E}\left[\frac{1}{N} \sum_{i=1}^N f\left(Y_i\right)\right] \\ & =\frac{1}{n} \sum_{i=1}^n \mathbb{E}\left[X_i-f\left(Y_i\right)\right]+\frac{1}{N} \sum_{i=1}^N \mathbb{E}\left[f\left(Y_i\right)\right] \\ & =\mathbb{E}[X]-\mathbb{E}[f(Y)]+\mathbb{E}[f(Y)] \quad\left(\text { when } Y_i^{\prime} \text { s are iid) }\right. \\ & =\mathbb{E}[X]\end{aligned}$$

- Improves the variance ? (proof)

: $$\begin{aligned} \hat{\theta} & =\frac{1}{n} \sum_{i=1}^n\left(X_i-f\left(Y_i\right)\right)+\frac{1}{N} \sum_{i=1}^N f\left(Y_i\right) \\ & =\frac{1}{n} \sum_{i=1}^n X_i-\left(\frac{1}{n}-\frac{1}{N}\right) \sum_{=1}^n f\left(Y_i\right)+\frac{1}{N} \sum_{i=n+1}^N f\left(Y_i\right) \\ \operatorname{Var}(\hat{\theta}) & =\operatorname{Var}\left(\frac{1}{n} \sum_{i=1}^n X_i\right)+\operatorname{Var}\left(-\left(\frac{1}{n}-\frac{1}{N}\right) \sum_{i=1}^n f\left(Y_i\right)\right) \\ & \quad -2 \operatorname{Cov}\left(\frac{1}{n} \sum_{i=1}^n X_i,\left(\frac{1}{n}-\frac{1}{N}\right) \sum_{i=1}^n f\left(Y_i\right)\right)+\operatorname{Var}\left(\frac{1}{N} \sum_{i=1}^N f\left(Y_i\right)\right) \\ & =\frac{1}{n} \operatorname{Var}(X)+\left(\frac{1}{n}-\frac{1}{N}\right)^2 \cdot n \operatorname{Var}(f(Y)) \\ & \quad -2 \frac{1}{n}\left(\frac{1}{n}-\frac{1}{N}\right) n \operatorname{Cov}(X, f(Y))+\frac{N-n}{N^2} \operatorname{Var}(f(Y)) \\ & =\frac{1}{n} \operatorname{Var}(X)+\left(\frac{1}{n}-\frac{2}{N}+\frac{n}{N^2}-\frac{N-n}{N^2}\right) \operatorname{Var}(f(Y))-2\left(\frac{1}{n}-\frac{1}{N}\right) \operatorname{Cov}\left(X, f(Y)\right) \\ & =\frac{1}{n} \operatorname{Var}(X)+\left(\frac{1}{n}-\frac{2}{N}+\frac{1}{N}\right) \operatorname{Var}(f(Y))-2\left(\frac{1}{n}-\frac{1}{N}\right) \operatorname{Cov}\left(X, f(Y)\right) \\ & =\frac{1}{n}\left[\operatorname{Var}(X)+\frac{N-n}{N}(\operatorname{Var}(f(Y))-2 \operatorname{Cov}(X, f(Y)))\right]\end{aligned}$$

- 이 때 $$\operatorname{Var}[\bar{X}]=\operatorname{Var}[X] / n$$ 이므로 $$\frac{1}{n}\left[\operatorname{Var}[X]+\frac{N-n}{N}\{\operatorname{Var}[f(Y)]-2 \operatorname{Cov}[X, f(Y)]\}\right]<\frac{\operatorname{Var}[X]}{n}$$이면,

  - 즉 $$\operatorname{Var}[f(Y)]<2 \operatorname{Cov}[X, f(Y)]$$이면 $$\hat \theta = \bar X$$보다 improve 된다.

- $$f(Y)=\mathbb{E}[X \mid Y]$$을 가정했으므로 $$\begin{aligned}\operatorname{Var}[\widehat{\theta}]=\frac{1}{n}\left[\operatorname{Var}(X)+\frac{N-n}{N}(\operatorname{Var}(f(Y))-2 \operatorname{Cov}(X, f(Y)))\right]\end{aligned}$$이고,
  - Covariance 부분만 보면
    - $$\begin{aligned}
      \operatorname{Cov}(X, \mathbb{E}[X \mid Y]) & =\mathbb{E}[(X-\mathbb{E}[X])(\mathbb{E}[X \mid Y]-\mathbb{E}[X])]\\&=\mathbb{E}\left[(\mathbb{E}[X \mid Y]-\mathbb{E}[X])^2\right] \\
      & =\operatorname{Var}[\mathbb{E}(X \mid Y)]
      \end{aligned}$$이므로 대입하면
- $$\begin{aligned}
  \operatorname{Var}[\widehat{\theta}] & =\frac{1}{n}\{\underbrace{\operatorname{Var}[X]}_{=\operatorname{Var}[\mathbb{E}(X \mid Y)]+\mathbb{E}[\operatorname{Var}(X \mid Y)]}+\frac{N-n}{N} \operatorname{Var}(\mathbb{E}[X \mid Y])-2 \frac{N-n}{N} \underbrace{\operatorname{Cov}(X, \mathbb{E}[X \mid Y])}_{=\operatorname{Var}[\mathbb{E}(X \mid Y)]}\} \\
  & =\frac{1}{n} \mathbb{E}[\operatorname{Var}(X \mid Y)]+\frac{1}{N} \operatorname{Var}[\mathbb{E}(X \mid Y)] \\
  & \leq \frac{1}{n} \mathbb{E}[\operatorname{Var}(X \mid Y)]+\frac{1}{n} \operatorname{Var}[\mathbb{E}(X \mid Y)]=\operatorname{Var}[\bar{X}],
  \end{aligned}$$이다.

- $$n << N$$이므로 $$\hat \theta=\bar X$$의 분산이 작아졌다.
- 이 방법의 본질은 $$X$$와 $$Y$$의 dependency이다.
  - 만약 $$X$$와 $$Y$$가 independent이면 $$Y$$가 $$\mathbb E[X]$$에 대한 정보를 가지고 있지 않으므로 improvement가 없다.
  - 즉 본질적으로 Antithetic variable for Variance reduction과 같다.
    - (sample의 개수가 같더라도 iid가 아닌 negatively correlated sampling을 함으로써 estimator의 분산을 줄이는 방법)