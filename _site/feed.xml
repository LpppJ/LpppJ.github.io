<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-03-06T19:08:28+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">LpppJ</title><subtitle>This is blog about machine learning, deep learning, artificial intelligence.
</subtitle><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><entry><title type="html">(SimMTM) A Simple Pre-Training Framework for Masked Time-Series Modeling</title><link href="http://localhost:4000/timeseries/2024-03-06-SimMTM/" rel="alternate" type="text/html" title="(SimMTM) A Simple Pre-Training Framework for Masked Time-Series Modeling" /><published>2024-03-06T00:00:00+09:00</published><updated>2024-03-06T17:14:53+09:00</updated><id>http://localhost:4000/timeseries/SimMTM</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-03-06-SimMTM/"><![CDATA[<h2 id="abstract">Abstract</h2>
<ul>
  <li>Labeling 비용 줄이고 다양한 task를 하기 위해 self-supervised pre-training 방식이 사용된다.
    <ul>
      <li>Contrastive learning : positive and negative pairs를 통해 representation space 최적화</li>
      <li>Masked modeling : unmasked part를 보고 masked content를 reconstruct</li>
    </ul>
  </li>
  <li>하지만 시계열에서는 randomly masking하면 temporal variations(trend, periodicity, peak valley …)가 망가져서 reconstruction task가 너무 어려워진다.</li>
  <li>그래서 본 논문에서 제시하는 SimMTM은 한 개가 아니라 여러 개의 masked series를 assembling해서 reconstruction한다.</li>
</ul>

<h2 id="1-intnroduction">1. Intnroduction</h2>
<ul>
  <li>Self-supervised pre-training(SSL) : 대량의 unlabeled 데이터로 pretext knowledge를 학습하고, 다양한 downstream task에 맞게 개선 (Linear probing / Fine tuning)</li>
  <li>pre-training 방법 중 하나인 Masked modeling을 시계열에 적용
    <ul>
      <li>Masked modeling : 데이터의 일부를 masking하고 unmasked part를 보고 masked part를 reconstruct하는 방식을 학습</li>
    </ul>
  </li>
  <li>이미지나 자연어는 불필요한 정보도 많이 있지만(이미지의 빈 공간, 수식어 등), 시계열에는 temporal variations(trend, periodicity, peak vally…)가 있어서 단순하게 일부를 masking하면 시계열의 본질적인 부분이 변형되거나 망가질 수 있다.</li>
  <li>그래서 multiple masking series로 original data를 reconstruction하면 개별 maksing series에서는 temporal variations가 변형될 수 있지만 각 maksing series는 서로서로 complement하기 때문에 multiple masking series를 봤을 때에는 본질적인 부분이 사라지지 않는다.
<img src="/assets/img/timeseries/SimMTM/fig1.jpeg" alt="사진1" /></li>
  <li>요약하자면 SimMTM은 neighborhood aggregation design for reconstruction이라고 할 수 있고,
    <ul>
      <li>풀어서 설명하자면 SimMTM은 masked part를 reconstruct하기 위해서 series-wise representation의 simailarity가 높은 point-wise representations을 aggregate한다고 할 수 있다.</li>
    </ul>

    <h2 id="2-related-work">2. Related Work</h2>
    <h3 id="21-self-supervised-pre-training">2.1. Self-supervised Pre-training</h3>
    <ul>
      <li>Self-supervised Pre-training(SSL)
        <ul>
          <li>Contrastive leaning : positive pairs는 가깝게, negative pairs는 멀게 representation하도록 학습</li>
          <li>Masked modeling
            <ul>
              <li>TST : learns to predict removed time points based on the remaining time points</li>
              <li>PatchTST : predict masked subseries-level patches to capture the local semantic information</li>
              <li>Ti-MAE : mask modeling as an auxiliary task to boost the forecasting and classification performances</li>
            </ul>
          </li>
          <li>하지만 directly masking time series 방식은 본질적인 temporal variations를 망가지게 할 수 있으니, multiple randomly masked series로 recunstruct한다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="3-simmtm">3. SimMTM</h2>
<ul>
  <li>모델은 크게 2개의 단계로 구성
    <ul>
      <li>multiple time series의 series-wise representation space에서의 similarities를 학습</li>
      <li>학습된 similarities를 바탕으로 point-wise representations를 aggregate</li>
    </ul>
  </li>
</ul>

<h3 id="31-overall-architecture">3.1. Overall Architecture</h3>
<ul>
  <li>모델은 4개의 modules로 구성
    <ul>
      <li>Masking</li>
      <li>Representation learning</li>
      <li>Series-wise similarity learning</li>
      <li>Point-wise aggregation
<img src="/assets/img/timeseries/SimMTM/fig2.png" alt="사진2" /></li>
    </ul>
  </li>
  <li><strong>Masking</strong>
    <ul>
      <li>\(\left\{\mathbf{x}_i\right\}_{i=1}^N\) : a mini-batch of \(N\) time series samples, <br />
where \(\mathbf{x}_i \in \mathbb{R}^{L \times C}\) contains \(L\) time points and \(C\) observed variates</li>
      <li>\(\left\{\overline{\mathbf{x}}_i^j\right\}_{j=1}^M=\operatorname{Mask}_{r}\left(\mathbf{x}_i\right)\) <br />
where \(r \in[0,1]\) denotes the masked portion,
\(M\) is a hyperparameter for the number of masked time series</li>
      <li>
        <p>\(\overline{\mathbf{x}}_i^j \in \mathbb{R}^{L \times C}\) : the \(j\)-th masked time series of \(\mathbf{x}_i\)</p>
      </li>
      <li>All the \((N(M+1))\) input series in a set as \(\mathcal{X}=\bigcup_{i=1}^N\left(\left\{\mathbf{x}_i\right\} \cup\left\{\overline{\mathbf{x}}_i^j\right\}_{j=1}^M\right)\).
        <ul>
          <li>\(N\)은 mini-batch에 있는 시계열 데이터 sample의 개수,</li>
          <li>\(M\)은 multiple masked time series의 개수</li>
          <li>\(1\)은 masking 하지 않은 원본 시계열을 의미한다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Representation learning</strong>
    <ul>
      <li>Encoder : Transformer and ResNet (to obtain the point-wise representations \(\mathcal{Z}\))
        <ul>
          <li>\(\mathcal{Z}=\bigcup_{i=1}^N\left(\left\{\mathbf{z}_i\right\} \cup\left\{\overline{\mathbf{z}}_i^j\right\}_{j=1}^M\right)=\operatorname{Enocder}(\mathcal{X})\) <br />
where \(\mathbf{z}_i, \overline{\mathbf{z}}_i^j \in \mathbb{R}^{L \times d_{\text {model }}}\)</li>
          <li>Detail : input 시계열마다 separately하게 통과 : \(\bigcup_{i=1}^N\left(\operatorname{Encoder}\left(\mathbf{x}_i\right) \cup\left\{\text { Encoder }\left(\overline{\mathbf{x}}_i^j\right)\right\}_{j=1}^M\right)\)</li>
        </ul>
      </li>
      <li>Projector : MLP layer along the temporal dim (to obtain the series-wise representations \(\mathcal{S}\))
        <ul>
          <li>\(\mathcal{S}=\bigcup_{i=1}^N\left(\left\{\mathbf{s}_i\right\} \cup\left\{\overline{\mathbf{s}}_i^j\right\}_{j=1}^M\right)=\operatorname{Projector}(\mathcal{Z})\) <br />
where \(\mathbf{s}_i, \overline{\mathbf{s}}_i^j \in \mathbb{R}^{1 \times d_{\text {model }}}\)</li>
        </ul>
      </li>
      <li>Note : \(\mathbf{z}_i, \overline{\mathbf{z}}_i^j \in \mathbb{R}^{L \times d_{\text {model }}}, \mathbf{s}_i, \overline{\mathbf{s}}_i^j \in \mathbb{R}^{1 \times d_{\text {model }}}\)
<img src="/assets/img/timeseries/SimMTM/myfig1.jpeg" alt="사진3" /></li>
    </ul>
  </li>
  <li><strong>Series-wise similarity learning</strong>
    <ul>
      <li>Multiple masked time series를 단순하게 averaging하면 over-smoothing problem이 있기 때문에, similarities among series-wise representation로 weighted aggregation한다.</li>
      <li>
\[\mathbf{R}=\operatorname{Sim}(\mathcal{S}) \in \mathbb{R}^{D \times D}, D=N(M+1), \quad \mathbf{R}_{\mathbf{u}, \mathbf{v}}=\frac{\mathbf{u v}^{\top}}{\|\mathbf{u}\|\|\mathbf{v}\|}, \mathbf{u}, \mathbf{v} \in \mathcal{S}\]
        <ul>
          <li>\(\mathbf{R}=\operatorname{Sim}(\mathcal{S}) \in \mathbb{R}^{D \times D}\)은 \(N(M+1)\)개의 input 각각에 대해 series-wise representation space에서의 similarities가 된다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Point-wise aggregation</strong>
    <ul>
      <li>The aggregation process는 다음과 같다 : \(\widehat{\mathbf{z}}_i=\sum_{\mathbf{s}^{\prime} \in \mathcal{S} \backslash\left\{\mathbf{s}_i\right\}} \frac{\exp \left(\mathbf{R}_{\mathbf{s}_i, \mathbf{s}^{\prime}} / \tau\right)}{\sum_{\mathbf{s}^{\prime \prime} \in \mathcal{S} \backslash\left\{\mathbf{s}_i\right\}} \exp \left(\mathbf{R}_{\mathbf{s}_i, \mathbf{s}^{\prime \prime}} / \tau\right)} \mathbf{z}^{\prime}\)
        <ul>
          <li>where \(\mathbf{z}^{\prime}=\text { Projector }\left(\mathbf{s}^{\prime}\right)\), \(\tau\) denotes the temperature hyperparameter of softmax normalization for series-wise similarities</li>
          <li>의미적으로는 \(\mathbf{x}_i\)를 reconstruction하기 위해서 \(\mathbf{x}_i\)에 대한 M개의 masked series \(\left\{\overline{\mathbf{x}}_i^j\right\}_{j=1}^M\) 뿐만 아니라, similarities가 높은 다른 series(samples)도 참고하겠다는 것으로, 시계열의 structure를 더 잘 학습하도록 의도했다.</li>
        </ul>
      </li>
      <li>그리고 마지막으로 Decoder를 통과시키면 reconstruction 값을 얻는다 : \(\left\{\widehat{\mathbf{x}}_i\right\}_{i=1}^N=\operatorname{Decoder}\left(\left\{\widehat{\mathbf{z}}_i\right\}_{i=1}^N\right)\)
        <ul>
          <li>\(\operatorname{Decoder}\)는 simple MLP layer (along the channel dim)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="32-self-supervised-pre-training">3.2. Self-supervised Pre-training</h3>
<ul>
  <li>SimMTM의 reconstruction loss는 \(\mathcal{L}_{\text {reconstruction }}=\sum_{i=1}^N\left\|\mathbf{x}_i-\widehat{\mathbf{x}}_i\right\|_2^2\)이다.</li>
  <li>The series-wise representation space에 constraints가 없으면 trivial aggregation이 발생할 수 있기 때문에, 한 series에 대한 multiple masked series끼리는 positive pair, 서로 다른 series에 대해서는 negative pair로 가정하고 (neighborhood assumption) contrastive하게 학습할 수 있도록 loss를 추가해주었다. : \(\mathcal{L}_{\text {constraint }}=-\sum_{\mathbf{s} \in \mathcal{S}}\left(\sum_{\mathbf{s}^{\prime} \in \mathcal{S}^{+}} \log \frac{\exp \left(\mathbf{R}_{\mathbf{s}, \mathbf{s}^{\prime}} / \tau\right)}{\sum_{\mathbf{s}^{\prime \prime} \in \mathcal{S} \backslash\{\mathbf{s}\}} \exp \left(\mathbf{R}_{\mathbf{s}, \mathbf{s}^{\prime \prime}} / \tau\right)}\right)\)</li>
  <li>SimMTM의 overall optimization loss는 다음과 같다 : \(\min _{\Theta} \mathcal{L}_{\text {reconstruction }}+\lambda \mathcal{L}_{\text {constraint }}\)
    <ul>
      <li>\(\mathcal{L}_{\text {constraint }}\)이 trivial aggregation이 발생하는 것에 대한 regularization 역할을 한다.</li>
    </ul>
  </li>
</ul>

<h2 id="4-experiments">4. Experiments</h2>
<p><img src="/assets/img/timeseries/SimMTM/table1.jpeg" alt="사진4" /></p>
<ul>
  <li>Low-level downstream task인 forecasting, high-level downstream task인 classification을 수행하였다.</li>
  <li>비교한 SOTA 모델들
    <ul>
      <li>contrastive learning methd : TF-C, CoST, TS2Vec, LaST</li>
      <li>masked modeling method : <strong>Ti-MAE</strong>, TST, TF-C
<img src="/assets/img/timeseries/SimMTM/fig3.png" alt="사진5" /></li>
      <li>(x-axis) 왼쪽에 있을수록 MSE가 낮고, (y-axis) 위쪽에 있을수록 Accuracy가 높다.</li>
    </ul>
  </li>
  <li><img src="/assets/img/timeseries/SimMTM/table2.png" alt="사진6" /></li>
  <li><img src="/assets/img/timeseries/SimMTM/table3.png" alt="사진7" /></li>
  <li><img src="/assets/img/timeseries/SimMTM/table4.png" alt="사진8" />
    <ul>
      <li>SimMTM은 학습 데이터와 테스트 데이터가 다른 cross-domain setting에서도 forecasting과 classification 모두 다른 모델보다 뛰어나기 때문에 좋은 baseline 모델이라 할 수 있다.</li>
    </ul>
  </li>
  <li><img src="/assets/img/timeseries/SimMTM/fig4.png" alt="사진9" />
    <ul>
      <li>\(\min _{\Theta} \mathcal{L}_{\text {reconstruction }}+\lambda \mathcal{L}_{\text {constraint }}\) 두 항 모두 loss term에 있을 때에 성능이 더 좋았다.</li>
    </ul>
  </li>
  <li><img src="/assets/img/timeseries/SimMTM/fig5.png" alt="사진10" />
    <ul>
      <li>(left) SimMTM은 학습의 effectiveness가 다른 모델보다 높다. 즉 적은 데이터만으로도 valuable knowledge를 잘 파악한다.</li>
      <li>(right) SimMTM에서 masked ratio가 높을수록 많은 multiple masked series를 만들 때 성능이 높다는 직관과 부합하는 결과이다.</li>
    </ul>
  </li>
</ul>

<h2 id="5-conclusion">5. Conclusion</h2>
<ul>
  <li>SimMTM은 new masked modeling 방법을 제시
    <ul>
      <li>reconstructs the original series from its multiple neighbor masked series</li>
      <li>aggregates the point-wise representations based on the series-wise similarities</li>
    </ul>
  </li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[NeurIPS 2023](https://arxiv.org/abs/2302.00861)]]></summary></entry><entry><title type="html">MCMC with Implementation (2) : Gibbs Sampling</title><link href="http://localhost:4000/stat/2024-03-06-gibbs/" rel="alternate" type="text/html" title="MCMC with Implementation (2) : Gibbs Sampling" /><published>2024-03-06T00:00:00+09:00</published><updated>2024-03-06T19:08:27+09:00</updated><id>http://localhost:4000/stat/gibbs</id><content type="html" xml:base="http://localhost:4000/stat/2024-03-06-gibbs/"><![CDATA[<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>만약 sampling하고자 하는 parameter의 full conditional distribution을 알 수 있다면 Gibbs sampler를 사용할 수 있다.</li>
  <li>Gibbs sampler는 MH-algorithm의 special case라고 할 수 있다.
    <ul>
      <li>Acceptance rate = 1이 되어 accept/reject 과정이 없다.</li>
    </ul>
  </li>
  <li><strong>Full conditional distribution</strong> : 만약 model parameters가 \(\mathbf{\theta}=\left(\theta_1, \cdots, \theta_k\right)\)이라면, full conditional distribution은 \(\pi\left(\theta_i \mid \theta_1, \cdots, \theta_{i-1}, \theta_{i+1}, \cdots, \theta_k, \mathbf{X}\right)\)이다. 즉 다른 parameters는 모두 given일 때 관심있는 parameter의 분포를 의미한다.</li>
  <li>정확히는 full conditional distribution이 모두 closed-form이어야 한다. 즉 k개의 conditional distributions가 standard한 분포(Normal, Gamma, …)를 따른다.</li>
  <li>그러므로 Gibss sampling 방식은 k개의 parameters로 이루어지는 확률변수 \(\mathbf{\theta}\)를 sampling을 할 때 k개 parameters를 한 번에 sampling하는 것이 아니라, 하나씩 sampling한 다음 k개를 모아서 하나의 sample로 만든다.
    <ul>
      <li>
        <ol>
          <li>Choose starting values \(\mathbf{\theta}=\left(\theta_1^{(1)}, \cdots, \theta_k^{(1)}\right)\)</li>
        </ol>
      </li>
      <li>
        <ol>
          <li>For \(i=2, \cdots, T\) sample <br />
\(\begin{aligned}
&amp; \theta_1^{(i)} \mid \theta_2^{(i-1)}, \cdots, \theta_k^{(i-1)}, \mathbf{X} \\
&amp; \theta_2^{(i)} \mid \theta_1^{(i)}, \theta_3^{(i-1)}, \cdots, \theta_k^{(i-1)}, \mathbf{X} \\
&amp; \theta_k^{(i)} \mid \theta_1^{(i)}, \cdots, \theta_{k-1}^{(i)}, \mathbf{X}
\end{aligned}\)</li>
        </ol>
      </li>
    </ul>
  </li>
  <li>주의할 점은 \(\theta_2^{(i)}\)를 sampling할 때에는 아직 sampling하지 않은 \(\theta_3^{(i)}\)부터 \(\theta_k^{(i)}\)까지는 이전 시점의 값을 사용하지만, 이미 sampling을 한 \(\theta_1^{(i)}\)은 sampling한 값을 사용한다는 점이다.</li>
</ul>

<h2 id="2-full-conditional-distribution-for-gibb-sampler">2. Full conditional distribution for Gibb Sampler</h2>
<ul>
  <li>다음과 같은 간단한 Bayse rule을 보자. \(P(A \mid B)=\frac{P(A, B)}{P(B)}=\frac{P(A, B)}{P(A)} \times \frac{P(A)}{P(B)}=P(B \mid A) \times \frac{P(A)}{P(B)}\)
    <ul>
      <li>A를 sampling할 parameters, B를 주어진 데이터라고 하면 \(P(B \mid A)\)는 likelihood이고, \(P(A)\)는 prior가 된다. 그리고 \(P(B)\)는 주어진 상수가 되어 고려하지 않아도 된다. 왜냐하면 결국 A가 바뀔 때 posterior \(P(A \mid B)\)의 대소관계가 궁금하기 때문이다.</li>
      <li>그러므로 \(\text{posterior} \propto \text{likelihood} \times \text{prior}\) 관계가 성립한다.</li>
    </ul>
  </li>
</ul>

<h2 id="3-r-implementation-of-gibb-sampler">3. R Implementation of Gibb Sampler</h2>

<h3 id="31-ex1--bayesian-linear-regression">3.1. Ex.1 : Bayesian Linear Regression</h3>
<p>\(\begin{gathered}
Y_i=\beta_0+\beta_1 X_{1, i}+\beta_2 X_{2, i}+\beta_3 X_{1, i} X_{2, i}+\epsilon_i  \\
\text{where } \epsilon_i \sim N\left(0, \sigma^2\right) \text{independently for } i=1, \cdots, 300,000 \\
\text{We will use independent priors as} \\
\beta_j \sim N(0,10) \text { for } j=0,1,2,3 \\
\sigma^2 \sim \operatorname{IG}(0.01,0.01)
\end{gathered}\)</p>
<ul>
  <li>위 모형에서 임의의 parameters로 데이터를 생성하고, Gibbs sampler가 생성한 parameters samples와 임의로 정한 parameters를 비교한다.</li>
  <li><strong>Simulation the dataset</strong>
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># the size of dataset</span><span class="w">
</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">300000</span><span class="w">

</span><span class="c1"># Simulating (X_1,1, ..., X_1,n) and (X_2,1, ..., X_2,n) ~ N(0,1)</span><span class="w">
</span><span class="n">X</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">Sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">2</span><span class="p">))</span><span class="w">
  
</span><span class="c1"># Setting the true parameters (beta)</span><span class="w">
</span><span class="n">beta.true</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">-1</span><span class="p">)</span><span class="w">

</span><span class="c1"># Simulating (Y_1, ..., Y_n) using the design matrix for above model</span><span class="w">
</span><span class="n">X_design</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="p">[,</span><span class="m">1</span><span class="p">]</span><span class="o">*</span><span class="n">X</span><span class="p">[,</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="p">)</span><span class="w">
</span><span class="n">Y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">X_design</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">beta.true</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><strong>Calculation the full conditional distribution</strong>
    <ul>
      <li>For \(\beta\), the kernel of posterior for Gibbs sampler is following :
\(\begin{aligned}
&amp; P\left(\beta \mid Y, X, \sigma^2\right) \propto L\left(Y, X \mid \beta, \sigma^2\right) P(\beta) \\
&amp; \propto\left(\frac{1}{\sqrt{2 \pi}}\right)^n\left(\frac{1}{\operatorname{det}\left(\sigma^2 I\right)}\right)^{\frac{1}{2}} \exp \left(-\frac{(Y-X \beta)^{\top}(Y-X \beta)}{2 \sigma^2}\right)\left(\frac{1}{\sqrt{2 \pi}}\right)^p\left(\frac{1}{\operatorname{det}(10 I)}\right)^{\frac{1}{2}} \exp \left(-\frac{\beta^{\top} \beta}{20}\right) \\
&amp; \propto \exp \left(-\frac{(Y-X \beta)^{\top}(Y-X \beta)}{2 \sigma^2}-\frac{\beta^{\top} \beta}{20}\right) \\
&amp; =\exp \left(-\frac{1}{2 \sigma^2} Y^{\top} Y+\frac{1}{2 \sigma^2} Y^{\top} X \beta+\frac{1}{2 \sigma^2} \beta^{\top} X Y-\frac{\beta^{\top} X^{\top} X \beta}{2 \sigma^2}-\frac{\beta^{\top} \beta}{20}\right) \\
&amp; =\exp \left(-\frac{1}{2}\left(\beta^{\top}\left(\frac{X^{\top} X}{\sigma^2}+\frac{I}{10}\right) \beta-\beta^{\top}\left(\frac{X^{\top} Y}{\sigma^2}\right)-\left(\frac{Y^{\top} X}{\sigma^2}\right) \beta+\frac{Y^{\top} Y}{6^2}\right)\right) \\
&amp; \therefore V_\beta=\left[\frac{X^{\top} X}{\sigma^2}+\frac{I}{10}\right]^{-1}, \quad m_\beta=V_\beta \frac{X^{\top} Y}{\sigma^2} \\
&amp; \beta \sim N\left(m_\beta, V_\beta\right) \\
\end{aligned}\)</li>
    </ul>
  </li>
  <li>For \(\sigma^2\), the kernel of posterior for Gibbs sampler is following :
\(\begin{aligned}
P\left(\sigma^2 \mid, \beta\right) &amp; \propto L\left(Y, X \mid \beta, \sigma^2\right) P\left(\sigma^2\right) \\
&amp; \propto\left(\frac{1}{\sigma \sqrt{2 \pi}}\right)^n \exp \left(-\frac{(Y-X \beta)^{\top}(Y-X \beta)}{2 \sigma^2}\right) \frac{\beta^\alpha}{\Gamma(\alpha)}\left(\frac{1}{\sigma^2}\right)^{\alpha+1} \exp \left(-\frac{\beta}{\sigma^2}\right) \\
&amp; \propto\left(\frac{1}{\sigma^2}\right)^{\frac{n}{2}+\alpha+1} \exp \left(-\frac{\beta+\frac{1}{2}(Y-X \beta)^{\top}(Y-X \beta)}{\sigma^2}\right) \\
&amp; \\
&amp; \therefore \alpha_{\sigma^2}=\frac{n}{2}+\alpha, \quad \beta_{\sigma^2}=\beta+\frac{1}{2}(Y-X \beta)^{\top}(Y-X \beta) \\
&amp; \sigma^2 \sim I G\left(\alpha_{\sigma^2}, \beta_{\sigma^2}\right)
\end{aligned}\)
    <ul>
      <li>위 결과를 바탕으로 sampling하는 R 코드를 작성한다.</li>
    </ul>

    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># the number of variates</span><span class="w">
</span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ncol</span><span class="p">(</span><span class="n">X_design</span><span class="p">)</span><span class="w">

</span><span class="c1"># The prior parameters</span><span class="w">
</span><span class="n">m.beta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="p">;</span><span class="w"> </span><span class="n">v.beta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="n">a.s2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.01</span><span class="p">;</span><span class="w"> </span><span class="n">b.s2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.01</span><span class="w">
  
</span><span class="c1"># 각각의 parameters를 1000개씩 sampling한다.</span><span class="w">
</span><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="w">

</span><span class="c1"># sample space with initialization for each parameters</span><span class="w">
</span><span class="n">beta.samps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">B</span><span class="p">)</span><span class="w">
</span><span class="n">s2.samps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">B</span><span class="p">)</span><span class="w">
</span><span class="n">beta.samps</span><span class="p">[,</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="n">p</span><span class="p">)</span><span class="w">
</span><span class="n">s2.samps</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">

</span><span class="c1"># Gibbs sampler</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">2</span><span class="o">:</span><span class="n">B</span><span class="p">){</span><span class="w">
    
  </span><span class="c1">## beta[i] | s2[i-1]</span><span class="w">
  </span><span class="n">V</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">solve</span><span class="p">(</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">X_design</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">X_design</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">s2.samps</span><span class="p">[</span><span class="n">i</span><span class="m">-1</span><span class="p">]</span><span class="o">+</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">v.beta</span><span class="w"> </span><span class="p">)</span><span class="w">
  </span><span class="n">m</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">V</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">X_design</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">Y</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">s2.samps</span><span class="p">[</span><span class="n">i</span><span class="m">-1</span><span class="p">]</span><span class="w"> </span><span class="p">)</span><span class="w">
  </span><span class="n">beta.samps</span><span class="p">[,</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rmvnorm</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"svd"</span><span class="p">)</span><span class="w">
    
  </span><span class="c1"># s2[i] | beta[i]</span><span class="w">
  </span><span class="n">a</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">n</span><span class="o">/</span><span class="m">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a.s2</span><span class="w">
  </span><span class="n">b</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">b.s2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="w"> </span><span class="n">Y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">X_design</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">beta.samps</span><span class="p">[,</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="n">Y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">X_design</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">beta.samps</span><span class="p">[,</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">2</span><span class="w">
  </span><span class="n">s2.samps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rinvgamma</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="o">=</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">scale</span><span class="o">=</span><span class="n">b</span><span class="p">)</span><span class="w">
  </span><span class="n">s2.samps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">s2.samps</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
  </span><span class="c1"># burn-in</span><span class="w">
  </span><span class="n">beta.samps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">beta.samps</span><span class="p">[,</span><span class="m">51</span><span class="o">:</span><span class="n">B</span><span class="p">]</span><span class="w">
  </span><span class="n">s2.samps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">s2.samps</span><span class="p">[</span><span class="m">51</span><span class="o">:</span><span class="n">B</span><span class="p">]</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><strong>Checking the Samples</strong>
    <ul>
      <li>density plot, trace plot 등 다양한 tools를 활용하여 결과를 확인해야 하지만, posterior mean(samples의 평균)만 확인한다. 상당히 정확하게 sampling 되었다는 것을 알 수 있다.</li>
    </ul>

    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># posterior mean</span><span class="w">
</span><span class="n">cat</span><span class="p">(</span><span class="s2">"posterior mean of beta0:"</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">1</span><span class="p">,]),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"posterior mean of beta1:"</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">2</span><span class="p">,]),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"posterior mean of beta2:"</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">3</span><span class="p">,]),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"posterior mean of beta3:"</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">4</span><span class="p">,]),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"posterior mean of sigma2:"</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">s2.samps</span><span class="p">)</span><span class="w"> </span><span class="p">)</span><span class="w">

</span><span class="c1">##### result #####</span><span class="w">
</span><span class="c1">## posterior mean of beta0: 0.4976068</span><span class="w">
</span><span class="c1">##  posterior mean of beta1: 0.9989775</span><span class="w">
</span><span class="c1">##  posterior mean of beta2: 2.00346</span><span class="w">
</span><span class="c1">##  posterior mean of beta3: -1.00101</span><span class="w">
</span><span class="c1">##  posterior mean of sigma2: 0.9986912</span><span class="w">
</span></code></pre></div>    </div>
    <ul>
      <li>Gibbs Sampler는 proposed sample이 항상 accept된다는 점에서 MH-algorithm의 speecial case라고 할 수 있다. samples의 unique value의 개수와 B=1000의 비율을 출력한다.</li>
    </ul>

    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># acceptance ratio</span><span class="w">
</span><span class="c1"># (Because I used Gibbs sampler, samples was always accepted !)</span><span class="w">
</span><span class="n">cat</span><span class="p">(</span><span class="s2">"Acceptance ratio of beta0 :"</span><span class="p">,</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">unique</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">1</span><span class="p">,]))</span><span class="o">/</span><span class="n">B</span><span class="w"> </span><span class="p">,</span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Acceptance ratio of beta1 :"</span><span class="p">,</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">unique</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">2</span><span class="p">,]))</span><span class="o">/</span><span class="n">B</span><span class="w"> </span><span class="p">,</span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Acceptance ratio of beta2 :"</span><span class="p">,</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">unique</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">3</span><span class="p">,]))</span><span class="o">/</span><span class="n">B</span><span class="w"> </span><span class="p">,</span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Acceptance ratio of beta3 :"</span><span class="p">,</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">unique</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">4</span><span class="p">,]))</span><span class="o">/</span><span class="n">B</span><span class="w"> </span><span class="p">,</span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Acceptance ratio of sigma2 :"</span><span class="p">,</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">unique</span><span class="p">(</span><span class="n">s2.samps</span><span class="p">))</span><span class="o">/</span><span class="n">B</span><span class="w"> </span><span class="p">)</span><span class="w">
  
</span><span class="c1">##### result #####</span><span class="w">
</span><span class="c1">## Acceptance ratio of beta0 : 0.95</span><span class="w">
</span><span class="c1">##  Acceptance ratio of beta1 : 0.95</span><span class="w">
</span><span class="c1">##  Acceptance ratio of beta2 : 0.95</span><span class="w">
</span><span class="c1">##  Acceptance ratio of beta3 : 0.95</span><span class="w">
</span><span class="c1">##  Acceptance ratio of sigma2 : 0.95</span><span class="w">
</span></code></pre></div>    </div>
    <ul>
      <li>앞서 burn-in으로 각 parameters에서 50개의 samples를 버린 것을 감안하면 sample가 항상 accept되었음을 알 수 있다. (acceptance probabilties = 1)
        <ul>
          <li>Acceptance probabilies는 각 proposed sample이 accept될 확률이고</li>
          <li>Acceptance ratio는 전체 sampling 횟수 중에서 accept된 비율을 의미한다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="32-ex2--truncated-exponential-distribution">3.2. Ex.2 : Truncated Exponential distribution</h3>
<ul>
  <li>to be continued…</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="stat" /><summary type="html"><![CDATA[1. Introduction 만약 sampling하고자 하는 parameter의 full conditional distribution을 알 수 있다면 Gibbs sampler를 사용할 수 있다. Gibbs sampler는 MH-algorithm의 special case라고 할 수 있다. Acceptance rate = 1이 되어 accept/reject 과정이 없다. Full conditional distribution : 만약 model parameters가 \(\mathbf{\theta}=\left(\theta_1, \cdots, \theta_k\right)\)이라면, full conditional distribution은 \(\pi\left(\theta_i \mid \theta_1, \cdots, \theta_{i-1}, \theta_{i+1}, \cdots, \theta_k, \mathbf{X}\right)\)이다. 즉 다른 parameters는 모두 given일 때 관심있는 parameter의 분포를 의미한다. 정확히는 full conditional distribution이 모두 closed-form이어야 한다. 즉 k개의 conditional distributions가 standard한 분포(Normal, Gamma, …)를 따른다. 그러므로 Gibss sampling 방식은 k개의 parameters로 이루어지는 확률변수 \(\mathbf{\theta}\)를 sampling을 할 때 k개 parameters를 한 번에 sampling하는 것이 아니라, 하나씩 sampling한 다음 k개를 모아서 하나의 sample로 만든다. Choose starting values \(\mathbf{\theta}=\left(\theta_1^{(1)}, \cdots, \theta_k^{(1)}\right)\) For \(i=2, \cdots, T\) sample \(\begin{aligned} &amp; \theta_1^{(i)} \mid \theta_2^{(i-1)}, \cdots, \theta_k^{(i-1)}, \mathbf{X} \\ &amp; \theta_2^{(i)} \mid \theta_1^{(i)}, \theta_3^{(i-1)}, \cdots, \theta_k^{(i-1)}, \mathbf{X} \\ &amp; \theta_k^{(i)} \mid \theta_1^{(i)}, \cdots, \theta_{k-1}^{(i)}, \mathbf{X} \end{aligned}\) 주의할 점은 \(\theta_2^{(i)}\)를 sampling할 때에는 아직 sampling하지 않은 \(\theta_3^{(i)}\)부터 \(\theta_k^{(i)}\)까지는 이전 시점의 값을 사용하지만, 이미 sampling을 한 \(\theta_1^{(i)}\)은 sampling한 값을 사용한다는 점이다.]]></summary></entry><entry><title type="html">MCMC with Implementation (1) : Metropolis Hastings algorithm</title><link href="http://localhost:4000/stat/2024-03-04-mcmc/" rel="alternate" type="text/html" title="MCMC with Implementation (1) : Metropolis Hastings algorithm" /><published>2024-03-04T00:00:00+09:00</published><updated>2024-03-06T17:11:13+09:00</updated><id>http://localhost:4000/stat/mcmc</id><content type="html" xml:base="http://localhost:4000/stat/2024-03-04-mcmc/"><![CDATA[<h2 id="1-probabilistic-ml-model">1. Probabilistic ML Model</h2>
<ul>
  <li>\(x\) : set of observed variables <br />
\(y\) : set of hidden / latent variables <br />
\(\theta\) : model parameters</li>
  <li>
    <p>Discriminative probabilistic ML model</p>

    <ul>
      <li>\(p(Y \mid X)\) : 데이터 \(X\)가 주어졌을 때 결과 \(y\) 예측하기 (Classification, Regression, …)</li>
    </ul>
  </li>
  <li>
    <p>Generative probabilistic ML model</p>

    <ul>
      <li>Bayes Theorem : \(p(Y \mid X)=\frac{p(X, Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{\int p(X \mid Y) p(Y) d Y}\)
<img src="/assets/img/stat/vi/fig1.png" alt="그림1" /></li>
    </ul>
  </li>
  <li>Discriminative model은 클래스(y) 사이의 차이를 의미하는 decision boundary를 학습하고, (\(p(Y\mid X)\))
Generative model은 분포 \(p(X), p(X,Y)\)를 학습하여 posterior \(p(Y\mid X)\)를 추정한다.</li>
  <li>\(Y\)의 차원이 높아질수록 분모에 있는 \(Y\)에 대한 적분이 어려워지기 때문에(intractable), 아래 두 가지 방법으로 \(p(Y\mid X)\)를 추정한다.
    <ul>
      <li>Variational Inference (optimization)</li>
      <li>Markov chain Monte Carlo (sampling)</li>
      <li>MCMC는 분포를 근사하기 위해 sampling으로 inference하는 것이고, VI는 분포를 근사하기 위해 optimization 문제로 바꾼 것이다.</li>
      <li>일반적으로 VI는 빠르고, MCMC는 정확하다.(상대적으로 그렇다는 것)</li>
    </ul>
  </li>
</ul>

<h2 id="2-markov-chain-monte-carlo">2. Markov Chain Monte Carlo</h2>
<h3 id="21-the-properties-of-mc">2.1. The properties of MC</h3>
<ul>
  <li><strong>Markov Chain</strong> : \(\operatorname{Pr}\left\{X_{t+1}=j_{t+1} \mid X_t=j_t, X_{t-1}=j_{t-1}, \cdots, X_0=j_0\right\} = \operatorname{Pr}\left\{X_{t+1}=j_{t+1} \mid X_t=j_t\right\}\)</li>
  <li><strong>Transition probability</strong> : \(\mathbf{P}=\left(\left(p_{i j}\right)\right) ; \quad \operatorname{Pr}\left\{X_t=j \mid X_0=i\right\}=\left(\mathbf{P}^t\right)_{i j}\) <br />
where \(p_{i j}=\operatorname{Pr}\left\{X_{t+1}=j \mid X_t=i\right\}\)
<img src="/assets/img/stat/mcmc/fig1.jpeg" alt="그림2" /></li>
  <li><strong>Irreducible</strong> : \(\left(\mathbf{P}^t\right)_{i j}=\operatorname{Pr}\left\{X_t=j \mid X_0=i\right\}&gt;0$ for some $t&gt;0, and all $i$ and $j$ in $\Omega$.\)
    <ul>
      <li>현재 state가 무엇이든, 모든 state에 언젠가는 도달할 수 있어야 한다.</li>
      <li>Markov Chain이 irreducible하면 unique한 stationary probabilities를 가진다. <br />
i.e. \(\pi_j=\lim _{n \rightarrow \infty} \frac{1}{n} \sum_{t=1}^n I\left(X_t=j\right) \text { w.p.1 for all initial states}\)</li>
      <li>Indicator의 expectation은 probability이므로 \(\pi_j=\lim _{n \rightarrow \infty} \frac{1}{n} \sum_{t=1}^n \operatorname{Pr}\left\{X_t=j \mid X_0=i\right\}, \text { for all initial states}\)</li>
    </ul>
  </li>
  <li><strong>Aperiodic</strong> : \(\operatorname{Pr}\left\{X_t=j \mid X_0=j\right\}&gt;0 \text { and } \operatorname{Pr}\left\{X_{t+1}=j \mid X_0=j\right\}&gt;0\)
    <ul>
      <li>주기가 없다는 것을 수학적으로 표현하면 위와 같다. Irreducible한 Markov Chain이 하나 이상의 self-loop를 가진다면 aperiodic하다.</li>
    </ul>
  </li>
  <li><strong>Time-reversible</strong> : \(\pi_i p_{i j}=\pi_j p_{j i}, \quad \forall i \neq j\)
    <ul>
      <li><code class="language-plaintext highlighter-rouge">i에 도달하고 i에서 j가 될 확률</code>과 <code class="language-plaintext highlighter-rouge">j에 도달하고 j에서 i가 될 확률</code>이 같다는 의미</li>
    </ul>
  </li>
  <li>많은 경우의 Markov Chains는 irreducible, aperiodic, time-reversible하다.</li>
  <li>결국 하고자 하는 것은 \(E[h(X)]=\sum_{j=1}^N h(j) \pi_j\)를 \(\frac{1}{n} \sum_{t=1}^n h\left(X_t\right)\)로 추정하는 것이다.</li>
</ul>

<h3 id="22-metropolis-hastings-algorithm">2.2. Metropolis-Hastings algorithm</h3>
<ul>
  <li>Goal : (MCMC를 왜 할까?)
    <ul>
      <li>\(X \sim F\) with density f를 sampling하고 싶은데 independent sampling이 불가능하기 때문에 최대한 independent한 samples를 만드는 것</li>
    </ul>
  </li>
  <li>\(F\)로부터 직접 sampling하기 어려운 경우에, sampling이 쉬운 proposal density \(q(x' \mid x)\)에서 propose</li>
  <li>\(q(x' \mid x)\)에서의 proposed sample은 \(\alpha=\min \left(\frac{f\left(x^{\prime}\right) q\left(x \mid x^{\prime}\right)}{f(x) q\left(x^{\prime} \mid x\right)}, 1\right)\)확률로 sample에 추가, 아니면 stay \(x\)</li>
  <li>정리하면
    <ul>
      <li>Step1. Proposal density \(q(x' \mid x)\)를 선택한다.</li>
      <li>Step2. 적당한 initial state \(X_0 = x_0\)를 정한다.</li>
      <li>
        <p>Step3. \(X' \sim q(x' \mid X_t)\)와 \(U \sim Unif(0,1)\)을 생성한다.</p>
      </li>
      <li>Step4. \(U&lt;\frac{f\left(X^{\prime}\right) q\left(X_t \mid X^{\prime}\right)}{f\left(X_t\right) q\left(X^{\prime} \mid X_t\right)}, \text { then } X_{t+1}=X^{\prime} . \text { Else } X_{t+1}=X_t\)</li>
      <li>Step5. \(t = t + 1\), Go to Step3</li>
    </ul>
  </li>
  <li>이 때 proposal density가 symmetric density이면 \(\frac{q\left(X_t \mid X^{\prime}\right)}{q\left(X^{\prime} \mid X_t\right)}=1\)이 되어 계산할 필요가 없어진다.</li>
  <li><img src="/assets/img/stat/mcmc/fig2.png" alt="그림3" /></li>
  <li>예를 들어, MCMC로 생성한 samples의 trace plot이 위와 같다면 target distribution은 \((-2,2)\)에서 높은 density를 갖는다는 것을 알 수 있고, initial state와 무관하게 빠르게 수렴하는 것을 볼 수 있다.</li>
</ul>

<h2 id="3-r-implementation--mh-algorithm">3. R Implementation : MH-algorithm</h2>
<ul>
  <li>예시를 통해 MH-algorithm을 구현해본다.
    <ul>
      <li>Target density : \(g(x)=\exp \left(-(x+1)^2-y^2\right)+\exp \left(-150\left(x^2-y\right)^2-150\left(x-y^2\right)^2\right)\)
        <ul>
          <li>복잡한 un-normalized density이므로 직접 sampling하기가 어렵기 때문에 MH-algorithm으로 sampling한다.</li>
        </ul>
      </li>
      <li>Proposal distribution : \(\left(\begin{array}{l} x_{new} \\ y_{new} \end{array}\right) \sim N\left(\left(\begin{array}{l} x_{now} \\ y_{now} \end{array}\right), \sigma^2\left(\begin{array}{ll} 1 &amp; \rho \\ \rho &amp; 1 \end{array}\right)\right)\) where \(\sigma^2 &gt; 0, \rho \in (-1,1)\)’</li>
    </ul>
  </li>
  <li>먼저 target density를 visualization해서 파악한다.</li>
  <li>
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">g</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">exp</span><span class="p">(</span><span class="m">-150</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">150</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)}</span><span class="w">

</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">-3</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">);</span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">-2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">)</span><span class="w">
</span><span class="n">z</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">outer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">g</span><span class="p">)</span><span class="w">
</span><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="w">
</span><span class="n">contour</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"X"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Y"</span><span class="p">,</span><span class="w">
        </span><span class="n">main</span><span class="o">=</span><span class="s2">"The contour plot of density g"</span><span class="p">)</span><span class="w">
</span></code></pre></div>    </div>
    <p><img src="/assets/img/stat/mcmc/fig3.png" alt="그림4" /></p>
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">))</span><span class="w">
</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">-3</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">);</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">-2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">)</span><span class="w">
</span><span class="n">z</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">outer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">g</span><span class="p">)</span><span class="w">
</span><span class="n">res1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">persp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="n">theta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="n">phi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">expand</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w">
              </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"green"</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"X"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Y"</span><span class="p">,</span><span class="w"> </span><span class="n">zlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Z"</span><span class="p">,</span><span class="w">
              </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"The density plot of g"</span><span class="p">)</span><span class="w">
</span><span class="n">res2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">persp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="n">theta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="n">phi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">expand</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w">
              </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"green"</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"X"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Y"</span><span class="p">,</span><span class="w"> </span><span class="n">zlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Z"</span><span class="p">,</span><span class="w">
              </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"The density plot of g"</span><span class="p">)</span><span class="w">
</span></code></pre></div>    </div>
    <p><img src="/assets/img/stat/mcmc/fig4.png" alt="그림5" /></p>
  </li>
  <li>MH-algorithm을 함수로 작성한다.
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MCMC.MH</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">init</span><span class="p">,</span><span class="w"> </span><span class="n">sigma</span><span class="p">,</span><span class="w"> </span><span class="n">rho</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  
</span><span class="c1">############################################################</span><span class="w">
</span><span class="c1"># n : sample size</span><span class="w">
</span><span class="c1"># init : starting value (initialization)</span><span class="w">
</span><span class="c1"># sigma, rho : parameters for covariance matrix of proposal distribution</span><span class="w">
</span><span class="c1">############################################################</span><span class="w">

</span><span class="c1"># sample space for x, y</span><span class="w">
</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w">

</span><span class="c1"># initialization</span><span class="w">
</span><span class="n">x</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">init</span><span class="p">[</span><span class="m">1</span><span class="p">];</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">init</span><span class="p">[</span><span class="m">2</span><span class="p">]</span><span class="w">
  
</span><span class="c1"># run the loop until sample space is full</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">2</span><span class="o">:</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">

  </span><span class="c1"># 현재값(=current, =now)이 new x, new y의 분포를 결정한다. (Markov chain의 property)</span><span class="w">
  </span><span class="n">current</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="m">-1</span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="m">-1</span><span class="p">])</span><span class="w">

  </span><span class="c1"># Proposed sample</span><span class="w">
  </span><span class="n">proposal</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rmvnorm</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">current</span><span class="p">,</span><span class="w">
                         </span><span class="n">sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">rho</span><span class="p">,</span><span class="w"> </span><span class="n">rho</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">sigma</span><span class="o">^</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">))</span><span class="w">

  </span><span class="c1"># Accept probability</span><span class="w">
  </span><span class="c1"># Note: Proposal function이 normal(symmetric)이므로 q항이 약분된다.                       </span><span class="w">
  </span><span class="n">a</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">g</span><span class="p">(</span><span class="n">proposal</span><span class="p">[</span><span class="m">1</span><span class="p">],</span><span class="w"> </span><span class="n">proposal</span><span class="p">[</span><span class="m">2</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">g</span><span class="p">(</span><span class="n">current</span><span class="p">[</span><span class="m">1</span><span class="p">],</span><span class="w"> </span><span class="n">current</span><span class="p">[</span><span class="m">2</span><span class="p">])</span><span class="w">
    
  </span><span class="c1"># Accept or Reject</span><span class="w">
  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">runif</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">proposal</span><span class="p">[</span><span class="m">1</span><span class="p">];</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">proposal</span><span class="p">[</span><span class="m">2</span><span class="p">]}</span><span class="w">
  </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">current</span><span class="p">[</span><span class="m">1</span><span class="p">];</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">current</span><span class="p">[</span><span class="m">2</span><span class="p">]}}</span><span class="w">

</span><span class="c1"># when sample space is full, we will return  </span><span class="w">
</span><span class="nf">return</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">))}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li>이제 MCMC를 실행하고 결과를 본다.
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1e6</span><span class="w">
</span><span class="n">samples.1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MCMC.MH</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">init</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">-10</span><span class="p">,</span><span class="w"> </span><span class="m">-10</span><span class="p">),</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">,</span><span class="w"> </span><span class="n">rho</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">samples.1</span><span class="o">$</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Scatter plot of x and y"</span><span class="p">,</span><span class="w"> </span><span class="n">pch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">)</span><span class="w">
</span></code></pre></div>    </div>
    <p><img src="/assets/img/stat/mcmc/fig5.png" alt="그림6" /></p>
    <ul>
      <li>생성된 samples가 점점 target density가 높은 방향으로 움직인다.</li>
    </ul>
  </li>
  <li>Density plot가 target density와 비슷한지, trace plot으로 chain이 잘 수렴하는지, acf plot으로 얼마나 dependent한지 눈으로 확인할 수 있다.
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># density plot</span><span class="w">
</span><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">))</span><span class="w">
</span><span class="n">hist</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Histogram of x"</span><span class="p">,</span><span class="w"> </span><span class="n">freq</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="o">=</span><span class="m">100</span><span class="p">)</span><span class="w">
</span><span class="n">hist</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Histogram of y"</span><span class="p">,</span><span class="w"> </span><span class="n">freq</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="o">=</span><span class="m">100</span><span class="p">)</span><span class="w">

</span><span class="c1"># trace plot</span><span class="w">
</span><span class="n">ts.plot</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Trace plot of x"</span><span class="p">)</span><span class="w">
</span><span class="n">ts.plot</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Trace plot of y"</span><span class="p">)</span><span class="w">

</span><span class="c1"># acf plot</span><span class="w">
</span><span class="n">acf</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Autocorrelation of x"</span><span class="p">)</span><span class="w">
</span><span class="n">acf</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Autocorrelation of y"</span><span class="p">)</span><span class="w">
</span></code></pre></div>    </div>
    <p><img src="/assets/img/stat/mcmc/fig6.jpg" alt="그림7" /></p>
  </li>
  <li>Tuning :
    <ul>
      <li>initial point가 (-10, 10)이므로 x와 y가 모두 커져야 target density가 높은 방향으로 움직인다.
        <ul>
          <li>\(rho&gt;0\)으로 설정</li>
        </ul>
      </li>
      <li>initial point가 target density가 높은 곳과 멀리 떨어져있다
        <ul>
          <li>\(sigma &gt;&gt; 0.1\)으로 설정</li>
        </ul>
      </li>
      <li>결과는 아래와 같다.
        <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples.4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MCMC.MH</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">init</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">-10</span><span class="p">,</span><span class="w"> </span><span class="m">-10</span><span class="p">),</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">rho</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.8</span><span class="p">)</span><span class="w">
</span><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">samples.4</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">samples.4</span><span class="o">$</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Scatter plot of x and y"</span><span class="p">,</span><span class="w"> </span><span class="n">pch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">)</span><span class="w">
</span><span class="c1"># 얼마나 빠르게 수렴하는지 보기 위해 첫 10개 sample을 색칠을 해주었다.</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">){</span><span class="n">points</span><span class="p">(</span><span class="n">samples.4</span><span class="o">$</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">samples.4</span><span class="o">$</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">pch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)}</span><span class="w">
</span></code></pre></div>        </div>
        <p><img src="/assets/img/stat/mcmc/fig7.png" alt="그림8" /></p>
      </li>
      <li>Scatter plot으로부터 수렴이 훨씬 빠르게 되었음을 확인할 수 있다. sigma로 보폭을, rho로 방향을 적절하게 설정했기 때문이다.</li>
      <li>물론 burn-in을 통해 수렴하기 전의 samples를 제거할 수 있다. 하지만 target distribution이 퍼져있는 정도를 고려했을 때, sigma를 늘리지 않을 이유는 없다.
<img src="/assets/img/stat/mcmc/fig8.jpeg" alt="그림9" /></li>
      <li>Acf plot이 유의미하게 낮아졌다. sigma가 커짐에 따라 현재값으로부터 멀리 떨어진 new sample이 proposed되었기 때문이다.</li>
      <li>그렇다고 sigma가 클수록 좋다는 것은 아니다. sigma가 충분히 큰 덕분에 빠르게 수렴했지만, sigma가 너무 크면 target density가 낮은 위치에서 sample이 생성될 확률이 높아지기 때문에 acceptance rate가 낮아지고 sampling에 시간이 지나치게 오래 걸린다.</li>
    </ul>
  </li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="stat" /><summary type="html"><![CDATA[1. Probabilistic ML Model \(x\) : set of observed variables \(y\) : set of hidden / latent variables \(\theta\) : model parameters Discriminative probabilistic ML model \(p(Y \mid X)\) : 데이터 \(X\)가 주어졌을 때 결과 \(y\) 예측하기 (Classification, Regression, …) Generative probabilistic ML model]]></summary></entry><entry><title type="html">Advanced Variational Inference(VI), Variational Autoencoder(VAE)</title><link href="http://localhost:4000/stat/2024-03-02-vi/" rel="alternate" type="text/html" title="Advanced Variational Inference(VI), Variational Autoencoder(VAE)" /><published>2024-03-02T00:00:00+09:00</published><updated>2024-03-04T16:34:37+09:00</updated><id>http://localhost:4000/stat/vi</id><content type="html" xml:base="http://localhost:4000/stat/2024-03-02-vi/"><![CDATA[<ul>
  <li>Paper : <a href="https://arxiv.org/abs/1601.00670">Variational Inference : A Review for Statisticians</a></li>
  <li>Paper : <a href="https://arxiv.org/pdf/1711.05597.pdf">Advances in Variational Inference</a></li>
  <li>Paper : <a href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes</a></li>
</ul>

<h2 id="1-probabilistic-ml-model">1. Probabilistic ML Model</h2>
<ul>
  <li>\(x\) : set of observed variables <br />
\(y\) : set of hidden / latent variables <br />
\(\theta\) : model parameters</li>
  <li>Discriminative probabilistic ML model
    <ul>
      <li>\(p(Y \mid X)\) : 데이터 \(X\)가 주어졌을 때 결과 \(y\) 예측하기 (Classification, Regression, …)</li>
    </ul>
  </li>
  <li>
    <p>Generative probabilistic ML model</p>

    <ul>
      <li>Bayes Theorem : \(p(Y \mid X)=\frac{p(X, Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{\int p(X \mid Y) p(Y) d Y}\)
<img src="/assets/img/stat/vi/fig1.png" alt="그림1" /></li>
    </ul>
  </li>
  <li>Discriminative model은 클래스(y) 사이의 차이를 의미하는 decision boundary를 학습하고, (\(p(Y\mid X)\))
Generative model은 분포 \(p(X), p(X,Y)\)를 학습하여 posterior \(p(Y\mid X)\)를 추정한다.</li>
  <li>\(Y\)의 차원이 높아질수록 분모에 있는 \(Y\)에 대한 적분이 어려워지기 때문에(intractable), 아래 두 가지 방법으로 \(p(Y\mid X)\)를 추정한다.
    <ul>
      <li>Variational Inference (optimization)</li>
      <li>Markov chain Monte Carlo (sampling)</li>
      <li>MCMC는 분포를 근사하기 위해 sampling으로 inference하는 것이고, VI는 분포를 근사하기 위해 optimization 문제로 바꾼 것이다.</li>
      <li>일반적으로 VI는 빠르고, MCMC는 정확하다.(상대적으로 그렇다는 것)</li>
    </ul>
  </li>
</ul>

<h2 id="2-variational-inference">2. Variational Inference</h2>
<ul>
  <li>The model: \(p_\theta(x)\) <br />
The data: \(\stackrel{}{D}=\left\{x_1, \ldots, x_N\right\}\) <br />
Maximum likelihood fit: \(\theta \leftarrow \operatorname{argmax}_\theta \frac{1}{N} \sum_i \log p_\theta\left(x_i\right)\) 
    <ul>
      <li>i.e. \(\theta \leftarrow \operatorname{argmax}_\theta \frac{1}{N} \sum_i \log \left(\int p_\theta\left(x_i \mid z\right) p(z) d z\right)\)</li>
      <li>i.e. \(\theta \leftarrow \operatorname{argmax}_\theta \frac{1}{N} \sum_i E_{z \sim p\left(z \mid x_i\right)}\left[\log p_\theta\left(x_i, z\right)\right]\)</li>
    </ul>
  </li>
  <li>log-likelihood \(\log p_\theta\)를 maximize : 
\(\begin{aligned}
  \log p\left(x_i\right) &amp; =\log \int p\left(x_i \mid z\right) p(z) d z \\
  &amp; =\log \int p\left(x_i \mid z\right) p(z) \frac{q_i(z)}{q_i(z)} d z \\
  &amp; =\log E_{z \sim q_i(z)}\left[\frac{p\left(x_i \mid z\right) p(z)}{q_i(z)}\right] \quad \left(\because E_{q(z)}[f(Z)]=\int f(z)q(z) dz\right) \\
  &amp; \geq E_{z \sim q_i(z)}\left[\log \frac{p\left(x_i \mid z\right) p(z)}{q_i(z)}\right] \quad (\because \text{Jensen's Inequality} : \varphi(E[X]) \geq E[\varphi(X)] (\varphi \ \text{is concave fn})) \\
  &amp; =E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]-E_{z \sim q_i(z)}\left[\log q_i(z)\right] \\
  &amp; =E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]+H\left(q_i\right) \quad (\text{where} \ H \ \text{is Entropy}) \\
  &amp; =E_{z \sim q_i(z)}\left[\log p_\theta \left(x_i, z\right)\right]+H\left(q_i\right) \\
  \\
  &amp; = \mathcal{L}_{i}\left(p, q_{i}\right)
  \end{aligned}\)</li>
  <li>위 식에서 \(E_{z \sim q_i(z)}\left[\log p\left(x_i, z\right)\right]\)은 \(q_i(z)\)가 \(p(x_i, z)\)의 density가 높은 곳에서 높은 density를 가질 때 커지고, \(H\left(q_i\right)\)는 \(q_i(z)\)가 고르게 퍼져있을 때 커진다.</li>
  <li>
    <p>위 전개식에서 부등식 앞뒤 식의 차이가 \(D_{\mathrm{KL}}\left(q_i\left(z_i\right) \| p\left(z \mid x_i\right)\right)\)가 되고, 그러므로 \(\mathcal{L}_{i}\left(p, q_{i}\right)\)를 maximize한다는 것은 \(D_{\mathrm{KL}}\left(q_i\left(z_i\right) \| p\left(z \mid x_i\right)\right)\)를 minimize한다는 것과 같다. (아래 전개식 참고)</p>

    <p><br />
\(\begin{aligned}
  D_{\mathrm{KL}}\left(q_i\left(x_i\right) \| p\left(z \mid x_i\right)\right) &amp; =E_{z \sim q_i(z)}\left[\log \frac{q_i(z)}{p\left(z \mid x_i\right)}\right]=E_{z \sim q_i(z)}\left[\log \frac{q_i(z) p\left(x_i\right)}{p\left(x_i, z\right)}\right] \\
  &amp; =-E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]+E_{z \sim q_i(z)}\left[\log q_i(z)\right]+E_{z \sim q_i(z)}\left[\log p\left(x_i\right)\right] \\
  \\
  &amp; =-E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]-\mathcal{H}\left(q_i\right)+\log p\left(x_i\right) \\
  &amp; =-\mathcal{L}_i\left(p, q_i\right)+\log p\left(x_i\right)
  \end{aligned}\)
\(\begin{aligned}
  &amp;\log p\left(x_i\right)=D_{\mathrm{KL}}\left(q_i(z) \| p\left(z \mid x_i\right)\right)+\mathcal{L}_i\left(p, q_i\right)
  \end{aligned}\)</p>
  </li>
  <li>\(\log p\left(x_i\right)\)가 고정되어 있다면, \(\mathcal{L}_i\left(p, q_i\right)\)를 maximize할 때 \(D_{\mathrm{KL}}\left(q_i(z) \| p\left(z \mid x_i\right)\right)\)가 minimize된다. <br />
(\(\mathcal{L}_i\left(p, q_i\right)\)은 ELBO이고, \(D_{\mathrm{KL}}\left(q_i(z) \| p\left(z \mid x_i\right)\right)\)은 variational distribution)</li>
  <li>이 때 학습되는 parameters는 아래와 같다.
    <ul>
      <li>\(z\)를 \(\hat x\)으로 mapping시키는 \(\theta\) (\(\theta\)는 \(\hat x\)가 \(x\)와 비슷해지도록 학습)</li>
      <li>\(z\)의 분포인 \(q_i(z)\)의 평균과 분산 (Gaussian을 가정)</li>
      <li>총 \(\mid \theta \mid +\left(\mid \mu_i\mid +\mid \sigma_i\mid \right) \times N\)개</li>
    </ul>
  </li>
</ul>

<h2 id="21-amortized-variational-inference">2.1. Amortized Variational Inference</h2>
<ul>
  <li>\(\mid \theta \mid +\left(\mid \mu_i\mid +\mid \sigma_i\mid \right) \times N\)개의 parameters는 데이터 개수가 늘어날수록 커진다는 단점이 있다.</li>
  <li>
    <p>Amortized Variational Inference는 \(q_i(z)\)가 아니라 \(q_\phi(z \mid x)=\mathcal{N}\left(\mu_\phi(x), \sigma_\phi(x)\right)\)가 \(p(x \mid z)\)와 비슷해지도록 학습한다.</p>

    <p><img src="/assets/img/stat/vi/fig2.png" alt="그림2" /></p>
  </li>
  <li>Basic Variational Inference는 sampled \(z\)로 \(\hat x\)를 만들어내는 것인데, Amortized Variational Inference는 \(x\)가 input으로 들어가면 latent vector \(z\)의 분포가 결정되고 그 분포에서 \(z\)를 sampling해서 \(\hat x\)를 만들어내기 때문에, autoencoder의 아이디어와 같다. 즉 VAE는 Amortized Variational Inference의 예시 중 하나이다.</li>
  <li>\(x\)가 input으로 들어가서 \(z\)의 분포가 결정되는 네트워크(\(\phi\))를 encoder, inference network가 되고, \(z\)로 \(\hat x\)을 만드는 네트워크(\(\theta\))를 decoder, generative network가 된다.</li>
  <li>\(p_\theta(x_i \mid z)\)를 Gaussian으로 가정한다는 것은, log를 씌웠을 때 exp 안에 있는 L2 term만 남기 때문에 \(\hat x\)과 \(x\)를 비교할 때 euclidean distance를 사용한다는 의미이다.</li>
  <li>이외에도 많은 variants of VI가 있지만 Amortized VI만 소개하는 이유는 VAE와 관련이 있기 때문이다.</li>
</ul>

<h2 id="22-mean-field-variational-inference">2.2. Mean-field Variational Inference</h2>
<ul>
  <li>Assumption : all latent variables are mutually independent (i.e. \(q(\mathbf{z})=\prod_{j=1}^m q_j\left(z_j\right) .\))</li>
  <li>Mean-field 가정을 하면 true posterior의 variables가 highly dependent인 경우에 approximation의 정확도가 다소 떨어지는 단점이 있지만, fully factorized distribution으로 계산이 간단해진다.</li>
  <li>ELBO를 maximize하는 \(q(z_i)\)들을 각각 찾고 다 곱해서 \(q(z)=q(z_1) \times ... \times q(z_M)\)을 계산하기 때문이다</li>
  <li>Mean-filed 가정을 하면 아까 봤던 식이 아래와 같이 전개된다.
\(\begin{aligned}
\mathrm{ELBO} &amp; =E_{q(z)}[\log p(x, z)-\log q(z)] \\
&amp; =E_{\prod_i q_i}\left[\log p(x, z)-\log \prod_i q_i\right] \ (\because \text{Mean-field assumption})\\
&amp; =\int \prod_i q_i\left\{\log p(x, z)-\log \prod_i q_i\right\} d z \ (\text{The definition of Expectation})\\
\\
&amp; =\int \prod_i q_i\left\{\log p(x, z)-\sum_i \log q_i\right\} d z \ (\text{Property of logarithm}) \\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int \prod_i q_i \sum_i \log q_i d z \ (\text{j번째 적분만 바깥으로 뺀 것})\\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int \prod_i q_i \log q_1 d z+\ldots \int \prod_i q_i \log q_M d z \\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int \prod_i q_i \log q_j d z+\text{(Constant)} \\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int q_j \log q_j d z_j+\text{(Constant)} \ (q_j\text{와 무관한 항들은 constant}) \\
&amp; =\int q_j E_{i \neq j}[\log p(x, z)] d z_j-\int q_j \log q_j d z_j+\text{(Constant)} \\
\\
&amp; =\int q_j \log \widetilde{p}\left(x, z_j\right) d z_j-\int q_j \log q_j d z_j+\text{(Constant)} \\
&amp; =\int q_j \log \frac{\widetilde{p}\left(x, z_j\right)}{q_j} d z_j+\text{(Constant)} \\
&amp; =-\mathrm{KL}\left[q_j \| \widetilde{p}\left(x, z_j\right)\right]+\text{(Constant)}
\end{aligned}\)</li>
  <li>위 결과로부터 \(q_j\)가 \(\tilde p(x,z_j)\)와 비슷해져야 한다는 것을 알 수 있다. 그러므로 \(q_j\)를 전개하고 normalization하면 아래와 같다. <br />
\(\begin{aligned}
q_j &amp; =\widetilde{p}\left(x, z_j\right) \\
\log q_j &amp; =\log \widetilde{p}\left(x, z_j\right) \\
\log q_j &amp; \propto E_{i \neq j}[\log p(x, z)] \\
q_j &amp; \propto \exp \left(E_{i \neq j}[\log p(x, z)]\right) \\
q_j &amp; =\frac{\exp \left(E_{i \neq j}[\log p(x, z)]\right)}{\int \exp \left(E_{i \neq j}[\log p(x, z)]\right) d z_j}
\end{aligned}\)</li>
  <li>optimal \(q^*_j\)를 알기 위해서 \(i\ne j\)에 대해 \(log\ p(x,z)\)의 expectation을 계산한다.</li>
</ul>

<h2 id="3-variational-autoencoder">3. Variational Autoencoder</h2>
<ul>
  <li>VAE는 2개의 neural network로 구성된다. 을 사용한다. (2개의 NN)
    <ul>
      <li>1) top-down generative model(=decoder) : mapping from the latent variable \(z\) to the data \(x\)</li>
      <li>2) bottom-up inference model(=encoder) : approximates the posterior \(p(z \mid x)\) (using amortized mean-field variational distribution)
<img src="/assets/img/stat/vi/fig3.png" alt="그림3" /></li>
    </ul>
  </li>
  <li>위 그림에서 나와있듯이 encoder를 거치면 deterministic하게 latent variable이 output으로 나오는 것이 아니다. output은 mean vector와 std dev vector이고, 이렇게 결정된 gaussian 분포에서 sampling을 통해 latent variable을 만든다. (VAE가 generative model인 이유이다.)</li>
  <li>Reparameterization trick : \(N(mean, std)\)에서 sampling하지 않고 \(N(0,1)\)에서 생성한 뒤 std를 곱하고 mean을 더해줌으로써 미분이 가능하도록 (backpropagation이 가능하도록) 한다.</li>
  <li>latent variable이 decoder를 거치면 input과 유사한(ideally) 새로운 데이터가 생성된다.</li>
  <li>
    <p>VAE의 loss는 다음과 같다.</p>

    <p>\(\arg \min _{\theta, \phi} \sum_i-\mathbb{E}_{q_\phi\left(z \mid x_i\right)}\left[\log \left(p\left(x_i \mid g_\theta(z)\right)\right)\right] \oplus K L\left(q_\phi\left(z \mid x_i\right) \| p(z)\right)\)</p>
    <ul>
      <li>학습 parameters는 encoder의 \(\phi\)와 decoder의 \(\theta\)이다.</li>
      <li>Reconstruction Error \(-\mathbb{E}_{q_\phi\left(z \mid x_i\right)}\left[\log \left(p\left(x_i \mid g_\theta(z)\right)\right)\right]\)
        <ul>
          <li>\(x\)가 주어졌을 때 encoder \(q_\phi\)를 지나 \(z\)생성 : \(q_\phi(z \mid x)\)</li>
          <li>그 \(z\)가 decoder \(g_\theta\)를 지나 \(x\) 생성 : \(g_\theta(z)\)</li>
          <li>이렇게 생성한 \(\hat x\)에 대한 \(x\)의 negative log-likelihood</li>
        </ul>
      </li>
      <li>Regularization Error \(K L\left(q_\phi\left(z \mid x_i\right) \| p(z)\right)\)
        <ul>
          <li>\(x\)가 주어졌을 때 encoder \(q_\phi\)를 지나 \(z\)생성 : \(q_\phi(z \mid x)\)</li>
          <li>그 \(z\)와 gaussian의 KL-divergence</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="stat" /><summary type="html"><![CDATA[Paper : Variational Inference : A Review for Statisticians Paper : Advances in Variational Inference Paper : Auto-Encoding Variational Bayes]]></summary></entry><entry><title type="html">(GAFormer) Enhancing Timeseries Transformers Through Group-Aware Embeddings</title><link href="http://localhost:4000/timeseries/2024-03-01-GAFormer/" rel="alternate" type="text/html" title="(GAFormer) Enhancing Timeseries Transformers Through Group-Aware Embeddings" /><published>2024-03-01T00:00:00+09:00</published><updated>2024-03-03T19:02:43+09:00</updated><id>http://localhost:4000/timeseries/GAFormer</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-03-01-GAFormer/"><![CDATA[<h2 id="abstract">Abstract</h2>
<ul>
  <li>Multivariate TS의 복잡한 inter-channel relationship과 dynamic shifts로 인해 Robust and generalizable representation을 학습하기 어렵다.</li>
  <li>본 논문에서 제시하는 GAFormer는 set of group tokens를 학습하고 instance-specific group embedding layer를 만든다.</li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>Multivariate TS의 temporal dynamics(temporal structure) of each channel, 그리고 relationship across channels(channel-wise structure)는 TS의 representation을 만드는 요소</li>
  <li>TS는 <strong>no predetermined ordering</strong>, 그리고 <strong>instance-specific relationships across channels and time</strong>으로 인해 position embedding을 그대로 사용하기에 적절하지 않다.</li>
  <li>본 논문에서 제시하는 GAFormer는 channel structure와 temporal structure를 통합하여 token에 ‘group embedding’한다.</li>
</ul>

<h2 id="2-method">2. Method</h2>
<ul>
  <li>Instance-specific group embeddings : grouping across different tokens, either channel-wise (spatially) or time-wise (temporally)
    <h3 id="21-group-embeddings">2.1. Group Embeddings</h3>
  </li>
  <li>Sequence of tokens : \(X=\left[\mathbf{x}_1, \ldots, \mathbf{x}_N\right] \in \mathbb{R}^{N \times D}\) (시계열의 채널, 길이와 다름)
    <ul>
      <li>\(N\) : the total # of tokens in a seq</li>
      <li>\(D\) : token dim</li>
    </ul>
  </li>
  <li>Linear weight matrix : \(W \in \mathbb{R}^{D \times K}\) project each token down to a space of \(K\) dim
    <ul>
      <li><code class="language-plaintext highlighter-rouge">operation</code> \(\operatorname{Encoder}(X) W \in \mathbb{R}^{N \times K}\)</li>
    </ul>
  </li>
  <li>그 다음 softmax : sparsify the coefficients that assign group tokens to input tokens (group awareness)
    <ul>
      <li><code class="language-plaintext highlighter-rouge">operation</code> \(\mathbb{S}(\operatorname{Encoder}(X) W)\)
        <ul>
          <li>where \(\mathbb{S}\) represents the softmax (along \((D)\) dim)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>각 tokens를 K차원으로 줄였기 때문에,  \(\mathbf{G} \in \mathbb{R}^{N \times D}\)을 곱해줄 수 있다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">operation</code> \(\operatorname{GE}(X)=\mathbb{S}(\operatorname{Encoder}(X) W) \cdot G\)</li>
    </ul>
  </li>
  <li>이제 \(X\)에 더해준다
    <ul>
      <li><code class="language-plaintext highlighter-rouge">operation</code> \(X \leftarrow X+\operatorname{GE}(X)\)</li>
    </ul>
  </li>
</ul>

<h3 id="22-gaformer-a-group-aware-spatiotemporal-transformer">2.2. GAFormer: A Group-Aware SpatioTemporal Transformer</h3>
<ul>
  <li><strong>Tokenization Layer</strong> : 시계열 \(X \in \mathbb{R}^{C \times T}\)를 P개의 패치로 잘라서 tensor \(X \in \mathbb{R}^{C \times P \times L}\)를 만든다. 그리고 <code class="language-plaintext highlighter-rouge">Token</code>이라는 encoder를 통과시키면 \(Z=\operatorname{Token}(X) \in \mathbb{R}^{C \times P \times D}\)가 된다. 이 때 channel-wise separation이 유지되고 각 channel에서의 temporal semantics는 알아낼 수 있다.</li>
  <li><strong>Spatial (Channel-Wise) Group Awareness</strong> : <code class="language-plaintext highlighter-rouge">Trans-S</code>(Transformer encoder)와 <code class="language-plaintext highlighter-rouge">SGE</code>(spatial group embedding)으로 channel-wise group embedding을 학습한다. <br />
<img src="/assets/img/timeseries/GAFormer/fig2.jpeg" alt="사진2" />
(\(Z^{\prime}=\operatorname{Trans}-\mathrm{S}\left(Z_S+\operatorname{SGE}\left(Z_S\right)\right)\)) Group embedding을 하지 않고 fixed positional embedding을 하면 두 시계열에 같은 사건이 발생했는데도 발생 시점이 다르다는 이유로 두 시계열의 structure를 다르게 학습하는데, group embedding을 하면 사건이 발생한 인접 시점들에 대해 embedding을 하기 때문에 같은 structure로 학습할 수 있다.
<img src="/assets/img/timeseries/GAFormer/fig1.jpeg" alt="사진1" /></li>
  <li><strong>Temporal Group Awareness</strong> : 먼저 dimension reduction layer \(H\)를 통과시켜 \(D\)차원 token을 \(D'\)차원 token으로 압축할 수 있다. 그리고 Spatial Group Awareness layer와 유사하게 학습한다. <br />
(\(Z^{\text {final}}=\operatorname{Trans}-\mathrm{T}\left(Z_T+\operatorname{TGE}\left(Z_T\right)\right)\)) 이렇게 학습된 \(Z^{\text {final}}\)은 linear classifier로 들어간다.</li>
</ul>

<h2 id="3-results">3. Results</h2>
<h3 id="31-an-intuitive-example--noisy-many-body-systems">3.1. An Intuitive example : Noisy many-body systems</h3>
<ul>
  <li>본 논문에서는 multivariate TS를 생성하기 위해 상호 작용하는 입자들로 구성된 many-body system의 궤적을 기반으로 한 실험 결과를 제시한다.</li>
  <li>시스템의 총 에너지를 분류하여, 고에너지 시스템인지 저에너지 시스템인지를 결정하는 것인데, 실험의 복잡성을 증가시키기 위해 상호 작용하지 않는 무관한 body들이 시스템을 오염시키는 상황을 가정했다.</li>
  <li>3가지의 embedding 방식을 실험했다.
    <ul>
      <li>1) learnable positional embedding</li>
      <li>2) parameter-free sin-cos positional embedding</li>
      <li>3) Group embedding</li>
    </ul>
  </li>
  <li>3가지의 setting을 실험했다.
    <ul>
      <li>1) Stable : the relative position of object(channels) never shifts</li>
      <li>2) Shuffle : the observed objects could be in any position and are randomized similarly</li>
      <li>3) Biased : the observed objects have different position that are randomly sampled from non-overapping set</li>
    </ul>
  </li>
  <li>실험 결과 Group embedding은 channel mismatch와 distribution shifts가 있을 때 다른 embedding보다 robust했다.
<img src="/assets/img/timeseries/GAFormer/fig3.jpeg" alt="사진3" />
    <h3 id="32-time-series-classification-tasks">3.2. Time series Classification tasks</h3>
  </li>
  <li>table1, table2 : TGE(temporal dimension embedding)에 Group embedding을 했을 때 classification 성능이 향상된다.
<img src="/assets/img/timeseries/GAFormer/table1.jpeg" alt="사진3" />
<img src="/assets/img/timeseries/GAFormer/table2.jpeg" alt="사진4" />
    <h3 id="33-classification-and-regression-tasks-on-neural-recordings">3.3. Classification and Regression tasks on Neural Recordings</h3>
    <p><img src="/assets/img/timeseries/GAFormer/table3.jpeg" alt="사진5" /></p>
    <h3 id="34-ablation-studies">3.4. Ablation Studies</h3>
  </li>
  <li>table4 :  temporal group embedding 또는 spatial group embedding 둘 중 하나만 적용하거나 둘 다 적용한 결과 둘 다 성능 향상에 필요하다.
<img src="/assets/img/timeseries/GAFormer/table4.jpeg" alt="사진6" /></li>
</ul>

<h2 id="4-related-work">4. Related Work</h2>
<h2 id="5-discussion">5. Discussion</h2>
<ul>
  <li>본 논문에서는 TS의 group-level structure를 다루는 새로운 프레임워크를 제안하였다.</li>
  <li>Group embedding은 group token across channel and temporal dimension을 학습해서 representation space로 보낸다.</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[ICLR 2024](https://openreview.net/forum?id=c56TWtYp0W)]]></summary></entry><entry><title type="html">(iTransformer) Inverted Transformers are Effective for Time Series Forecasting</title><link href="http://localhost:4000/timeseries/2024-02-23-iTransformer/" rel="alternate" type="text/html" title="(iTransformer) Inverted Transformers are Effective for Time Series Forecasting" /><published>2024-02-23T00:00:00+09:00</published><updated>2024-03-06T17:11:13+09:00</updated><id>http://localhost:4000/timeseries/iTransformer</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-02-23-iTransformer/"><![CDATA[<h2 id="abstract">Abstract</h2>
<ul>
  <li>Transformer-based TS : larger lookback \(\to\) performance degradation &amp; computation explosion.</li>
  <li>iTransformer : attention과 feed-forward network(FFN)를 inverted dimension에서 적용
<img src="/assets/img/timeseries/iTransformer/fig2'.jpeg" alt="사진1" class="lead" width="00" height="100" /></li>
  <li>각 time point가 token이 되는 것이 아니라 각 series(variate)가 token이 된다.</li>
  <li>Inverted dimension만 다르고 이외의 Transformer의 components는 수정 없이 그대로 사용한다.</li>
</ul>

<h2 id="1-introduction">1. introduction</h2>
<ul>
  <li>Transformer가 다른 fields에서는 linear model보다 성능이 좋은데, multivariate ts forecasting에서는 not sutable하다. <br />
(특히 time points 사이에 semantic 관계보다 numerical 관계가 강한 경우에는 그냥 simple linear layer의 성능이 더 좋았다.)</li>
  <li>그 이유는 한 시점에 기록된 서로 다른 변수들의 값들이 하나의 token으로 기록되기 때문이다. 논문에서는 아래처럼 표현하고 있다. <br />
(= embed multiple variates of the same timestamp into indistinguishable channels…) <br />
(= the points of the same time step that represent different physical meanings recorded by inconsistent mesurements are embedded into one token …)</li>
  <li>이러한 single time step의 token 형태는 receptive field가 너무 좁아서 유용한 정보를 얻어내기가 어렵다.</li>
  <li>
    <p>또한 시계열은 데이터의 순서가 중요한데, transformer는 permutation-invariant attention mechanism이라서 temporal dimension을 잘 잡지 못한다.</p>
  </li>
  <li>그래서 iTransformer는 각각의 variate를 독립적으로 token으로 embedding해서 receptive field를 늘려준다.(Patching의 extreme case)</li>
  <li>그러면 token은 series의 global representation을 통합해서 variate-centric하다.</li>
  <li>FFN은 개별 변수에 대해 인코딩된 lookback series를 보고 예측할 수 있을 정도의 generalizable representation을 학습할 수 있다.</li>
  <li>본 논문의 contribution은 아래와 같다.
    <ul>
      <li>Transformer가 비효과적인 것이 아니라 아직 underexplored라서 잘못 사용되었으니 component를 개선한다.</li>
      <li>독립적인 개별 시계열을 token으로 간주하여 self-attention으로 multivariate correlations를 파악하고, FFN으로 forecasting을 위한 series-global representation을 학습한다.</li>
    </ul>
  </li>
</ul>

<h2 id="2-related-work">2. Related Work</h2>
<ul>
  <li>TCN-based, RNN-base forecasters를 지나서 Transformer가 시퀀스 모델링과 확장 가능성으로 좋은 성능을 보여주며 많은 variant가 나왔다.</li>
  <li>Transformer의 variant는 component를 수정하는지, architecture를 수정하는지에 따라 4가지로 구분된다.
<img src="/assets/img/timeseries/iTransformer/fig3.jpeg" alt="사진2" />
    <ul>
      <li>1) Temporal dependency 모델링을 위한 attention module 수정 (Component adaptation)</li>
      <li>2) Linear model이 떠오르면서, transformer에서도 component나 architecture를 바꾸지 않고 Stationarization, Channel independence, Patching 등을 통해 효율적으로 성능 향상</li>
      <li>3) Transformer의 component와 architecture를 모두 수정하여 multivariate의 cross-time and cross-variate dependency를 파악</li>
      <li>4) iTransformer는 Transformer의 component는 그대로 가져오지만 inverted하게 가져온다. (architecture만 바뀜)</li>
    </ul>
  </li>
</ul>

<h2 id="3-itransformer">3. ITransformer</h2>
<ul>
  <li>현실 시나리오에서는 각각의 variate마다 발생 시점과 기록 시점의 delay 정도가 다를 수 있기 때문에 시점 \(t\)에서 모든 variates가 관측되지 않을 수도 있다. 뿐만 아니라 각각의 variate마다 통계적 분포 자체가 다를 수도 있다.</li>
</ul>

<h3 id="31-structure-overview">3.1. Structure Overview</h3>
<ul>
  <li><img src="/assets/img/timeseries/iTransformer/fig4.png" alt="사진3" /></li>
  <li>iTransformer는 Transformer의 encoder-only architecture (including the embedding, projection, and Transformer blocks)</li>
  <li><strong>Embedding the whole series as the token</strong> : 한 시점에서 많은 변수들을 하나의 token으로 간주하면 attention map을 학습하기 어렵다는 것은 patching으로 respective field를 늘리는 방식들이 좋은 성능을 낸다는 것으로부터 알 수 있다. 그러므로 each time series가 token이 되어 해당 변수의 properties를 다루고, self-attention으로 mutual interactions를, feed-forward networks로 series representations를 처리한다.</li>
  <li>iTransformer가 예측하는 future series \(\hat{\mathbf{Y}}_{:, n}\) based on \(\mathbf{X}_{:, n}\)의 formula :
<img src="/assets/img/timeseries/iTransformer/formula1.png" alt="사진4" />
    <ul>
      <li>\(\mathbf{H}=\left\{\mathbf{h}_1, \cdots, \mathbf{h}_N\right\} \in \mathbb{R}^{N \times D}\)은 \(D\)차원의 embedded tokens \(N\)개이고 \(h\)의 아래첨자는 layer index이다.</li>
      <li>Embedding \(\mathbb{R}^T \mapsto \mathbb{R}^D\)과 Projection \(\mathbb{R}^D \mapsto \mathbb{R}^S\)는 MLP가 한다.</li>
      <li>Inverted dimension으로 sequence의 순서가 FFN에 저장되므로 position embedding이 더이상 필요하지 않다.</li>
    </ul>
  </li>
  <li><strong>iTransformers</strong> : Attention에 multivariate correlation 외에는 requirements가 없어서 variates가 많아질 때 효율적이다. 또한 training과 inference에서 token의 개수가 다를 수 있어서 variates의 개수에 대해 유연한 모델이다.</li>
</ul>

<h3 id="32-inverted-transformer-components">3.2. Inverted Transformer Components</h3>
<ul>
  <li><strong>Layer normalization</strong> : Layer normalization은 훈련할 때 convergence speed and stability를 위한 것이다. 기존 Transformer에서는 한 시점에서 multivariate representation을 normalize했었는데, non-causal이나 앞서 언급한 delay를 고려하면 interaction noise의 원인이 될 수 있다. 그러므로 개별 variate를 normalize한다. 그러면 measurements(=variates, sensor, series)끼리의 불일치성도 해소된다.
\(\text { LayerNorm }(\mathbf{H})=\left\{\left.\frac{\mathbf{h}_n-\operatorname{Mean}\left(\mathbf{h}_n\right)}{\sqrt{\operatorname{Var}\left(\mathbf{h}_n\right)}} \right\rvert\, n=1, \cdots, N\right\}\)</li>
  <li><strong>Feed-Forward network</strong> : 각각의 variate token을 FFN에 태우면 universal approximation therem(Hornik, 1991)에 의해 시계열의 복잡한 representation을 추출할 수 있다. 이러한 inverted blocks를 쌓으면 observed를 encoding하고 future series를 decoding하는 과정을 <a href="/timeseries/2024-02-16-DLinear">MLP</a>처럼 할 수 있다. (MLP 방식은 시계열의 amplitude, periodicity, frequency spectrums까지 학습할 수 있고, time point self-attention보다도 좋은 성능을 낼 수 있다.)</li>
  <li><strong>Self-attention</strong> : Inverted dimenstion으로 self-attention을 계산하면 \(Q, K, V \in \mathbf R^{N \times d_k}\)를 linear projection으로 구한다. 사전에 feature-dimension으로 normalize를 해놓았으니 pre-Softmax score \(\mathbf{A}_{i, j}=\left(\mathbf{Q} \mathbf{K}^{\top} / \sqrt{d_k}\right)_{i, j} \propto \mathbf{q}_i^{\top} \mathbf{k}_j\)는 variate-wisecorrelation을 의미하고, whole score map \(\mathbf{A} \in \mathbb{R}^{N \times N}\)는 multivariate correlations btw paired variate tokens가 된다.</li>
</ul>

<h2 id="4-experiments">4. Experiments</h2>

<h3 id="41-forecasting-results">4.1. Forecasting Results</h3>
<ul>
  <li>7개의 데이터셋 사용(ECL, ETT, Exchange, Traffic, Weather, Solar-Energy, PEMS), 10개의 forecasting models과 비교
    <ul>
      <li>Transformer-based : Autoformer, FEDformer, Stationary, Crossformer, PatchTST</li>
      <li>Linear-based : DLinear, TiDE, RLinear</li>
      <li>TCN-based : SCINet, TimesNet
<img src="/assets/img/timeseries/iTransformer/table1.png" alt="사진5" /></li>
    </ul>
  </li>
  <li>SOTA였던 PatchTST는 변동이 심한 PEM 데이터를 처리하기 어렵고, 명시적으로 multivariate correlation을 파악하는 Crossformer보다 iTransformer의 성능이 뛰어나다.</li>
</ul>

<h3 id="42-itransformer-generality">4.2. ITransformer Generality</h3>
<ul>
  <li><strong>Performance promotion</strong>
<img src="/assets/img/timeseries/iTransformer/table2.png" alt="사진6" />
    <ul>
      <li>Transformer-based models에 inverted framework를 적용하여 성능을 비교한 결과 일관되게 성능이 향상되었다.</li>
    </ul>
  </li>
  <li><strong>Variate generalization</strong>
<img src="/assets/img/timeseries/iTransformer/fig5.png" alt="사진7" />
    <ul>
      <li>데이터의 20%만으로 training을 하더라도 100%로 training을 했을 때에 비해서 성능에 큰 차이가 없다는 것은 iTransformer가 효율적으로 훈련할 수 있는 모델임을 의미한다. 즉 unseen variates에 대해 generalization capability가 뛰어나다. 그 이유는 1) 각 variate를 token으로 embedding하니 variate의 개수에 제한이 없어지기 때문이고, 2) FFN이 각 token에 identically하게 적용되어 어떤 time series에서든 존재하는 본질적인 패턴을 학습할 수 있기 때문이다.</li>
    </ul>
  </li>
  <li><strong>Increasing lookback length</strong>
<img src="/assets/img/timeseries/iTransformer/fig6.png" alt="사진8" />
    <ul>
      <li>Transformer-based models는 look-back window가 길어져도 성능 향상으로 이어지지 않았지만, inverted framework는 look-back window가 길어지면 성능이 향상된다.</li>
    </ul>
  </li>
</ul>

<h3 id="43-model-analysis">4.3. Model Analysis</h3>
<ul>
  <li><strong>Ablation Study</strong>
<img src="/assets/img/timeseries/iTransformer/table3.png" alt="사진9" />
    <ul>
      <li>Time series의 multivariate correlation(Variate)와 series representation(Temporal)을 학습하기 위해 Attention을 FFN으로 바꿔도 보고 아예 안써보기도 하면서 iTransformer가 가장 좋은 성능을 낸다는 것을 확인하였다.</li>
    </ul>
  </li>
  <li><strong>Analysis of multivariate Representations and Correlations</strong>
<img src="/assets/img/timeseries/iTransformer/fig7.png" alt="사진10" />
    <ul>
      <li>The centered kernel alignment (CKA)는 높을수록 similar representation을 의미하는데, inverted frameworks가 유의미하게 높다.</li>
      <li>또한 얕은 layer의 attention map은 input series와 상관관계가 높고, 깊은 layer의 attention map은 future series와 상관관계가 높다는 점에서 interpretable attention이다.</li>
    </ul>
  </li>
  <li><strong>Efficient training strategy</strong>
<img src="/assets/img/timeseries/iTransformer/fig8.png" alt="사진11" />
    <ul>
      <li>각 배치에서 변수의 일부만 사용하여 훈련하더라도 MSE가 안정적이고, sample ratio가 낮아짐에 따라 memory가 적게 사용되므로 효율적인 모델이라 할 수 있다.</li>
    </ul>
  </li>
</ul>

<h2 id="5-conclusion-and-future-work">5. Conclusion and Future work</h2>
<ul>
  <li>iTransformer는 각 series를 variate token으로 보고 multivariate correlation을 파악하기 위해 attention과 FFN을 사용하였다.</li>
  <li>실험 결과를 통해 기존 Transformer-based time series forecasters보다 뛰어날 뿐만 아니라 interpretable한 성능을 보여주었다.</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[ICLR 2024](https://arxiv.org/abs/2310.06625)]]></summary></entry><entry><title type="html">FITS: Modeling Time Series with 10k Parameters</title><link href="http://localhost:4000/timeseries/2024-02-22-FITS/" rel="alternate" type="text/html" title="FITS: Modeling Time Series with 10k Parameters" /><published>2024-02-22T00:00:00+09:00</published><updated>2024-03-03T18:59:39+09:00</updated><id>http://localhost:4000/timeseries/FITS</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-02-22-FITS/"><![CDATA[<h2 id="abstract">Abstract</h2>

<ul>
  <li>FITS(Frequency Interpolation Time Series)라는 lightweight yet powerful model 제안</li>
  <li>Raw time domain이 아니라 complex frequency domain에서 interpolation</li>
  <li>10k개의 parameters만 사용</li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>

<ul>
  <li>Time series domain에서는 시계열의 complexity와 dynamism 때문에 sparse and scattered하다.</li>
  <li>Frequency domain에서 time series를 representation하면 compact and efficient하다.</li>
  <li>Forecasting : simply extending the given look-back window with frequency interpolation</li>
  <li>Reconstruction : recover the original segment by interpolating the frequency representation of its downsampled counterpart</li>
  <li>FITS의 핵심은 <strong>complex-valued linear layer</strong> : amplitude scaling과 phase shift를 학습하여 complex domain에서 interpolation을 가능하게 한다.</li>
  <li>FITS의 <strong>low-pass filter</strong>를 통해 핵심적인 정보는 보존하면서 압축적인 정보를 representation한다.</li>
</ul>

<h2 id="2-related-work-and-motivation">2. Related Work and Motivation</h2>

<h3 id="21-frequency-aware-time-series-analysis-models">2.1. Frequency-Aware Time Series Analysis Models</h3>

<ul>
  <li>Frequency domain에서 시계열의 pattern을 잡으려는 시도 (FNet(2022), FEDFormer(2022), FiLM(2022), …)</li>
  <li>시계열의 periodicity(주기성)을 잡는 것도 중요 (DLinear(2023), TimesNet(2023))</li>
  <li>하지만 여전히 데이터 전처리를 포함하는 feature engineering에 의존하는 면이 있다.</li>
</ul>

<h3 id="22-divide-and-conquer-the-frequency-components">2.2. Divide and Conquer the Frequency Components</h3>

<ul>
  <li>Time series를 signal로 이해한다면 ?
    <ul>
      <li>시계열을 linear combination of sinusoidal components로 쪼갤 수 있다. (정보 손실 없이 !)</li>
      <li>그러면 sinusoidal waves에 phase bias만 추가해주면 예측값이 되니까 매우 간단해진다.</li>
    </ul>
  </li>
  <li>하지만 time domain에서 sinusoidal component를 예측하는 일은 어려우니 frequency domain에서 한다면 정보 손실도 없고 compact하다.</li>
</ul>

<h2 id="3-method">3. Method</h2>

<h3 id="31-preliminary--fft-and-complex-frequency-domain">3.1. Preliminary : FFT and Complex Frequency Domain</h3>

<ul>
  <li><strong>FFT(Fast Fourier Transform)</strong> : DFT(Discrete Fourier Transform)을 빠르게 계산, DFT는 discrete-time signals을 time domain에서 frequency domain으로 보내는 방법이다. (\(N\)개의 real numbers \(\to\) \(\frac{N}{2}+1\)개의 complex numbers)</li>
  <li><strong>Complex Frequency Domain</strong> : complex frequency는 signal의 representation인데, 각각의 frequency에 있는 complex number가 amplitude(magnitude or strength)와 phase(temporal shift or delay)를 파악한다.</li>
  <li>Complex number : \(X(f) = \mid X(f)\mid e^{j \theta (f)}\)
    <ul>
      <li>\(X(f)\) : frequency에서 component의 complex number</li>
      <li>\(\mid X(f)\mid\). : component의 amplitude</li>
      <li>\(e^{j \theta(f)}\) : component의 phase</li>
      <li>\(X(f)\)는 length가 amplitude이고 angle이 phase인 벡터로 visualize된다.</li>
      <li>다시 표현하면 \(X(f)=\mid X(f)\mid (\cos \theta(f)+j \sin \theta(f))\)</li>
      <li><img src="/assets/img/timeseries/FITS/fig1.png" alt="사진1" /></li>
    </ul>
  </li>
  <li><strong>Time Shift and Phase Shift</strong> : Time shift는 phase shift와 같다. 즉 unit complex exponential element를 곱하는 것과 같다. 예를 들어 만약 \(\tau\)만큼 time shift했다면(\(x(t-\tau)\)), Fourier transform은 \(X_\tau (f)=e^{-j 2 \pi f \tau } X(f)=\mid X(f)\mid e^{j(\theta(f)-2 \pi f \tau)}=[\cos (-2 \pi f \tau)+j \sin (-2 \pi f \tau)] X(f)\)이 된다. Amplitude는 변하지 않았고 phase만 \(\theta_\tau(f)=\theta(f)-2 \pi f \tau\)만큼 변했다. (time shift에 대해 linear)</li>
  <li>결론적으로, amplitude scaling과 phase shifting은 multiplication of complex numbers와 같다. (fig1)</li>
</ul>

<h3 id="32-fits-pipeline">3.2. FITS Pipeline</h3>

<ul>
  <li>Time series가 길수록 higher frequency resolution이 되기 때문에, 시계열의 frequency representation을 interpolate한다는 말은 = 시계열을 extend한다는 말과 같다. (시계열이 길어지면 더 작은 간격의 주파수로 변환될 수 있다는 걸 반대로 생각하면 된다.)</li>
  <li><img src="/assets/img/timeseries/FITS/fig2.png" alt="사진2" /></li>
  <li>FITS의 low-pass filter(LPF)는 말 그대로 낮은 주파수만 pass시키고 high-frequency components는 제거한다. 시계열의 essential한 정보, coarse한 정보는 남기고 fine한 정보는 제거하여 모델을 가볍게 만든다. (주기가 큰 파동만 남고 주기가 작아서 노이즈에 가까운 파동은 제거한다.)</li>
  <li><strong>Forecasting</strong> : 모델은 frequency interpolation을 통해 look-back window를 늘릴 수 있고(논문에서는 <code class="language-plaintext highlighter-rouge">extending</code>, <code class="language-plaintext highlighter-rouge">generate</code>, <code class="language-plaintext highlighter-rouge">reconstruct</code>로 표현하고 있다.) forecasting results가 된다.</li>
  <li><strong>Reconstruction</strong> : 우리는 원본 시계열을 downsampling했다가 reconstruction하게 되는데, downsampling된 segment를 원래 형태로 되돌릴 때 FITS가 사용된다. (frequency interpolation)</li>
</ul>

<h3 id="33-key-mechanisms-of-fits">3.3. Key Mechanisms of FITS</h3>

<ul>
  <li><strong>Complex Frequency Linear Interpolation</strong> : 모델의 output의 length를 조절해주기 위해서 interpolation rate를 일정하게 만들어준다. 원본 시계열의 절반 길이가 되는 frequency domain에서 interpolation을 하는데 output의 길이를 \(L_o\)로 맞춰주기 위해서는 \(\eta_{f r e q}=\frac{L_o / 2}{L_i / 2}=\frac{L_o}{L_i}=\eta\)가 되어야 한다.</li>
  <li><strong>Low Pass Filter(LPF)</strong> : 아래 그림처럼 frequency domain에서 high-frequency component에 해당하는 75%를 버리더라도 원래 시계열의 structure와 periodicity를 잘 보존한다. 왜냐하면 high-frequency component는 주기가 매우 짧은 성분들이라 노이즈에 가깝고 애초에 모델이 학습할 수 있는 영역 밖이라고 할 수 있기 때문이다.</li>
  <li><img src="/assets/img/timeseries/FITS/fig3.png" alt="사진3" /></li>
  <li><strong>Weight Sharing</strong> : 한 데이터셋 내에서 channels는 base frequency가 비슷하고 그러면 sharing weights로 효율적으로 multivariate task를 수행할 수 있다. 만약 채널마다 base frequency가 다르더라도 채널들을 클러스터링 해서 클러스터마다 개별적으로 학습하면 된다.</li>
</ul>

<h2 id="4-experiments-for-forecasting">4. Experiments for Forecasting</h2>

<h3 id="41-forecasting-as-frequency-interpolation">4.1. Forecasting as Frequency Interpolation</h3>

<ul>
  <li>일반적으로 look-back window의 길이 \(L\)이 forecasting horizon의 길이 \(H\)보다 기니까 단순하게 interpolation하기보다는 interpolation rate를 \(\eta_{\text {Fore }}=1+\frac{H}{L}\)로 한다.</li>
  <li><img src="/assets/img/timeseries/FITS/table12.png" alt="사진4" /></li>
</ul>

<h2 id="5-experiments-for-anomaly-detection">5. Experiments for Anomaly Detection</h2>

<ul>
  <li><img src="/assets/img/timeseries/FITS/table6.png" alt="사진5" /></li>
</ul>

<h2 id="6-conclusion">6. Conclusion</h2>

<ul>
  <li>Frequency interpolation으로 10k개의 parameters만으로 SOTA의 성능을 냈다.</li>
  <li>Future work : frequency domain에서의 large-scale complex-valued NN (ex. Complex-valued Transformer)</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[ICLR 2023](https://arxiv.org/abs/2307.03756)]]></summary></entry><entry><title type="html">\(2\). Geometric diatance (QGIS)</title><link href="http://localhost:4000/project/2024-02-21-prop2/" rel="alternate" type="text/html" title="\(2\). Geometric diatance (QGIS)" /><published>2024-02-21T00:00:00+09:00</published><updated>2024-03-03T18:54:12+09:00</updated><id>http://localhost:4000/project/prop2</id><content type="html" xml:base="http://localhost:4000/project/2024-02-21-prop2/"><![CDATA[<h2 id="1-shapefile-다운로드">1. Shapefile 다운로드</h2>
<ul>
  <li>지도에 두 주소 또는 좌표를 입력했을 때 출력되는 geometric distance를 구하려면 패키지가 아닌 지리 API를 활용해야 한다. 여기서는 <a href="https://qgis.org/en/site/forusers/download.html">QGIS</a>를 사용한다.</li>
  <li><code class="language-plaintext highlighter-rouge">서울시 도로망 layer</code>, <code class="language-plaintext highlighter-rouge">(지하철역, 버스정류장, 학교) layer</code>, 그리고 <code class="language-plaintext highlighter-rouge">아파트 layer</code>를 깔고 <strong>네트워크 분석</strong>을 진행할 것이다.</li>
  <li><code class="language-plaintext highlighter-rouge">서울시 도로망 layer</code>는 <a href="https://www.openstreetmap.org">OpenStreetMap</a>의 지도 정보를 추출해야 하는데, 3가지의 extractor가 있다.
    <ul>
      <li>1) <a href="https://download.geofabrik.de">Geofabrik</a>에서 sub region 지정
        <ul>
          <li>가장 하위 sub region이 South Korea이다. 즉 서울만 선택하는 것이 불가능하다.</li>
        </ul>
      </li>
      <li>2) <a href="https://extract.bbbike.org">BBBike</a>에서 region search (특정 도시 직접 search 가능)
        <ul>
          <li>특정 도시를 직접 search 가능하다. shp파일이 필요하므로 Shapefile을 선택하고 extract한다.</li>
        </ul>
      </li>
      <li>3) <a href="https://www.vworld.kr/v4po_main.do">국가공간정보포털(브이월드)</a>
        <ul>
          <li><code class="language-plaintext highlighter-rouge">공간정보 다운로드</code> \(\to\) <code class="language-plaintext highlighter-rouge">오픈마켓</code> \(\to\) <code class="language-plaintext highlighter-rouge">(도로명주소)도로구간</code>에서 지역별 도로 shp파일을 수집할 수 있다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>2) BBBike 또는 3) 국가공간정보포털을 선택하면 되는데, 2)를 선택했다.
    <ul>
      <li><img src="/assets/img/project/prop/prop2_1.png" alt="사진1" /></li>
      <li>왼쪽(국가공간정보포털)은 서울시에 포함되는 정확한 Node와 Link를 제공하지만, Node와 Link가 있어도 지나갈 수 없는 길 많다. 그래서 실제로 갈 수 있는 경로임에도 경로를 찾지 못하는 경우가 많다.</li>
      <li>오른쪽(BBBike)는 Node와 Link가 있어도 지나갈 수 없는 길이 훨씬 적지만, 실제와 다른 Link가 존재한다. (ex. 중앙에서 우측 하단으로 길게 그려진 직선)</li>
    </ul>
  </li>
</ul>

<h2 id="2-qgis-layer-추가">2. QGIS Layer 추가</h2>
<ul>
  <li>이제 QGIS를 실행한다. 기본 설정으로 <code class="language-plaintext highlighter-rouge">보기</code> \(\to\) <code class="language-plaintext highlighter-rouge">패널</code>에서 탐색기, 레이어, 공간 처리 툴박스를 선택한다.</li>
  <li><code class="language-plaintext highlighter-rouge">Z_KAIS_TL_SPRD_MANAGE_11000.shp</code>를 레이어로 추가한다. (<code class="language-plaintext highlighter-rouge">레이어</code> \(\to\) <code class="language-plaintext highlighter-rouge">레이어 추가</code> \(\to\) <code class="language-plaintext highlighter-rouge">벡터 레이어 추가</code> \(\to\) <code class="language-plaintext highlighter-rouge">*.shp 선택</code>하면 되는데 그냥 드래그해도 된다.)</li>
  <li>그리고 그 위에 미리 수집해놓은 지하철역 좌표를 레이어로 추가한다. 경도와 위도가 있는 csv파일이어야 한다. (<code class="language-plaintext highlighter-rouge">레이어</code> \(\to\) <code class="language-plaintext highlighter-rouge">레이어 추가</code> \(\to\) <code class="language-plaintext highlighter-rouge">구분자로 분리된 텍스트 레이어 추가</code> \(\to\) <code class="language-plaintext highlighter-rouge">지하철역.csv 파일 선택</code>)</li>
  <li><img src="/assets/img/project/prop/prop2_2.png" alt="사진2" /></li>
  <li>추가적으로 수집한 데이터(버스정류장, 학교 등)가 있다면 같은 방식으로 추가하면 되겠다.</li>
</ul>

<h2 id="3-최단경로-찾기">3. 최단경로 찾기</h2>
<ul>
  <li>우측 <code class="language-plaintext highlighter-rouge">공간 처리 툴박스</code> \(\to\) <code class="language-plaintext highlighter-rouge">네트워크 분석</code> \(\to\) <code class="language-plaintext highlighter-rouge">최단경로</code>를 선택하면 된다. <code class="language-plaintext highlighter-rouge">포인트에서 포인트</code>는 <code class="language-plaintext highlighter-rouge">ex.집에서 학교까지</code>이고, <code class="language-plaintext highlighter-rouge">포인트에서 레이어</code>는 <code class="language-plaintext highlighter-rouge">ex.집에서 모든 지하철역들까지</code>이다.</li>
  <li>네트워크 레이어, 시작점(출발지) 레이어, 그리고 종단 레이어를 지하철역으로 선택한다.</li>
  <li><img src="/assets/img/project/prop/prop2_3.png" alt="사진3" /></li>
  <li>연세대학교 정문(point)에서 모든 지하철역(layer)로 가는 최단거리를 표시했다. <code class="language-plaintext highlighter-rouge">레이어</code> \(\to\) <code class="language-plaintext highlighter-rouge">속성 테이블 열기</code>에서 cost가 낮은 순서대로 정렬하면 가까운 지하철역을 정렬할 수 있다.</li>
</ul>

<h2 id="4-최단경로-excel에-저장하기">4. 최단경로 excel에 저장하기</h2>
<ul>
  <li>좌측 하단 <code class="language-plaintext highlighter-rouge">레이어</code> 패널에서 <code class="language-plaintext highlighter-rouge">최단 경로</code>를 우클릭 후, export를 누르면 최단경로의 속성 테이블을 원하는 형태(ex. *.xlsx)로 추출할 수 있다.</li>
  <li><img src="/assets/img/project/prop/prop2_4.png" alt="사진4" /></li>
</ul>

<p>to be continued…</p>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="project" /><summary type="html"><![CDATA[1. Shapefile 다운로드 지도에 두 주소 또는 좌표를 입력했을 때 출력되는 geometric distance를 구하려면 패키지가 아닌 지리 API를 활용해야 한다. 여기서는 QGIS를 사용한다. 서울시 도로망 layer, (지하철역, 버스정류장, 학교) layer, 그리고 아파트 layer를 깔고 네트워크 분석을 진행할 것이다. 서울시 도로망 layer는 OpenStreetMap의 지도 정보를 추출해야 하는데, 3가지의 extractor가 있다. 1) Geofabrik에서 sub region 지정 가장 하위 sub region이 South Korea이다. 즉 서울만 선택하는 것이 불가능하다. 2) BBBike에서 region search (특정 도시 직접 search 가능) 특정 도시를 직접 search 가능하다. shp파일이 필요하므로 Shapefile을 선택하고 extract한다. 3) 국가공간정보포털(브이월드) 공간정보 다운로드 \(\to\) 오픈마켓 \(\to\) (도로명주소)도로구간에서 지역별 도로 shp파일을 수집할 수 있다. 2) BBBike 또는 3) 국가공간정보포털을 선택하면 되는데, 2)를 선택했다. 왼쪽(국가공간정보포털)은 서울시에 포함되는 정확한 Node와 Link를 제공하지만, Node와 Link가 있어도 지나갈 수 없는 길 많다. 그래서 실제로 갈 수 있는 경로임에도 경로를 찾지 못하는 경우가 많다. 오른쪽(BBBike)는 Node와 Link가 있어도 지나갈 수 없는 길이 훨씬 적지만, 실제와 다른 Link가 존재한다. (ex. 중앙에서 우측 하단으로 길게 그려진 직선)]]></summary></entry><entry><title type="html">\(1\). 데이터 수집 및 전처리</title><link href="http://localhost:4000/project/2024-02-20-prop1/" rel="alternate" type="text/html" title="\(1\). 데이터 수집 및 전처리" /><published>2024-02-20T00:00:00+09:00</published><updated>2024-03-03T18:54:12+09:00</updated><id>http://localhost:4000/project/prop1</id><content type="html" xml:base="http://localhost:4000/project/2024-02-20-prop1/"><![CDATA[<h2 id="11-데이터-수집">1.1. 데이터 수집</h2>
<p><img src="/assets/img/project/prop/prop1_1.png" alt="사진1" /></p>
<ul>
  <li>아파트 매매 데이터는 <a href="https://rt.molit.go.kr/pt/xls/xls.do?mobileAt=">국토교통부 실거래가 공개시스템</a>에서 다운로드하였다.</li>
</ul>

<p><img src="/assets/img/project/prop/prop1_2.png" alt="사진2" /></p>
<ul>
  <li>아파트의 위치, 면적, 층, 매매가격 정도를 알 수가 있다. 부동산 분석을 위해서는 주변 정보도 수집할 필요가 있는데, 1.3.에서 포스팅한다.</li>
</ul>

<h2 id="12-좌표-변환--geocode">1.2. 좌표 변환 : Geocode</h2>
<ul>
  <li>Google Geocode를 활용하여 주소를 경도, 위도 좌표계로 변환하였다. 구글 spreadsheets에서 파일을 열고, 확장 프로그램에서 Geocode by Awesome Table을 다운받아 확장프로그램 \(\to\) Start Geocoding을 실행하였다.
<img src="/assets/img/project/prop/prop1_3.png" alt="사진3" /></li>
  <li>그러면 아래 사진처럼 Latitude와 Longitude 열이 생기면서 주소에 해당하는 좌표가 자동으로 입력된다. 다만 속도가 빠르지 않다는 점, Geocode premium을 사용하지 않으면 사용량에 제한이 있다.
<img src="/assets/img/project/prop/prop1_4.png" alt="사진4" /></li>
  <li>Geocode 중복 사용량을 없애기 위해서 같은 아파트의 여러 매매에 대해 매번 좌표를 계산하지 않도록, 아파트에 대해 unique하게 좌표를 계산하고 다시 merge하여 사용량을 1.2%로 줄였다.
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">2013년 ~ 2023년 거래된 아파트의 수 : </span><span class="sh">"</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">add20u</span><span class="p">))</span>
<span class="mi">2013</span><span class="n">년</span> <span class="o">~</span> <span class="mi">2023</span><span class="n">년</span> <span class="n">거래된</span> <span class="n">아파트의</span> <span class="n">수</span> <span class="p">:</span>  <span class="mi">9166</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">2013년 ~ 2023년 거래건수: </span><span class="sh">"</span><span class="p">,</span> <span class="nf">all_len</span><span class="p">(</span><span class="n">apt20</span><span class="p">))</span>
<span class="mi">2013</span><span class="n">년</span> <span class="o">~</span> <span class="mi">2023</span><span class="n">년</span> <span class="n">거래건수</span><span class="p">:</span>  <span class="mi">822029</span>
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="13-주변-정보-수집">1.3. 주변 정보 수집</h2>
<ul>
  <li>부동산 분석을 위해서는 다양한 요인이 고려되어야겠지만, 그 중 하나가 주변 정보이다. 아파트의 주변에 지하철역이 있는지, 초/중/고등학교가 있는지 등등이다. 일단은 지하철역, 버스정류장, 학교의 위치를 수집하였다.</li>
  <li>수도권 지하철역 위치 : <a href="https://gaussian37.github.io/python-etc-수도권-지하철/">JINSOL KIM님 Blog</a></li>
  <li>서울시 버스정류장 위치 : <a href="https://topis.seoul.go.kr">서울시 교통정보 시스템</a></li>
  <li>서울시 초/중/고등학교 :  <a href="https://open.neis.go.kr/portal/mainPage.do">나이스 교육정보 개방 포털</a></li>
</ul>

<h2 id="14-euclidean-distance--haversine">1.4. Euclidean distance : haversine</h2>
<ul>
  <li>(* 1.4.는 trial and error 기록을 위한 포스팅일 뿐, 결과적으로 사용하지 않은 방법이니 넘어가도 된다.)</li>
  <li>이제 haversine 패키지를 사용해서 아파트별로 근처에 지하철역, 버스정류장, 그리고 학교가 몇 개인지 계산해주었다. harversine 사용법은 매우 쉽다. 예를 들어 서울역과 고속터미널역의 거리는 6.35km 정도 된다.
<img src="/assets/img/project/prop/prop1_5.png" alt="사진5" /></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">haversine</span> <span class="kn">import</span> <span class="n">haversine</span>
<span class="c1"># 서울역
</span><span class="n">seoul_station</span> <span class="o">=</span> <span class="p">(</span><span class="mf">37.5547278494914</span><span class="p">,</span> <span class="mf">126.969526329341</span><span class="p">)</span>
<span class="c1"># 고속터미널역
</span><span class="n">terminal_station</span> <span class="o">=</span> <span class="p">(</span><span class="mf">37.5049267445237</span><span class="p">,</span> <span class="mf">127.004949918697</span><span class="p">)</span>

<span class="nf">haversine</span><span class="p">(</span><span class="n">seoul_station</span><span class="p">,</span> <span class="n">terminal_station</span><span class="p">)</span>
<span class="c1"># 6.357909897291526
</span></code></pre></div></div>

<ul>
  <li>이제 아래와 같이 학교, 지하철역, 버스정류장의 좌표 데이터를 준비하고 harversine을 통해 아파트별로 가까운 지하철역이 몇 개인지를 센다.
<img src="/assets/img/project/prop/prop1_6.png" alt="사진6" /></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">NearStation</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">station</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
    <span class="c1"># For all apts
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">(Station) (</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s">)-th apt is completed !</span><span class="sh">"</span><span class="p">)</span>
        <span class="c1"># For all stations
</span>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">station</span><span class="p">)):</span>
            <span class="n">apt_lat</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">"</span><span class="s">Latitude</span><span class="sh">"</span><span class="p">];</span> <span class="n">apt_long</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">"</span><span class="s">Longitude</span><span class="sh">"</span><span class="p">]</span>
            <span class="n">bus_lat</span> <span class="o">=</span> <span class="n">station</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="sh">"</span><span class="s">Latitude</span><span class="sh">"</span><span class="p">];</span> <span class="n">bus_long</span> <span class="o">=</span> <span class="n">station</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="sh">"</span><span class="s">Longitude</span><span class="sh">"</span><span class="p">]</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="nf">haversine</span><span class="p">((</span><span class="n">apt_lat</span><span class="p">,</span> <span class="n">apt_long</span><span class="p">),</span> <span class="p">(</span><span class="n">bus_lat</span><span class="p">,</span> <span class="n">bus_long</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">dist</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>
                <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="sh">"</span><span class="s">NearStation</span><span class="sh">"</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></div>

<ul>
  <li>하지만 우리가 실제로 아파트가 지하철역에서 얼마나 떨어져있는지를 생각할 때에는 <strong>euclidean distance</strong>가 아니라 실제로 지나가는 최단거리와 소요시간을 생각한다. 그러므로 최단거리에 해당하는 <strong>geometric distance</strong>을 사용할 필요가 있다. Geometric distance는 QGIS를 사용하므로 다음 게시글에서 다룬다.</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="project" /><summary type="html"><![CDATA[1.1. 데이터 수집 아파트 매매 데이터는 국토교통부 실거래가 공개시스템에서 다운로드하였다. 아파트의 위치, 면적, 층, 매매가격 정도를 알 수가 있다. 부동산 분석을 위해서는 주변 정보도 수집할 필요가 있는데, 1.3.에서 포스팅한다.]]></summary></entry><entry><title type="html">(PatchTST) A Time Series Is Worth 64 Words: Long-term Forecasting With Transformers</title><link href="http://localhost:4000/timeseries/2024-02-18-PatchTST/" rel="alternate" type="text/html" title="(PatchTST) A Time Series Is Worth 64 Words: Long-term Forecasting With Transformers" /><published>2024-02-18T00:00:00+09:00</published><updated>2024-03-03T18:59:39+09:00</updated><id>http://localhost:4000/timeseries/PatchTST</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-02-18-PatchTST/"><![CDATA[<h2 id="abstract">Abstract</h2>
<ul>
  <li>논문에서 요약을 잘 해놔서 굳이 번역하지 않고 그대로 가져왔다.</li>
  <li>2개의 Key components
    <ul>
      <li>Segmentation of time series into <strong>subseries-level patches</strong> which are served as input tokens to Transformer</li>
      <li><strong>Channel-independence</strong> where each channel contains a single univariate time series that shares the same embedding and Transformer weights across all the series.</li>
    </ul>
  </li>
  <li>Patching design의 장점 3가지
    <ul>
      <li><strong>local semantic information</strong> is retained in the embedding</li>
      <li><strong>computation and memory usage</strong> of the attention maps are quadratically reduced</li>
      <li>the model can attend <strong>longer history</strong></li>
    </ul>
  </li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>Patching : 단일 time-step을 token으로 만들면 (<code class="language-plaintext highlighter-rouge">point-wise input token</code>) 시계열의 포괄적인 의미 정보를 파악할 수 없기 때문에, time-steps를 합쳐서 subseries-level patchs를 만들어 locality를 강화하고 포괄적인 의미 정보를 파악한다.</li>
  <li>Channel-independence : 각 token이 오직 하나의 채널(feature)의 정보만 담는 것이다. (반대로 <code class="language-plaintext highlighter-rouge">channel-mixing</code>은 token이 모든 채널(features)를 embedding space에 projection해서 정보를 섞는 방식이다.)</li>
  <li>PatchTST의 장점 3
    <ul>
      <li>Reduction on time and space complexity</li>
      <li>Longer look-back window</li>
      <li>Capability of representation learning</li>
    </ul>
  </li>
</ul>

<h2 id="2-related-work">2. Related work</h2>
<ul>
  <li>Patching의 milestone은 ViT(2021)</li>
  <li>LogTrans(2019)
    <ul>
      <li>key, query는 point-wise 내적 안하지만 여전히 value는 single time step에 기반한다.</li>
    </ul>
  </li>
  <li>Autoformer(2021)
    <ul>
      <li>patch level connection을 얻기 위해 auto-correlation을 사용하지만 handcrafted design이라서 패치 내 의미 정보를 모두 파악하기 어렵다.</li>
    </ul>
  </li>
  <li>Triformer(2022)
    <ul>
      <li>patch attention을 제안하긴 하지만 patch를 input으로 사용하지 않는다는 점에서 의미 정보를 파악하기 어렵다.</li>
    </ul>
  </li>
  <li>Unlabelled data로 인해 self-supervised learning이 많이 떴는데, transformer를 통해 time series에 적용하기 위한 representation을 학습하는 시도는 아직 완전하지 않다.</li>
</ul>

<h2 id="3-proposed-method">3. Proposed Method</h2>

<h3 id="31-model-structure">3.1. Model Structure</h3>
<ul>
  <li>\((\boldsymbol{x_{1}}, ..., \boldsymbol x_L)\) 를 보고 \((\boldsymbol x_{L+1}, ..., \boldsymbol x_{L+T})\)를 예측하는 문제이고, PatchTST는 transformer의 encoder를 핵심으로 한다.
<img src="/assets/img/timeseries/PatchTST/fig1.jpeg" alt="사진1" /></li>
  <li><strong>Forward Process</strong> : 시계열에 있는 M개의 변수가 있고 길이가 L이라고 할 때, \(i\)번째 series는 \(\boldsymbol{x}_{1:L}^{(i)}=(x_{1}^{(i)}, ... , x_{L}^{(i)})\)이다.</li>
  <li>M개의 \(\boldsymbol{x}^{(i)} \in \mathbb R^{1 \times L}\) 가 각각 transformer backbone으로 들어가고 (channel-independence) 각각의 transformer는 \(\boldsymbol{\hat x}^{(i)} =(\hat x_{L+1}^{(i)}, ..., \hat x_{L+T}^{(i)})\in \mathbb R^{1 \times L}\)를 output으로 한다.</li>
  <li><strong>Patching</strong> : 아래 그림처럼 univariate time series \(\boldsymbol{x}^{(i)}\)를 \(\boldsymbol{x}_p^{(i)} \in \mathbb R^{P \times N}\)으로 patching한다.
<img src="/assets/img/timeseries/PatchTST/myfig1.jpeg" alt="사진2" /></li>
  <li>Input token의 개수가 \(L\)에서 \(N=\left\lfloor\frac{(L-P)}{S}\right\rfloor+2\)로 줄어들기 때문에, 사용할 수 있는 memory와 complexity가 확보되면서 더 긴 historical sequence를 볼 수 있어 성능이 향상된다.</li>
  <li><strong>Transformer Encoder</strong> :
    <ul>
      <li>1) Mapping to the transformer latent space : \(\boldsymbol{x}_d^{(i)}= \mathbf W_p\boldsymbol{x}_p^{(i)}+ \mathbf W_{pos}\)
        <ul>
          <li>where trainable linear projection \(\mathbf W_p \in \mathbb R^{D \times P}\), learnable addictive position encoding \(\mathbf W_{pos} \in \mathbb R^{D \times N}\))</li>
        </ul>
      </li>
      <li>
        <dl>
          <dt>2) Multi-head attention (with Batchnorm and Residual connection)</dt>
          <dd><code class="language-plaintext highlighter-rouge">Query</code> \(Q_h^{(i)}=\left(\boldsymbol{x}_d^{(i)}\right)^T \mathbf{W}_h^Q\), <code class="language-plaintext highlighter-rouge">Key</code> \(K_h^{(i)}=\left(\boldsymbol{x}_d^{(i)}\right)^T \mathbf{W}_h^K\) and <code class="language-plaintext highlighter-rouge">Value</code> \(V_h^{(i)}=\left(\boldsymbol{x}_d^{(i)}\right)^T \mathbf{W}_h^V\)</dd>
        </dl>
        <ul>
          <li>where \(\mathbf{W}_h^Q, \mathbf{W}_h^K \in \mathbb{R}^{D \times d_k}\) and \(\mathbf W_h^V \in \mathbb R^{D \times D}\)</li>
        </ul>
      </li>
      <li>3) Getting attention : \(\mathbf O_h^{(i)} \in \mathbb R^{D \times N}\)
        <ul>
          <li>where \(\left(\mathbf{O}_h^{(i)}\right)^T=\operatorname{Attention}\left(Q_h^{(i)}, K_h^{(i)}, V_h^{(i)}\right)=\operatorname{Softmax}\left(\frac{Q_h^{(i)} K_h^{(i)^T}}{\sqrt{d_k}}\right) V_h^{(i)}\)</li>
        </ul>
      </li>
      <li>4) Flatten and Linear head : \(\boldsymbol{\hat x}^{(i)}=(\boldsymbol{\hat x}_{L+1}^{(i)}, ..., \boldsymbol{\hat x}_{L+T}^{(i)}) \in \mathbb R^{1 \times T}\)</li>
    </ul>
  </li>
  <li><strong>Loss function</strong> : MSE. \(\mathcal{L}=\mathbb{E}_{\boldsymbol{x}} \frac{1}{M} \sum_{i=1}^M\left\|\hat{\boldsymbol{x}}_{L+1: L+T}^{(i)}-\boldsymbol{x}_{L+1: L+T}^{(i)}\right\|_2^2\)</li>
  <li><strong>Instance Normalization</strong> : Pathcing 전에 각 univariate time series에 <code class="language-plaintext highlighter-rouge">mean=0</code>, <code class="language-plaintext highlighter-rouge">std=1</code>하고, output prediction 전에 다시 더해준다.</li>
</ul>

<h3 id="32-representation-learning">3.2. Representation Learning</h3>
<ul>
  <li>Self-supervised representation learning 방법 중에서 masked autoencoder를 사용했다. (input sequence의 일부를 0으로 masking하고 recover하도록 모델링)</li>
  <li>다만 이걸 그대로 Multivariate time series에 가져오면 두 가지 문제가 발생한다.
    <ul>
      <li>첫째, single time step에 masking하면 맞추기가 너무 쉽다. (interpolating 하면 끝) 그래서 다양한 크기의 group of time series를 랜덤하게 masking하는 기존의 방법을 사용했다.</li>
      <li>둘째, 각 time step을 D차원으로 representation하면 \(z_t \in \mathbb R^D\)가 되니, parameter matrix \(\mathbf W\)의 차원이 \((L\cdot D) \times (M\cdot T)\)이 되어 \(L, D, M, T\) 중 하나만 커지더라도 oversieze가 된다. 그래서 PatchTST에서는 \(D \times P\) size의 linear layer를 사용하였고, patch 단위로 masking을 했다.</li>
    </ul>
  </li>
</ul>

<h2 id="4-experiments">4. Experiments</h2>

<ul>
  <li>사용한 데이터셋은 9개(ETTm1/2, ETTh1/2, ILI, Weather, Traffic, Exchange, Electrictiy)이고 비교한 모델은 6개(FEDformer, Autoformer, Informer, Pyraformer, LogTrans +LTSF-Linear)이다.
<img src="/assets/img/timeseries/AreTF/table12.jpeg" alt="사진3" />
<img src="/assets/img/timeseries/PatchTST/table34.jpeg" alt="사진4" /></li>
  <li>PatchTST/64는 input patches 64개, look-back window size L=512이다.
  PatchTST/42는 input patches 42개, look-back window size L=336이다.
  두 버전 모두 patch length P = 16, stride S = 8이다.
  Masking ratio = 40%이다.</li>
  <li>실험 결과 long-term forecasting에서 다른 transformer-based models 및 DLinear보다 성능이 뛰어났다.
<img src="/assets/img/timeseries/PatchTST/table56.jpeg" alt="사진5" /></li>
  <li>Transfer learning task에서도 다른 모델들보다 성능이 뛰어났다.
<img src="/assets/img/timeseries/PatchTST/table7.jpeg" alt="사진6" /></li>
  <li>Ablation study 결과 patching과 channel-independence 모두 성능에 중요한 역할을 하고 있음을 알 수 있다. 특히 patching의 motivation은 앞서 언급한 것처럼 직관적이다.
<img src="/assets/img/timeseries/PatchTST/fig2.jpeg" alt="사진7" /></li>
  <li>논문 <a href="/timeseries/2024-02-16-AreTF">Are Transformer Effective for Time Series Forecasting?</a>에서 transformer-based models의 경우 look-back windows size가 커져도 예측 성능이 좋아지지 않는다고 주장했고, 이는 temporal information을 잘 못잡아내는 것이 맞다. 하지만 PatchTST는 look-back windows가 길어질수록 성능이 좋아지므로 해당사항이 없다.</li>
</ul>

<h2 id="5-conclusion">5. Conclusion</h2>
<ul>
  <li>PatchTST의 key components 2가지는 : Patching과 Channel-independence이다.</li>
  <li>PatchTST는 longer look-back windows의 benefit을 가질 수 있으면서 local semantic information을 파악할 수 있다.</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[ICLR 2023](https://arxiv.org/abs/2211.14730)]]></summary></entry></feed>