---
layout: post
related_posts:
  _
title: 
description: >
sitemap:
    changefreq: daily
    priority: 1.0
hide_last_modified: true
---

# Median of Means Estimator (MoM)

- 우리는 sample을 n개 뽑아서 만든 estimator가 true parameter의 근처에서 자주 등장하기를 원한다.
- Estimator와 true parameter의 거리는 $$\left\vert \hat \mu - \mu \right\vert$$이다. (mean에 대한 estimator인 경우)
- $$\left\vert \hat \mu - \mu \right\vert \ge t$$는 estimator의 error가 우리의 기준 t보다 높은 경우로 볼 수 있으므로,
  - $$P(\left\vert \hat \mu - \mu \right\vert \ge t) \le \delta$$일 때, 주어진 $$t$$에 대해 $$\delta$$가 얼마나 작은지가 중요하다.
  - 또는 $$t$$가 커짐에 따라 $$\delta$$가 얼마나 빠르게 줄어드는지
- Ex. Chebyshev’s inequality $$P\left\{\left\vert \frac{1}{n} \sum_{i=1}^n X_i-\mu \right\vert \geq \sigma \sqrt{\frac{1}{n \delta}}\right\} \leq \delta$$는 polynomial upper bound를 제공한다.
- 하지만 [Inequalities for Probabilities](https://lpppj.github.io/stat/2024-04-18-ineq2)에서 exponential upper bound를 제공하는 다양한 부등식을 소개하였다.
- <u>Exponential upper bound를 제공하는 또 다른 부등식 Median of Means Estimator (MoM)</u>을 소개한다.

## Median of Means Estimator (MoM)

- 목표는 $$X_1, \ldots, X_n \stackrel{\text { i.i.d. }}{\sim} F$$ 으로  $$\mathbb{E}[X]=\mu$$를 estimate하는 것이다.
- $$n$$개의 sample을 $$K$$개의 그룹으로 나누고, (각 그룹에는 $$B$$개의 samples) 각 그룹의 평균 $$\widehat{\mu}_1, \ldots, \widehat{\mu}_K$$를 만든다.
- MoM은 $$\widehat{\mu}_{\mathrm{MoM}}=\operatorname{median}\left(\widehat{\mu}_1, \ldots, \widehat{\mu}_K\right)$$으로 정의한다.
- MoM은 $$\operatorname{Var}\left[X_1\right]:=\sigma^2<\infty$$라는 단순한 가정만으로 exponential upper bound $$P\left(\left\vert \widehat{\mu}_{\mathrm{MoM}}-\mu\right\vert \geq t\right) \leq e^{-2 K\left(\frac{1}{2}-\frac{K}{n} \frac{\sigma^2}{t^2}\right)^2}=e^{-2 \frac{n}{B}\left(\frac{1}{2}-\frac{\sigma^2}{B t^2}\right)^2}$$를 제공한다.
- Upper bound를 단순하게 표현하려면 $$t=\sqrt{4 \sigma^2 / B}\left(>\sqrt{2 \sigma^2 / B}\right)$$로 잡으면 $$P\left(\left\vert \widehat{\mu}_{\mathrm{MoM}}-\mu\right\vert \geq 2 \sigma \sqrt{K / n}\right) \leq e^{-K / 8}$$가 된다.

### Proof

- 증명이 아주 직관적이다.
  - 만약 $$\hat \mu_{MoM}$$이 $$\mu+t$$보다 크다면, 적어도 $$K$$개의 $$\hat \mu$$ 중 절반인 $$\frac{K}{2}$$개의 $$\hat \mu$$가 $$\mu+t$$보다 크다는 것을 의미한다.
  - 반대로  $$\hat \mu_{MoM}$$이 $$\mu-t$$보다 크다면, 적어도 $$K$$개의 $$\hat \mu$$ 중 절반인 $$\frac{K}{2}$$개의 $$\hat \mu$$가 $$\mu-t$$보다 작다는 것을 의미한다.
- 그러므로 $$P\left(\left\vert \widehat{\mu}_{\mathrm{MoM}}-\mu\right\vert \geq t\right) \leq P\left(\sum_{i=1}^K \mathbb{1}\left(\left\vert \widehat{\mu}_i-\mu\right\vert \geq t\right) \geq \frac{K}{2}\right)$$이다.
  - $$Z_i = \mathbb{1}\left(\left\vert \widehat{\mu}_i-\mu\right\vert \geq t\right)$$라 하면 indicator function이기 때문에 $$[0,1]$$​로 bounded이다.
  - 또한 $$\mathbb{E}[Z_i] = \mathbb{E}[Z_1]$$이고, Chebyshev's inequality에 의해 $$\mathbb{E}\left[Z_1\right]=P\left(\left\vert \widehat{\mu}_1-\mu\right\vert \geq t\right) \leq \frac{\sigma^2}{B t^2}$$이다.

- 따라서 $$\begin{aligned} P\left(\frac{1}{K} \sum_{i=1}^K Z_i \geq \frac{1}{2}\right)&=P\left(\frac{1}{K} \sum_{i=1}^K\left(Z_i-\mathbb{E}\left[Z_1\right]\right) \geq \frac{1}{2}-\mathbb{E}\left[Z_1\right]\right) \\ &\le P\left( \sum_{i=1}^K\left(Z_i-\mathbb{E}\left[Z_1\right]\right) \ge K(\frac{1}{2}-\frac{\sigma^2}{Bt^2})\right)\end{aligned}$$는
  - Hoeffding's inequality $$P\left\{\displaystyle\sum_{i=1}^n\left(X_i-\mathbb{E}\left[X_i\right]\right) \geq t\right\} \leq e^{-2 t^2 / \sum_{i=1}^n\left(b_i-a_i\right)^2}$$을 이용하여
  - $$P\left(\frac{1}{K} \sum_{i=1}^K Z_i \geq \frac{1}{2}\right) \le e^{-2 K^2\left(\frac{1}{2}-\frac{K}{n} \frac{\sigma^2}{t^2}\right)^2/\sum_{i=1}^{K}(1-0)^2}= e^{-2 K\left(\frac{1}{2}-\frac{K}{n} \frac{\sigma^2}{t^2}\right)^2}$$이다. 