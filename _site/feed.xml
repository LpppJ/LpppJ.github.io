<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-04-16T17:49:56+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">LpppJ</title><subtitle>This is blog about machine learning, deep learning, artificial intelligence.
</subtitle><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><entry><title type="html">Inequalities for 1. Expectation and 2.Variance</title><link href="http://localhost:4000/stat/2024-04-16-ineq1/" rel="alternate" type="text/html" title="Inequalities for 1. Expectation and 2.Variance" /><published>2024-04-16T00:00:00+09:00</published><updated>2024-04-16T17:49:43+09:00</updated><id>http://localhost:4000/stat/ineq1</id><content type="html" xml:base="http://localhost:4000/stat/2024-04-16-ineq1/"><![CDATA[<h2 id="1-inequalities-for-expectation">1. Inequalities for Expectation</h2>

<h2 id="11-jensens-inequality">1.1. Jensen’s Inequality</h2>

<ul>
  <li>Suppose \(g\) is a convex function such that \(\lambda g(x)+(1-\lambda) g(y) \geq g(\lambda x+(1-\lambda) y)\) for all \(\lambda \in(0,1)\) and \(x, y \in \mathbb{R}\).</li>
  <li>Then \(\mathbb{E}[g(X)] \geq g(\mathbb{E}[X]),\) provided that both expectations exist, i.e., \(\mathbb{E}{\left\vert X \right\vert}&lt;\infty\) and \(\mathbb{E}{\left\vert g(X) \right\vert}&lt;\infty\).</li>
</ul>

<h3 id="proof">Proof</h3>

<ul>
  <li>Assumption : \(g^{\prime \prime}(x)\ge0 \ \forall x\)</li>
  <li>Using Taylor series about \(\mu = \mathbb E[X]\) of order 2</li>
  <li>\(g(x)=g(\mu)+g^{\prime}(\mu)(x-\mu)+\frac{g^{\prime \prime}(\zeta)}{2}(x-\mu)^2 \text { where } \zeta \text { is between } x \text { and } \mu\)이고</li>
  <li>\(g(x) \geq g(\mu)+g^{\prime}(\mu)(x-\mu)\quad (\because g^{\prime \prime}(x)\ge0 \ \forall x)\). 양변에 expectation을 취하면</li>
  <li>\(\mathbb E[g(x)] \geq g(\mu)\)이 된다.</li>
</ul>

<p><img src="/assets/img/stat/ineq1/fig1.png" alt="그림1" /></p>

<h3 id="examples--amge-gm-ge-hm">Examples : \(AM\ge GM \ge HM\)</h3>

<ul>
  <li>
    <p>\(\begin{aligned} \text { Arithmetic Mean (AM) }&amp;=\frac{\sum_{i=1}^n x_i}{n} \\ \text { Geometric Mean }(\mathrm{GM}) &amp; =\left(\prod_{i=1}^n x_i\right)^{1 / n} \\ \text { Harmonic Mean }(\mathrm{HM}) &amp; =\frac{1}{\frac{1}{n} \sum_{i=1}^n \frac{1}{x_i}} \end{aligned}\)이다.</p>
  </li>
  <li>
    <p>\(-\log(HM) = \log \left(\frac{1}{n} \sum_{i=1}^n \frac{1}{x_i}\right) \ \geq \ -\log(GM)=\frac{1}{n} \sum_{i=1}^n\left\{\log \left(\frac{1}{x_i}\right)\right\}\ \geq \ -\log \left(\frac{1}{n} \sum_{i=1}^n x_i\right)=-\log (\mathrm{AM})\)를 보이면 된다.</p>
  </li>
</ul>

<h3 id="examples--kl-divergence-ge-0">Examples : KL-divergence \(\ge 0\)</h3>

<ul>
  <li>
    <p>\(D_{\mathrm{KL}}(P \mid\mid Q)=\sum_x p(x) \log \left(\frac{p(x)}{q(x)}\right)=\mathbb{E}\left[\log \left(\frac{p(X)}{q(X)}\right)\right]=\mathbb{E}\left[-\log \left(\frac{q(X)}{p(X)}\right)\right]\)이다.</p>
  </li>
  <li>
    <p>\(D_{\mathrm{KL}}(P \mid\mid Q)=\mathbb{E}[-\log (Z)] \geq-\log \mathbb{E}[Z]=-\log \sum_x p(x) \frac{q(x)}{p(x)}=-\log (1)=0\)이므로 KL-divergence는 non-negative이다.</p>
  </li>
</ul>

<h3 id="examples--chi-square-divergence-d_chi2-ge-d_kl">Examples : Chi-square divergence \(D_{\chi^2} \ge D_{KL}\)</h3>

<ul>
  <li>using \(\log x\le x-1\)</li>
  <li>\(\begin{aligned}D_{\mathrm{KL}}(P \mid\mid Q) &amp;= \sum_x p(x) \log \left(\frac{p(x)}{q(x)}\right) \\ &amp;\le \sum_x\left(\frac{p(x)}{q(x)}\right)^2 q(x)-1 \\ &amp; = \mathrm{D}_{\chi^2}(P \mid\mid Q)\end{aligned}\)이다.</li>
</ul>

<h2 id="12-holders-inequality">1.2. Holder’s inequality</h2>

<ul>
  <li>If \(p, q \in(1, \infty)\) with \(1 / p+1 / q=1\),</li>
  <li>Then \(\left\vert\mathbb{E}[X Y]\right\vert \leq \mathbb{E}\left\vert X Y\right\vert \leq\left(\mathbb{E}{\left\vert X \right\vert}^p\right)^{1 / p}\left(\mathbb{E}{\left\vert Y\right\vert}^q\right)^{1 / q} .\)</li>
</ul>

<h3 id="proof-1">Proof</h3>

<ul>
  <li>The first inequality follows from \(-{\left\vert XY \right\vert} \leq X Y \leq{\left\vert XY \right\vert}\)</li>
  <li>The second inequality follows from :</li>
  <li>
    <p>.\(\begin{aligned}
a=\frac{|X|}{\left(\mathbb{E}|X|^p\right)^{1 / p}} \quad \text { and } \quad b=\frac{|Y|}{\left(\mathbb{E}|Y|^q\right)^{1 / q}}\\ \frac{1}{p} \frac{|X|^p}{\mathbb{E}|X|^p}+\frac{1}{q} \frac{|Y|^q}{\mathbb{E}|Y|^q} \geq \frac{|X Y|}{\left(\mathbb{E}|X|^p\right)^{1 / p}\left(\mathbb{E}|Y|^q\right)^{1 / q}}
\end{aligned}\)</p>
  </li>
  <li>c.f. Lemma) Let \(a\) and \(b\) be any positive numbers, and let \(p\) and \(q\) be any positive numbers satisfying \(1 / p+1 / q=1\). Then \(\frac{1}{p} a^p+\frac{1}{q} b^q \geq a b\) with equality if and only if \(a^p=b^q\)​.
    <ul>
      <li>Note : \(1 / p+1 / q=1 \Longleftrightarrow p-1=p / q \text {. }\)</li>
    </ul>
  </li>
</ul>

<h3 id="corollary--cauchyschwarz-inequality">Corollary : Cauchy–Schwarz inequality</h3>

<ul>
  <li>\(\left\vert\mathbb{E}[X Y]\right\vert \leq \mathbb{E}[{\left\vert XY\right\vert}] \leq\left(\mathbb{E}{\left\vert X \right\vert}^2\right)^{1 / 2}\left(\mathbb{E}{\left\vert Y\right\vert}^2\right)^{1 / 2}\)이다.</li>
</ul>

<h3 id="example--covariance-inequality">Example : Covariance inequality</h3>

<ul>
  <li>\(\mathbb{E}\left[\left(X-\mu_X\right)\left(Y-\mu_Y\right)\right] \leq\left\{\mathbb{E}\left[\left(X-\mu_X\right)^2\right]\right\}^{1 / 2}\left\{\mathbb{E}\left[\left(Y-\mu_Y\right)^2\right]\right\}^{1 / 2}\) 이다.</li>
  <li>즉 \(\operatorname{Cov}(X, Y)^2 \leq \sigma_X^2 \sigma_Y^2\)</li>
  <li>Cramér–Rao Lower Bound : \(\frac{\operatorname{Cov}(Y, Z)}{\sqrt{\operatorname{Var}(Y) \operatorname{Var}(Z)}} \leq 1 \quad \Longleftrightarrow \quad \operatorname{Var}(Y) \geq \frac{\operatorname{Cov}(Y, Z)^2}{\mathcal{I}(\theta)}=\frac{1}{\mathcal{I}(\theta)}\)
    <ul>
      <li>\(\begin{aligned}
\operatorname{Cov}(Y, Z) &amp; =\mathbb{E}[Y Z]-\mathbb{E}[Y] \mathbb{E}[Z] \\
&amp; =\frac{d}{d \theta} \underbrace{\int u(x) f_X(x ; \theta) d x}_{=\theta}-\theta \frac{d}{d \theta} \underbrace{\int f_X(x ; \theta) d x}_{=1}=1
\end{aligned}\) under some regularity conditions.</li>
    </ul>
  </li>
</ul>

<h3 id="example">Example</h3>

<ul>
  <li>
    <p>\(\mathbb{E}{\left\vert X \right\vert} \leq\left\{\mathbb{E}\left[{\left\vert X \right\vert}^p\right]\right\}^{1 / p} \leq\left\{\mathbb{E}\left[{\left\vert X \right\vert}^s\right]\right\}^{1 / s}, \quad \text { for } 1&lt;p&lt;s&lt;\infty\)이다.</p>
  </li>
  <li>
    <p><strong>즉 higher moment \(\mathbb E[{\left\vert X \right\vert}^N]&lt;\infty\)이면 lower moment \(\mathbb E[{\left\vert X \right\vert}^n]&lt;\infty\)이다.</strong></p>
  </li>
</ul>

<h2 id="13-minkowskis-inequality">1.3. Minkowski’s inequality</h2>

<ul>
  <li>\(1&lt;p&lt;\infty, \quad\left(\mathbb{E}{\left\vert X+Y \right\vert}^p\right)^{1 / p} \leq\left(\mathbb{E}{\left\vert X \right\vert}^p\right)^{1 / p}+\left(\mathbb{E}{\left\vert Y \right\vert}^p\right)^{1 / p}\)이다.</li>
</ul>

<h3 id="proof-2">Proof</h3>

<ul>
  <li>
    <p>Using the Hölder’s inequality, \(\begin{aligned}
\mathbb{E}|X+Y|^p &amp; =\mathbb{E}\left[|X+Y||X+Y|^{p-1}\right] \\
&amp; \leq \mathbb{E}\left[|X||X+Y|^{p-1}\right]+\mathbb{E}\left[|Y||X+Y|^{p-1}\right] \\
&amp; \leq\left(\mathbb{E}|X|^p\right)^{1 / p}\left(\mathbb{E}|X+Y|^{q(p-1)}\right)^{1 / q}+\left(\mathbb{E}|Y|^p\right)^{1 / p}\left(\mathbb{E}|X+Y|^{q(p-1)}\right)^{1 / q} \\ &amp; \text { where } q \text { satisfies } 1 / p+1 / q=1
\end{aligned}\)</p>
  </li>
  <li>
    <p>Then, \(\begin{aligned}
\frac{\mathbb{E}|X+Y|^p}{\left(\mathbb{E}|X+Y|^{q(p-1)}\right)^{1 / q}} = \frac{\mathbb{E}|X+Y|^p}{\left(\mathbb{E}|X+Y|^{p}\right)^{1 / q}} = \left(\mathbb{E}|X+Y|^p\right)^{1/p}\leq\left(\mathbb{E}|X|^p\right)^{1 / p}+\left(\mathbb{E}|Y|^p\right)^{1 / p}
\end{aligned}\)</p>
  </li>
</ul>

<h2 id="14-association-inequality">1.4. Association inequality</h2>

<ul>
  <li>\(f, g\) non-decreasing implies \(\mathbb{E}[f(X) g(X)] \geq \mathbb{E}[f(X)] \mathbb{E}[g(X)]\).</li>
  <li>\(f, g\) non-increasing implies \(\mathbb{E}[f(X) g(X)] \geq \mathbb{E}[f(X)] \mathbb{E}[g(X)]\).</li>
  <li>\(f\) non-decreasing and \(g\) non-increasing implies \(\mathbb{E}[f(X) g(X)] \leq \mathbb{E}[f(X)] \mathbb{E}[g(X)]\)</li>
</ul>

<h3 id="proof-3">Proof</h3>

<p>Let the pair of random variables \(X^{\prime}\) be distributed as the pair \(X\) and independent of it. If \(f\) and \(g\) are non-decreasing, it holds \(\left(f(X)-f\left(X^{\prime}\right)\right)\left(g(X)-g\left(X^{\prime}\right)\right) \geq 0\) and therefore \(\mathbb{E}\left[\left(f(X)-f\left(X^{\prime}\right)\right)\left(g(X)-g\left(X^{\prime}\right)\right)\right] \geq 0\)</p>

<h3 id="example-1">Example</h3>

<p>\(\begin{aligned}
&amp; \mathbb{E}\left[X^4\right] \geq \mathbb{E}[X] \mathbb{E}\left[X^3\right] \\
&amp; \mathbb{E}\left[X e^{-X}\right] \leq \mathbb{E}[X] \mathbb{E}\left[e^{-X}\right] \\
&amp; \mathbb{E}[X \mathbb{1}(X \geq a)] \geq \mathbb{E}[X] P(X \geq a)
\end{aligned}\)​</p>

<hr />

<h2 id="2-inequalities-for-variance">2. Inequalities for Variance</h2>

<h2 id="21-variance-upper-bound">2.1. Variance upper bound</h2>

<ul>
  <li>Suppose that \(a \leq X \leq b\) for some \(a, b \in \mathbb{R}\).</li>
  <li>Then \(\operatorname{Var}[X] \leq \frac{(b-a)^2}{4}\)</li>
</ul>

<h3 id="proof-4">Proof</h3>

<ul>
  <li>
    <p>\(\operatorname{Var}[X]=\mathbb{E}\left[(X-\mathbb{E}[X])^2\right] \leq \mathbb{E}\left[(X-c)^2\right] \quad \text { for any } c \in \mathbb{R}\)이다.</p>
  </li>
  <li>
    <p>\(c=(b+a) / 2\)이면 \(\operatorname{Var}[X] \leq \mathbb{E}\left[(X-(b+a) / 2)^2\right] \leq(b-a)^2 / 4\)</p>
  </li>
</ul>

<h2 id="22-efronstein-inequality">2.2. Efron–Stein inequality</h2>

<ul>
  <li><u>Simple but surprisingly powerful !</u></li>
  <li>
    <p>Suppose that \(X_1, \ldots, X_n, X_1^{\prime}, \ldots, X_n^{\prime}\) are independent with \(X_i\) and \(X_i^{\prime}\) having the same distribution for all \(i \in\{1, \ldots, n\}\). Let \(X=\left(X_1, \ldots, X_n\right)\) and \(X^{(i)}=\) \(\left(X_1, \ldots, X_{i-1}, X_i^{\prime}, X_{i+1}, \ldots, X_n\right)\).</p>
  </li>
  <li>Then\(\operatorname{Var}[f(X)] \leq \frac{1}{2} \sum_{i=1}^n \mathbb{E}\left[\left\{f(X)-f\left(X^{(i)}\right)\right\}^2\right]\)</li>
</ul>

<h3 id="proof-5">Proof</h3>

<ul>
  <li><strong>Step 1</strong>: Define \(V\)</li>
  <li>Let \(V_i=\mathbb{E}\left[f(X) \mid X_1, \ldots, X_i\right]-\mathbb{E}\left[f(X) \mid X_1, \ldots, X_{i-1}\right], \quad \text { for } i=1, \ldots, n\)</li>
  <li>Then \(V=\sum_{i=1}^n V_i\)</li>
  <li>.\(\begin{aligned}
\operatorname{Var}[V] &amp; =\mathbb{E}\left[\left(\sum_{i=1}^n V_i\right)^2\right] \\
&amp; =\sum_{i=1}^n \mathbb{E}\left[V_i^2\right]+2 \sum_{1 \leq i&lt;j \leq n} \mathbb{E}\left[V_i V_j\right]
\end{aligned}\)</li>
  <li><strong>Step 2</strong> : cross product = 0</li>
  <li>
    <p>For any \(i&gt;j,\) \(\begin{aligned}
\mathbb{E}\left[V_i V_j\right]&amp;=\mathbb{E}\left[\mathbb{E}\left[V_i V_j \mid X_1, \ldots, X_j\right]\right] \\&amp; =\mathbb{E}\left[V_j \mathbb{E}\left[V_i \mid X_1, \ldots, X_j\right]\right]=0\end{aligned}\)</p>
  </li>
  <li>Because \(\begin{aligned}
\mathbb{E}\left[V_i \mid X_1, \ldots, X_j\right] &amp; =\mathbb{E}\left[\mathbb{E}\left[f(X) \mid X_1, \ldots, X_i\right] \mid X_1, \ldots, X_j\right]-\mathbb{E}\left[\mathbb{E}\left[f(X) \mid X_1, \ldots, X_{i-1}\right] \mid X_1, \ldots, X_j\right] \\
&amp; =\mathbb{E}\left[f(X) \mid X_1, \ldots, X_j\right]-\mathbb{E}\left[f(X) \mid X_1, \ldots, X_j\right]=0
\end{aligned}\)
    <ul>
      <li>c.f. \(\mathbb{E}[X Y]=\mathbb{E}[\mathbb{E}[X Y \mid X]]=\mathbb{E}[X \mathbb{E}[Y \mid X]]\) and \(\mathbb{E}[\mathbb{E}[X \mid Y, f(X)] \mid f(X)]=\mathbb{E}[X \mid f(X)]\)​</li>
    </ul>
  </li>
  <li>
    <p>Therefore, \(\operatorname{Var}[V]=\sum_{i=1}^n \mathbb{E}\left[V_i^2\right]\)</p>
  </li>
  <li><strong>Step 3</strong> by Jensen’s inequality</li>
  <li>.\(\begin{aligned}
V_i^2 &amp; =\left(\mathbb{E}\left[f(X) \mid X_1, \ldots, X_i\right]-\mathbb{E}\left[f(X) \mid X_1, \ldots, X_{i-1}\right]\right)^2 \\
&amp; =\left(\mathbb{E}\left[\mathbb{E}\left[f(X) \mid X_1, \ldots, X_n\right]-\mathbb{E}\left[f(X) \mid X_1, \ldots, X_{i-1}, X_{i+1}, \ldots, X_n\right] \mid X_1, \ldots, X_i\right]\right)^2 \\
&amp; \leq \mathbb{E}\left[\left(\mathbb{E}\left[f(X) \mid X_1, \ldots, X_n\right]-\mathbb{E}\left[f(X) \mid X_1, \ldots, X_{i-1}, X_{i+1}, \ldots, X_n\right]\right)^2 \mid X_1, \ldots, X_i\right] \\
&amp; =\mathbb{E}\left[\left(f(X)-\mathbb{E}[f(X^{(i)})]\right)^2 \mid X_1, \ldots, X_i\right] \end{aligned}\)</li>
  <li>. \(\begin{aligned} \mathbb{E}[V_i^2]&amp;\le\mathbb{E}\left[\mathbb{E}\left[\left(f(X)-\mathbb{E}[f(X^{(i)})]\right)^2 \mid X_1, \ldots, X_i\right]\right]\\&amp;=\mathbb{E}\left[\left(f(X)-\mathbb{E}(f(X^{(i)}))\right)^2\right] \\ &amp; =\mathbb{E}\left[\operatorname{Var}\left(f(X) \mid X_1, \ldots, X_{i-1}, X_{i+1}, \ldots, X_n\right)\right] \\ &amp; =\frac{1}{2} \mathbb{E}\left[\left(f(X)-f(X^{(i)})\right)^2\right] \end{aligned}\)</li>
  <li>Note : \(f(X^{(i)})\) is \(Z=f\left(X_1, \ldots, X_{i-1}, X_i^{\prime}, X_{i+1}, \ldots, X_n\right)\)</li>
  <li><strong>결론</strong> : samples \(X = (X_1, \ldots, X_n),\quad X^{\prime} = (X_1^{\prime}, \ldots, X_n^{\prime})\)이 있을 때, estimator \(f(X)\)의 variance를 알기 위해서는 sample \(X_1, \ldots, X_n\)를 하나씩 \(X_1^{\prime}, \ldots, X_n^{\prime}\)으로 바꿔보면서, \(f(X)\)의 변화량\(^2\) 의 expectation을 다 더하고 2로 나누어주면 upper bound를 구할 수 있다.</li>
</ul>

<h3 id="example--sample-mean">Example : Sample mean</h3>

<ul>
  <li>Let \(f(X)=\frac{1}{n} \sum_{i=1}^n X_i\) where \(X_1, \ldots, X_n \stackrel{\text { i.i.d. }}{\sim} P\).</li>
  <li>Then the EfronStein inequality yields \(\operatorname{Var}[f(X)] \leq \sum_{i=1}^n \frac{1}{n^2} \mathbb{E}\left[\frac{\left(X_i-X_i^{\prime}\right)^2}{2}\right]=\frac{\sigma^2}{n}\)</li>
  <li>We know that \(\operatorname{Var}[f(X)]=\sigma^2 / n\). In this regard, the Efron-Stein inequality is not improvable.</li>
</ul>

<h3 id="example--bounded-differences">Example : Bounded Differences</h3>

<ul>
  <li>\(\sup _{x_1, \ldots, x_n, x_i^{\prime} \in \mathcal{X}}{\left\vert g\left(x_1, \ldots, x_n\right)-g\left(x_1, \ldots, x_{i-1}, x_i^{\prime}, x_{i+1}, \ldots, x_n\right) \right\vert} \leq c_i,\)이면</li>
  <li>the Efron-Stein inequality shows \(\operatorname{Var}\left[g\left(X_1, \ldots, X_n\right)\right] \leq \frac{1}{2} \sum_{i=1}^n c_i^2, \quad \text { for } 1 \leq i \leq n\)</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="stat" /><summary type="html"><![CDATA[1. Inequalities for Expectation]]></summary></entry><entry><title type="html">Semi-Supervised Mean Estimation (Variance Reduction Technique)</title><link href="http://localhost:4000/stat/2024-04-16-SSmean/" rel="alternate" type="text/html" title="Semi-Supervised Mean Estimation (Variance Reduction Technique)" /><published>2024-04-16T00:00:00+09:00</published><updated>2024-04-16T13:11:09+09:00</updated><id>http://localhost:4000/stat/SSmean</id><content type="html" xml:base="http://localhost:4000/stat/2024-04-16-SSmean/"><![CDATA[<ul>
  <li>일반적으로 \(\left\{X_i\right\}_{i=1}^n\)으로 \(\mathbb{E}[X]\)를 estimate할 때 sample mean \(\hat \theta = \bar{X}=\frac{1}{n} \sum_{i=1}^n X_i\)을 사용한다.</li>
  <li>하지만 실제로는 소량의 labeled data \(\left\{X_i\right\}_{i=1}^n\)와 대량의 unlabeled data \(\left\{Y_i\right\}_{i=1}^N\), \(n&lt;&lt;N\)이 존재한다.</li>
  <li>Motivation : 대량의 unlabeled data를 사용하여 \(\bar{X}=\frac{1}{n} \sum_{i=1}^n X_i\)보다 좋은 (분산이 작은) unbiased estimator를 찾자.</li>
  <li><strong>Consider an estimator</strong> \(\widehat{\theta}=\frac{1}{n} \sum_{i=1}^n\left\{X_i-f\left(Y_i\right)\right\}+\frac{1}{N} \sum_{i=1}^N f\left(Y_i\right)\)​
    <ul>
      <li>\(f(Y)\)는  \(Y\)​로 만들 수 있는 estimator라고 생각하면 된다.</li>
      <li>지금은 \(f(Y)\)가 없는 부분이 unbiased이므로 \(f(Y)\)도 unbiased estimator이어야 한다.</li>
      <li>참고로 \(f(Y)=\mathbb E[X \mid Y]\)인 경우가 strong assumption이긴 하지만 optimal choice이다.</li>
    </ul>
  </li>
  <li>Unbiased ? (proof)</li>
</ul>

<p>: \(\begin{aligned} \mathbb{E}[\hat{\theta}] &amp; =\mathbb{E}\left[\frac{1}{n} \sum_{i=1}^n\left(X_i-f\left(Y_i\right)\right)\right]+\mathbb{E}\left[\frac{1}{N} \sum_{i=1}^N f\left(Y_i\right)\right] \\ &amp; =\frac{1}{n} \sum_{i=1}^n \mathbb{E}\left[X_i-f\left(Y_i\right)\right]+\frac{1}{N} \sum_{i=1}^N \mathbb{E}\left[f\left(Y_i\right)\right] \\ &amp; =\mathbb{E}[X]-\mathbb{E}[f(Y)]+\mathbb{E}[f(Y)] \quad\left(\text { when } Y_i^{\prime} \text { s are iid) }\right. \\ &amp; =\mathbb{E}[X]\end{aligned}\)</p>

<ul>
  <li>Improves the variance ? (proof)</li>
</ul>

<p>: \(\begin{aligned} \hat{\theta} &amp; =\frac{1}{n} \sum_{i=1}^n\left(X_i-f\left(Y_i\right)\right)+\frac{1}{N} \sum_{i=1}^N f\left(Y_i\right) \\ &amp; =\frac{1}{n} \sum_{i=1}^n X_i-\left(\frac{1}{n}-\frac{1}{N}\right) \sum_{=1}^n f\left(Y_i\right)+\frac{1}{N} \sum_{i=n+1}^N f\left(Y_i\right) \\ \operatorname{Var}(\hat{\theta}) &amp; =\operatorname{Var}\left(\frac{1}{n} \sum_{i=1}^n X_i\right)+\operatorname{Var}\left(-\left(\frac{1}{n}-\frac{1}{N}\right) \sum_{i=1}^n f\left(Y_i\right)\right) \\ &amp; \quad -2 \operatorname{Cov}\left(\frac{1}{n} \sum_{i=1}^n X_i,\left(\frac{1}{n}-\frac{1}{N}\right) \sum_{i=1}^n f\left(Y_i\right)\right)+\operatorname{Var}\left(\frac{1}{N} \sum_{i=1}^N f\left(Y_i\right)\right) \\ &amp; =\frac{1}{n} \operatorname{Var}(X)+\left(\frac{1}{n}-\frac{1}{N}\right)^2 \cdot n \operatorname{Var}(f(Y)) \\ &amp; \quad -2 \frac{1}{n}\left(\frac{1}{n}-\frac{1}{N}\right) n \operatorname{Cov}(X, f(Y))+\frac{N-n}{N^2} \operatorname{Var}(f(Y)) \\ &amp; =\frac{1}{n} \operatorname{Var}(X)+\left(\frac{1}{n}-\frac{2}{N}+\frac{n}{N^2}-\frac{N-n}{N^2}\right) \operatorname{Var}(f(Y))-2\left(\frac{1}{n}-\frac{1}{N}\right) \operatorname{Cov}\left(X, f(Y)\right) \\ &amp; =\frac{1}{n} \operatorname{Var}(X)+\left(\frac{1}{n}-\frac{2}{N}+\frac{1}{N}\right) \operatorname{Var}(f(Y))-2\left(\frac{1}{n}-\frac{1}{N}\right) \operatorname{Cov}\left(X, f(Y)\right) \\ &amp; =\frac{1}{n}\left[\operatorname{Var}(X)+\frac{N-n}{N}(\operatorname{Var}(f(Y))-2 \operatorname{Cov}(X, f(Y)))\right]\end{aligned}\)</p>

<ul>
  <li>
    <p>이 때 \(\operatorname{Var}[\bar{X}]=\operatorname{Var}[X] / n\) 이므로 \(\frac{1}{n}\left[\operatorname{Var}[X]+\frac{N-n}{N}\{\operatorname{Var}[f(Y)]-2 \operatorname{Cov}[X, f(Y)]\}\right]&lt;\frac{\operatorname{Var}[X]}{n}\)이면,</p>

    <ul>
      <li>즉 \(\operatorname{Var}[f(Y)]&lt;2 \operatorname{Cov}[X, f(Y)]\)이면 \(\hat \theta = \bar X\)보다 improve 된다.</li>
    </ul>
  </li>
  <li>\(f(Y)=\mathbb{E}[X \mid Y]\)을 가정했으므로 \(\begin{aligned}\operatorname{Var}[\widehat{\theta}]=\frac{1}{n}\left[\operatorname{Var}(X)+\frac{N-n}{N}(\operatorname{Var}(f(Y))-2 \operatorname{Cov}(X, f(Y)))\right]\end{aligned}\)이고,
    <ul>
      <li>Covariance 부분만 보면
        <ul>
          <li>\(\begin{aligned}
\operatorname{Cov}(X, \mathbb{E}[X \mid Y]) &amp; =\mathbb{E}[(X-\mathbb{E}[X])(\mathbb{E}[X \mid Y]-\mathbb{E}[X])]\\&amp;=\mathbb{E}\left[(\mathbb{E}[X \mid Y]-\mathbb{E}[X])^2\right] \\
&amp; =\operatorname{Var}[\mathbb{E}(X \mid Y)]
\end{aligned}\)이므로 대입하면</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>\(\begin{aligned}
\operatorname{Var}[\widehat{\theta}] &amp; =\frac{1}{n}\{\underbrace{\operatorname{Var}[X]}_{=\operatorname{Var}[\mathbb{E}(X \mid Y)]+\mathbb{E}[\operatorname{Var}(X \mid Y)]}+\frac{N-n}{N} \operatorname{Var}(\mathbb{E}[X \mid Y])-2 \frac{N-n}{N} \underbrace{\operatorname{Cov}(X, \mathbb{E}[X \mid Y])}_{=\operatorname{Var}[\mathbb{E}(X \mid Y)]}\} \\
&amp; =\frac{1}{n} \mathbb{E}[\operatorname{Var}(X \mid Y)]+\frac{1}{N} \operatorname{Var}[\mathbb{E}(X \mid Y)] \\
&amp; \leq \frac{1}{n} \mathbb{E}[\operatorname{Var}(X \mid Y)]+\frac{1}{n} \operatorname{Var}[\mathbb{E}(X \mid Y)]=\operatorname{Var}[\bar{X}],
\end{aligned}\)이다.</p>
  </li>
  <li>\(n &lt;&lt; N\)이므로 \(\hat \theta=\bar X\)의 분산이 작아졌다.</li>
  <li>이 방법의 본질은 \(X\)와 \(Y\)의 dependency이다.
    <ul>
      <li>만약 \(X\)와 \(Y\)가 independent이면 \(Y\)가 \(\mathbb E[X]\)에 대한 정보를 가지고 있지 않으므로 improvement가 없다.</li>
      <li>즉 본질적으로 Antithetic variable for Variance reduction과 같다.
        <ul>
          <li>(sample의 개수가 같더라도 iid가 아닌 negatively correlated sampling을 함으로써 estimator의 분산을 줄이는 방법)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="stat" /><summary type="html"><![CDATA[일반적으로 \(\left\{X_i\right\}_{i=1}^n\)으로 \(\mathbb{E}[X]\)를 estimate할 때 sample mean \(\hat \theta = \bar{X}=\frac{1}{n} \sum_{i=1}^n X_i\)을 사용한다. 하지만 실제로는 소량의 labeled data \(\left\{X_i\right\}_{i=1}^n\)와 대량의 unlabeled data \(\left\{Y_i\right\}_{i=1}^N\), \(n&lt;&lt;N\)이 존재한다. Motivation : 대량의 unlabeled data를 사용하여 \(\bar{X}=\frac{1}{n} \sum_{i=1}^n X_i\)보다 좋은 (분산이 작은) unbiased estimator를 찾자. Consider an estimator \(\widehat{\theta}=\frac{1}{n} \sum_{i=1}^n\left\{X_i-f\left(Y_i\right)\right\}+\frac{1}{N} \sum_{i=1}^N f\left(Y_i\right)\)​ \(f(Y)\)는 \(Y\)​로 만들 수 있는 estimator라고 생각하면 된다. 지금은 \(f(Y)\)가 없는 부분이 unbiased이므로 \(f(Y)\)도 unbiased estimator이어야 한다. 참고로 \(f(Y)=\mathbb E[X \mid Y]\)인 경우가 strong assumption이긴 하지만 optimal choice이다.]]></summary></entry><entry><title type="html">The Law of Total Probability / Total Expectation / Total Variance (Gumbel-Max trick, …)</title><link href="http://localhost:4000/stat/2024-04-14-lawtotal/" rel="alternate" type="text/html" title="The Law of Total Probability / Total Expectation / Total Variance (Gumbel-Max trick, …)" /><published>2024-04-14T00:00:00+09:00</published><updated>2024-04-15T09:39:45+09:00</updated><id>http://localhost:4000/stat/lawtotal</id><content type="html" xml:base="http://localhost:4000/stat/2024-04-14-lawtotal/"><![CDATA[<ul>
  <li>The Law of Total Probability
\(P(A)=\sum P\left(A \mid B_n\right) P\left(B_n\right)\)</li>
  <li>The Law of Total Expectation
\(\mathrm{E}(X)=\mathrm{E}(\mathrm{E}(X \mid Y))\)</li>
  <li>The Law of Total Variance
\(\operatorname{Var}(Y)=\mathrm{E}[\operatorname{Var}(Y \mid X)]+\operatorname{Var}(\mathrm{E}[Y \mid X])\)</li>
  <li>The Law of Total Covariance
\(\operatorname{cov}(X, Y)=\mathrm{E}(\operatorname{cov}(X, Y \mid Z))+\operatorname{cov}(\mathrm{E}(X \mid Z), \mathrm{E}(Y \mid Z))\)</li>
</ul>

<h2 id="the-law-of-total-probability">The Law of Total Probability</h2>

<p>\(P(A)=\sum P\left(A \mid B_n\right) P\left(B_n\right)\)</p>
<ul>
  <li>Example) <strong>Gumbel-Max trick</strong></li>
  <li>일반적으로 계산이 어려운 normalizing constant \(\sum \exp(\theta)\)를 계산하지 않으면서 categorical distribution에서 sample을 생성하는 technique</li>
  <li>다음과 같은 상황을 가정한다.</li>
  <li>\(X \sim Cat(\pi)\)는 \(1, ..., K\)중 하나의 class에 속하는 R.V (각 class에 속할 확률은 \(\pi_k\))</li>
</ul>

\[\begin{array}{c|ccccc} \hline k &amp; 1 &amp; 2 &amp; \cdots &amp; K-1 &amp; K \\ \hline P(X=k) &amp; \pi_1 &amp; \pi_2 &amp; \cdots &amp; \pi_{K-1} &amp; \pi_K \\ \hline \end{array}\]

<ul>
  <li>
    <p>Probability \(\pi\)는 다음과 같이 계산한다. \(\pi_i=\frac{\exp \left(\theta_i\right)}{\sum_{j \in[K]} \exp \left(\theta_j\right)} \quad \text { where }[K]=\{1,2, \ldots, K\}\)</p>
  </li>
  <li>이 경우 normalizaing constant \(\sum_{j \in[K]} \exp \left(\theta_j\right)\)를 계산해야 한다.</li>
  <li>
    <p>Gumbel-Max trick은 normalizaing constant를 계산하지 않는다.</p>
  </li>
  <li>
    <p><strong>\(X\)대신 \(Y=\arg \max _{j \in[K]}\left\{\theta_j+G_j\right\} \sim \operatorname{Cat}(\pi)\)을 사용하자 !</strong></p>

    <ul>
      <li>\(G_1, ..., G_k\)는 i.i.d standard Gumbel R.V</li>
      <li>즉 \(G\)의 CDF가 \(F(x)=e^{-e^{-x}} \text { for all } x \in \mathbb{R}\)</li>
      <li><strong>\(P(Y=i)=\pi_i \text { for each } i \in[K] \text {. }\)를 보이면 된다 !</strong></li>
    </ul>
  </li>
  <li>Proof</li>
</ul>

<p>: \(\begin{aligned}
    P(Y=i) &amp; =P\left(\theta_i+G_i \geq \max _{j \in[K] \backslash\{i\}}\left\{\theta_j+G_j\right\}\right)\\&amp;=\mathbb{E}\left[P\left(\theta_i+G_i \geq \max _{j \in[K] \backslash\{i\}}\left\{\theta_j+G_j\right\} \mid G_i\right)\right] \\ &amp; \text{by the law of total probability}\\
    &amp; =\int_{-\infty}^{\infty} f_{G_i}(x) P\left(\theta_i+G_i \geq \max _{j \in[K] \backslash\{i\}}\left\{\theta_j+G_j\right\} \mid G_i=x\right) d x \\
    &amp;=\int_{-\infty}^{\infty} f_{G_i}(x) P\left(\theta_i+x \geq \max _{j \in[K] \backslash\{i\}}\left\{\theta_j+G_j\right\}\right) d x \\ &amp;=\int_{-\infty}^{\infty} f_{G_i}(x) A\ dx
    \end{aligned}\)</p>

<p>where \(\begin{aligned}A &amp;= P\left(\theta_i+x \geq \max _{j \in[K] \backslash\{i\}}\left\{\theta_j+G_j\right\}\right)\\ &amp; =\prod_{j \in[K] \backslash\{i\}} P\left(G_j \leq x+\theta_i \theta_j\right)\\&amp;=\prod_{j \in[K] \backslash\{i\}} e^{-e^{-x-\theta_i+\theta_j}} \\ &amp;=e^{-B} \end{aligned}\)</p>

<p>where \(\begin{aligned}B &amp;= e^{-x+\theta_i+\theta_1}+e^{-x+\theta_i+\theta_2}+...\\&amp;= e^{-x-\theta_1} \sum_{j \in[K] \backslash\{i\}} e^{\theta_j} \\ &amp;=e^{-x} \frac{\sum_{j \in[K] \backslash\{i\}} e^{\theta_j}}{e^{-\theta_i}} \\ &amp;= e^{-x}\frac{1-\pi_i}{\pi_i}\end{aligned}\)</p>

<ul>
  <li>
    <p>therefore, \(\begin{aligned} A &amp;= e^{-B} = e^{-e^{-x} \times \frac{1-\pi_i}{\pi_i}}\end{aligned}\)​</p>
  </li>
  <li>
    <p>finally,  \(\begin{aligned} P(Y=i) &amp; =\int_{-\infty}^{\infty} f_{G_i}(x) e^{-e^{-x} \times \frac{1-\pi_i}{\pi_i}} d x \\&amp; =\int_{-\infty}^{\infty} e^{-x-e^{-x}} e^{-e^{-x} \times \frac{1-\pi_i}{\pi_i}} d x \\ &amp; =\int_{-\infty}^{\infty} e^{-x-e^{-x} \pi_i^{-1}} d x \\ &amp; =\pi_i \int_{-\infty}^{\infty} e^{-\left[\left(x-\log \frac{1}{\pi_i}\right)+e^{\left.-\left(x-\log \frac{1}{\pi_i}\right)\right]}\right.} d x=\pi_i \\ &amp;\because \int e^{-(x+A+e^{(-x+A)})}dx = 1\end{aligned}\)</p>
  </li>
</ul>

<h2 id="the-law-of-total-expectation">The Law of Total Expectation</h2>

<p>\(\mathrm{E}(X)=\mathrm{E}(\mathrm{E}(X \mid Y))\)</p>
<ul>
  <li>Proof</li>
</ul>

<p>: \(\begin{aligned}
    \mathrm{E}[\mathrm{E}(X \mid Y)] &amp; =\mathrm{E}\left[\sum_{x \in \mathcal{X}} x \cdot \operatorname{Pr}(X=x \mid Y)\right] \\
    &amp; =\sum_{y \in \mathcal{Y}}\left[\sum_{x \in \mathcal{X}} x \cdot \operatorname{Pr}(X=x \mid Y=y)\right] \cdot \operatorname{Pr}(Y=y) \\ &amp; =\sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} x \cdot \operatorname{Pr}(X=x \mid Y=y) \cdot \operatorname{Pr}(Y=y) \\ &amp; =\sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} x \cdot \operatorname{Pr}(X=x, Y=y) \\&amp; =\sum_{x \in \mathcal{X}} x \sum_{y \in \mathcal{Y}} \operatorname{Pr}(X=x, Y=y)\\  &amp; =\sum_{x \in \mathcal{X}} x \cdot \operatorname{Pr}(X=x) \\ &amp; =\mathrm{E}(X) \end{aligned}\)</p>

<ul>
  <li>Example)
    <ul>
      <li>\(\begin{aligned} X \mid P &amp;\sim \operatorname{Binomial}(n, P), \\ P &amp;\sim \operatorname{Beta}(\alpha, \beta) \end{aligned}\)이면</li>
      <li>\(\mathbb{E}[X]=\mathbb{E}[\mathbb{E}(X \mid P)]=\mathbb{E}[n P]=n \frac{\alpha}{\alpha+\beta}\)이다.</li>
    </ul>
  </li>
</ul>

<h2 id="the-law-of-total-variance">The Law of Total Variance</h2>

<ul>
  <li>
    <p>\(\operatorname{Var}(Y)=\mathrm{E}[\operatorname{Var}(Y \mid X)]+\operatorname{Var}(\mathrm{E}[Y \mid X])\) (EVVE)</p>
  </li>
  <li>
    <p>Proof</p>
  </li>
</ul>

<p>: \(\begin{aligned}
  Var[X]&amp;=\mathbb{E}\left[(X-\mathbb{E}[X])^2\right]\\&amp;=\mathbb{E}\left[(X-\mathbb{E}[X \mid Y]+\mathbb{E}[X \mid Y]-\mathbb{E}[X])^2\right]\\&amp; =\mathbb{E}\left[(X-\mathbb{E}[X \mid Y])^2\right]+\mathbb{E}\left[(\mathbb{E}[X \mid Y]-\mathbb{E}[X])^2\right] \\&amp;\quad +2 \mathbb{E}([X-\mathbb{E}(X \mid Y)]\left[\mathbb{E}(X \mid Y)-\mathbb{E}(X)\right])\\&amp;=\mathbb{E}\left[(X-\mathbb{E}[X \mid Y])^2\right]+\mathbb{E}\left[(\mathbb{E}[X \mid Y]-\mathbb{E}[X])^2\right] \\ &amp;=\mathbb{E}[Var(X\mid Y)] + Var[\mathbb{E}(X \mid Y)]\\ &amp; \because \mathbb{E}[X-\mathbb{E}(X \mid Y)] = \mathbb{E}[\mathbb{E}[X-\mathbb{E}(X \mid Y)]\mid Y]=0
  \end{aligned}\)</p>

<ul>
  <li>Example)
    <ul>
      <li>
        <p>\(\begin{aligned} X \mid Y &amp;\sim \operatorname{Binomial}(n, P), \\ Y &amp;\sim \operatorname{Beta}(\alpha, \beta) \end{aligned}\)이면</p>
      </li>
      <li>
        <p>\(\begin{aligned}Var(X)&amp;=\mathrm{E}[\operatorname{Var}(X \mid Y)]+\operatorname{Var}(\mathrm{E}[X \mid Y])\end{aligned}\)​</p>
      </li>
    </ul>
  </li>
</ul>

<p>: \(\begin{aligned}
  \mathbb{E}[\operatorname{Var}(X \mid Y)] &amp; =n\left(\mathbb{E}[Y]-\mathbb{E}\left[Y^2\right]\right)\\&amp;=n\left(\frac{\alpha}{\alpha+\beta}-\frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)}-\frac{\alpha^2}{(\alpha+\beta)^2}\right) \\ &amp; =n \frac{\alpha \beta}{(\alpha+\beta)(\alpha+\beta+1)} \\ \operatorname{Var}[\mathbb{E}(X \mid Y)]&amp;=\operatorname{Var}[n P]=n^2 \frac{\alpha \beta}{(\alpha+\beta)^2(\alpha+\beta+1)} \\ \therefore \operatorname{Var}[X]&amp;=n \frac{\alpha \beta(\alpha+\beta+n)}{(\alpha+\beta)^2(\alpha+\beta+1)}
  \end{aligned}\)​</p>

<h2 id="the-law-of-total-covariance">The Law of Total Covariance</h2>

<ul>
  <li>
    <p>\(\operatorname{cov}(X, Y)=\mathrm{E}(\operatorname{cov}(X, Y \mid Z))+\operatorname{cov}(\mathrm{E}(X \mid Z), \mathrm{E}(Y \mid Z))\).</p>
  </li>
  <li>
    <p>\(\begin{aligned}\operatorname{Cov}\left(X_i, X_j\right) &amp;\leq \sqrt{\operatorname{Var}\left(X_i\right) \operatorname{Var}\left(X_j\right)} \leq \operatorname{Var}\left(X_i\right) / 2+\operatorname{Var}\left(X_j\right) / 2 \\ &amp;\text{by }x y \leq x^2 / 2+y^2 / 2 \end{aligned}\).</p>
  </li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="stat" /><summary type="html"><![CDATA[The Law of Total Probability \(P(A)=\sum P\left(A \mid B_n\right) P\left(B_n\right)\) The Law of Total Expectation \(\mathrm{E}(X)=\mathrm{E}(\mathrm{E}(X \mid Y))\) The Law of Total Variance \(\operatorname{Var}(Y)=\mathrm{E}[\operatorname{Var}(Y \mid X)]+\operatorname{Var}(\mathrm{E}[Y \mid X])\) The Law of Total Covariance \(\operatorname{cov}(X, Y)=\mathrm{E}(\operatorname{cov}(X, Y \mid Z))+\operatorname{cov}(\mathrm{E}(X \mid Z), \mathrm{E}(Y \mid Z))\)]]></summary></entry><entry><title type="html">Total variation distance and Convergence in distribution</title><link href="http://localhost:4000/stat/2024-04-14-dTV/" rel="alternate" type="text/html" title="Total variation distance and Convergence in distribution" /><published>2024-04-14T00:00:00+09:00</published><updated>2024-04-14T14:37:24+09:00</updated><id>http://localhost:4000/stat/dTV</id><content type="html" xml:base="http://localhost:4000/stat/2024-04-14-dTV/"><![CDATA[<ul>
  <li>통계학에서 Convergence in distribution은 중요한 성질이다. 우리는 Sample size n이 커질수록 확률변수 또는 estimator가 어떤 분포에 가까워지는지 궁금하기 때문이다.</li>
  <li>그러므로 Convergence in distribution을 imply하는 성질도 중요하다. Convergence in distribution을 보일 수 있는 방법들 중 하나가 되기 때문이다.</li>
  <li>Total variation distance는 두 분포 사이의 distance metric 중 하나이다. Total variation distance가 작으면 두 분포가 가깝다는 의미이다.</li>
  <li>본 게시글에서는 Total variation distance에 대해서 알아보고 <strong>Total variation distance가 0으로 수렴</strong>하면 한 분포가 다른 분포로 근사한다, 즉 Convergence in distribution한다는 것을 보인다.</li>
</ul>

<h2 id="total-variation-distanced_tv">Total variation distance(\(d_{TV}\))</h2>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Total_variation_distance_of_probability_measures">Wikipedia</a>에 따르면 Total variation distance의 정의는 아래와 같다.
    <ul>
      <li>Consider a measurable space \((\Omega, \mathcal{F})\) and probability measures \(P\) and \(Q\) defined on \((\Omega, \mathcal{F})\). The total variation distance between \(P\) and \(Q\) is defined as: \(\delta(P, Q)=\sup _{A \in \mathcal{F}}\mid P(A)-Q(A)\mid\)​</li>
    </ul>
  </li>
  <li>\(d_{TV}\)​는 half of the L1 distance btw/ the probability functions이다.
    <ul>
      <li><img src="/assets/img/stat/dTV/fig1.png" alt="그림1" /></li>
      <li>Geometric 의미는 두 분포의 차이에 해당하는 회색 영역의 넓이를 2로 나눈 값이다.</li>
      <li>discrete : \(\delta(P, Q)=\frac{1}{2} \sum_x\mid P(x)-Q(x)\mid\)</li>
      <li>continuous : \(\delta(P, Q)=\frac{1}{2} \int\mid p(x)-q(x)\mid  \mathrm{d} x\)​</li>
      <li>\(\frac{1}{2}\)를 곱해주는 이유는 \(0 \le d_{TV} \le 1\)으로 만들어주기 위함인데, 아래 사진처럼 \(d_{TV}\)가 매우 큰 경우에 두 분포의 차이의 넓이가 2에 가까워지기 때문에 \(\frac{1}{2}\)를 곱한다.</li>
      <li><img src="/assets/img/stat/dTV/fig2.png" alt="그림2" /></li>
    </ul>
  </li>
</ul>

<h2 id="convergence-in-total-variation-distance">Convergence in Total variation distance</h2>

<ul>
  <li>Convergence in Total variation distance는 Convergence in distribution보다 강력한 성질이다.</li>
  <li>
    <p><strong>즉 두 분포의 Total variation distance가 0으로 수렴하면, 두 분포는 Convergence in distribution이다.</strong></p>

    <p>: \(\begin{aligned}\text{When }\delta(P, Q)&amp;=\sup _{A \in \mathcal{F}}\mid P(A)-Q(A)\mid  \\ \lim _{n \rightarrow \infty} \delta\left(P_n, Q\right)&amp;=0 \\ \lim _{n \rightarrow \infty}\mid P_n(A)-Q(A)\mid &amp;=0 \quad \forall A \in \mathcal{F} \\ \lim _{n \rightarrow \infty}\mid F_n(x)-F(x)\mid &amp;=0 \end{aligned}\)</p>
  </li>
  <li>
    <p>하지만 역은 성립하지 않는다. Convergence in distribution이라고 해서 Total variation distance가 0으로 수렴하는 것은 아니다.</p>

    <ul>
      <li>Counterexample : \(f_n \sim \frac{2}{\pi} \cos ^2(n x) \mathbf{1}_{[0, \pi]}(x) d x\)</li>
    </ul>

    <p>: \(\begin{aligned}F_n(x)&amp;=\int_0^x f_n(t)dt \\ &amp;=\int_0^x\frac{2}{\pi} \cos ^2(nt) \mathbf{1}_{[0, \pi]}(x)dt \\ &amp; = \frac{2}{\pi}\mathbf{1}_{[0, \pi]}(x) \int_0^x \cos ^2(nt)dt \\ &amp;= \frac{2}{\pi}\mathbf{1}_{[0, \pi]}(x) \frac{sin(2nx)+2nx}{4n} \\  \lim_{n \to \infty} F_n(x) &amp;=\frac{2}{\pi}\mathbf{1}_{[0, \pi]}(x) \frac{x}{2} \\ &amp;=\frac{x}{\pi},\quad 0 \le x \le \pi \end{aligned}\)</p>

    <ul>
      <li>즉 \(\lim_{n \to \infty} F_n = F_{\infty}\)는 \(Unif(0, \pi)\)의 CDF가 되므로 Convergence in distribution이다.</li>
      <li>하지만 \(\lim_{n \to \infty}d_{TV}(F_n, F_{\infty}) \nrightarrow 0\)이다.</li>
    </ul>

    <p>: \(\begin{aligned} d_{TV}\left(F_n, F_{\infty}\right) &amp; =\frac{1}{2} \int_0^\pi\mid f_n(x)-f_{\infty}(x)\mid  d x \\ &amp; =\frac{1}{2} \int_0^\pi\mid \frac{2}{\pi} \cos ^2(n x)-\frac{1}{\pi}\mid  d x \\ &amp; =\frac{1}{\pi} \int_0^\pi\mid \cos ^2(n x)-\frac{1}{2}\mid  d x \\ &amp; &gt;0 \quad \text{strictly positive} \end{aligned}\)</p>

    <ul>
      <li><img src="/assets/img/stat/dTV/fig3.png" alt="그림3" /></li>
      <li>\(cos^2(nx)\)는 0과 1사이에서의 주기 함수이고, \(n\)이 커져도 주기가 짧아질 뿐이다.</li>
      <li>그러므로 \(\mid \cos ^2(n x)-\frac{1}{2}\mid\)는 n과 관계없이 strictly positive이다. 즉 Total variation distance가 0으로 수렴하지 않는다.</li>
      <li>만약 \(f_n, f_{\infty}\)​가 continuous random variable의 density이고 unimodal한 경우에는 Convergence in distribution과 Total variation distance이 0으로 수렴하는 것은 if and only if(필요충분)이다. (skip the proof)</li>
      <li><a href="https://hal.science/hal-00821911/document">Reference : Ivan Nourdin, Guillaume Poly, Convergence in law implies convergence in total variation for polynomials in independent Gaussian, Gamma or Beta random variables</a></li>
    </ul>
  </li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="stat" /><summary type="html"><![CDATA[통계학에서 Convergence in distribution은 중요한 성질이다. 우리는 Sample size n이 커질수록 확률변수 또는 estimator가 어떤 분포에 가까워지는지 궁금하기 때문이다. 그러므로 Convergence in distribution을 imply하는 성질도 중요하다. Convergence in distribution을 보일 수 있는 방법들 중 하나가 되기 때문이다. Total variation distance는 두 분포 사이의 distance metric 중 하나이다. Total variation distance가 작으면 두 분포가 가깝다는 의미이다. 본 게시글에서는 Total variation distance에 대해서 알아보고 Total variation distance가 0으로 수렴하면 한 분포가 다른 분포로 근사한다, 즉 Convergence in distribution한다는 것을 보인다.]]></summary></entry><entry><title type="html">(Dish-TS) A General Paradigm for Alleviating Distribution Shift in Time Series Forecasting (AAAI 2023)</title><link href="http://localhost:4000/timeseries/2024-04-12-Dish-TS/" rel="alternate" type="text/html" title="(Dish-TS) A General Paradigm for Alleviating Distribution Shift in Time Series Forecasting (AAAI 2023)" /><published>2024-04-12T00:00:00+09:00</published><updated>2024-04-12T19:26:03+09:00</updated><id>http://localhost:4000/timeseries/Dish-TS</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-04-12-Dish-TS/"><![CDATA[<h2 id="abstract">Abstract</h2>

<ul>
  <li>Distribution shift in TS : series distribution changes over time</li>
  <li>기존 연구들은 the quantification of distribution 정도</li>
  <li>Distribution shift in TS는 2개 카테고리
    <ul>
      <li><strong>intra-space shift</strong> : the distribution within the input-space keeps shifted over time</li>
      <li><strong>inter-space shift</strong> : that the distribution is shifted btw/ input-space and output-space</li>
    </ul>
  </li>
  <li>Dish-TS : neural paradigm for alleviating distribution shift in TSF
    <ul>
      <li>CONET : can be any NN, input sequences into learnable distribution coefficients</li>
      <li>Dual-CONET : separately learn the distribution of input- and output-space</li>
    </ul>
  </li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>

<p><img src="/assets/img/timeseries/Dish-TS/fig1.png" alt="사진1" /></p>

<ul>
  <li>TS의 non-stationarity(distribution shift over time)는 예측 성능을 방해</li>
  <li><strong>intra-space shift</strong> :  TS distribution changes over time</li>
  <li><strong>inter-space shift</strong> :  Distribution shift btw/ input-space (lookbacks) and output-space (horizons)</li>
  <li>대표적인 alleviate distribution shift solution : RevIN.
    <ul>
      <li>Quantifying true distribution with fixed statistics (e.g., mean and std.)
        <ul>
          <li>But, unreliable (limited in expressiveness for representing the true distribution)</li>
          <li>Different sampling frequencies provide different statistics</li>
        </ul>
      </li>
      <li>Strong assumption : the lookbacks and horizons share the same statistical properties</li>
      <li>But,  always a variation in distribution btw/ input-space and output-space</li>
    </ul>
  </li>
  <li>Dish-TS는 RevIN으로부터 영감을 받은 만큼 전체적인 구조는 유사하다
    <ul>
      <li>two-stage process : normalizing \(\to\) forecasting \(\to\) denormalizing</li>
      <li>CONET : window \(\to\) two learnable coefficients:
        <ul>
          <li>a level coefficient and a scaling coefficient</li>
          <li>to illustrate series overall scale and fluctuation</li>
        </ul>
      </li>
      <li>Dual-CONET
        <ul>
          <li>BACKCONET : coefficients to estimate the distribution of input-space (lookbacks)</li>
          <li>HORICONET : coefficients to infer the distribution of output-space (horizons)</li>
        </ul>
      </li>
      <li>Prior-knowledge : HORICONET 학습할 때 prior 줘서 output-space를 잘 infer(predict) 하도록</li>
    </ul>
  </li>
</ul>

<h2 id="2-related-work">2. Related Work</h2>

<ul>
  <li>Models for Time Series Forecasting
    <ul>
      <li>ARMA, BEATS, Transformer, Informer, Autoformer, …</li>
    </ul>
  </li>
  <li>Distribution Shift in Time Series Forecasting
    <ul>
      <li>Adaptive Norm :  puts z-score normalization on series by the computed global statistics</li>
      <li>DAIN (Passalis et al. 2019) :  applies nonlinear NN to adaptively normalize the series</li>
      <li>RevIN (Kim et al. 2022) : instance normalization to reduce series shift</li>
    </ul>
  </li>
  <li>대부분의 연구가 static statistics 사용해서 normalizing한다. (inter-space shift 고려 안함)</li>
</ul>

<h2 id="3-problem-formulations">3. Problem Formulations</h2>

<ul>
  <li>
    <p>Time Series Forecasting</p>

    <ul>
      <li>Formula : \(\left(x_{t: t+H}^{(1)}, \cdots, x_{t: t+H}^{(N)}\right)^T=\mathscr{F}_{\Theta}\left(\left(x_{t-L: t}^{(1)}, \cdots, x_{t-L: t}^{(N)}\right)^T\right)\)​</li>
      <li>\(\mathscr{F}_{\Theta}: \mathbb{R}^{L \times N} \rightarrow \mathbb{R}^{H \times N}\),   \(\Theta\) :  forecasting model parameters</li>
    </ul>
  </li>
  <li>
    <p>Distribution Shift in Time Series</p>

    <ul>
      <li>intra-space shift : \(\mid d\left(\mathcal{X}_{\text {input }}^{(i)}(u), \mathcal{X}_{\text {input }}^{(i)}(v)\right)\mid &gt;\delta\)​</li>
      <li>
        <p>inter-space shift : \(\mid d\left(\mathcal{X}_{\text {input }}^{(i)}(u), \mathcal{X}_{\text {output }}^{(i)}(u)\right)\mid &gt;\delta\)</p>
      </li>
      <li>\(\mathcal{X}_{\text {input }}^{(i)}(u)\)는 \(t=u\) 시점으로부터 과거 방향으로 \(L\) 길이의 lookback window</li>
      <li>\(\mathcal{X}_{\text {output }}^{(i)}(u)\)는 \(t=u\) 시점으로부터 미래 방향으로 \(H\) 길이의 horizon window</li>
    </ul>
  </li>
</ul>

<h2 id="4-dish-ts">4. Dish-TS</h2>

<h3 id="41-overview">4.1. Overview</h3>

<p><img src="/assets/img/timeseries/Dish-TS/fig2.png" alt="사진2" /></p>

<ul>
  <li>CONET :  input series \(\to\)​​ coefficients (for distribution measurement)</li>
  <li>RevIN처럼 two-stage process
    <ul>
      <li>BACKCONET : transformed the lookbacks (before forecasting model)</li>
      <li>HORICONET : transformed the forecasting results
        <ul>
          <li>HORICONET can be trained in a prior knowledgeinduced fashion (4.4에서 설명)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="42-dual-conet-framework">4.2. Dual-Conet Framework</h3>

<ul>
  <li>기존 연구들은 mean, std로 distribution을 measure \(\to\)​ unreliable (Different frequencies different statistics)</li>
  <li>기본 CONET구조
    <ul>
      <li>\(\varphi, \xi=\operatorname{CONET}(x)\) : any NN (can non-linear mapping)
        <ul>
          <li>\(\varphi \in \mathbb{R}^1\) : level coefficient (overall scale of input series)</li>
          <li>\(\xi \in \mathbb{R}^1\) : scaling coefficient (fluctuation scale)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Mutivariate forecasting을 위한 Dual-CONET
    <ul>
      <li>\(\begin{aligned}
&amp; \varphi_{b, t}^{(i)}, \xi_{b, t}^{(i)}=\operatorname{BACKCONET}\left(x_{t-L: t}^{(i)}\right), i=1, \cdots, N \\
&amp; \varphi_{h, t}^{(i)}, \xi_{h, t}^{(i)}=\operatorname{HORICONET}\left(x_{t-L: t}^{(i)}\right), i=1, \cdots, N
\end{aligned}\)​
        <ul>
          <li>\(\varphi_{b, t}^{(i)}, \xi_{b, t}^{(i)} \in \mathbb{R}^1\) : level, scaling coefficients for lookbacks</li>
          <li>\(\varphi_{h, t}^{(i)}, \xi_{h, t}^{(i)} \in \mathbb{R}^1\) : level, scaling coefficients for horizons</li>
        </ul>
      </li>
      <li>BACKCONET과 HORICONET 둘다 input이 “t 시점에서 L 길이의 historical series”이다 !</li>
    </ul>
  </li>
  <li>Integrating Dual-Conet into Forecasting
    <ul>
      <li>Final transformed forecasting results : \(\hat{x}_{t: t+H}^{(i)}=\xi_{h, t}^{(i)} \mathscr{F}_{\Theta}\left(\frac{1}{\xi_{b, t}^{(i)}}\left(x_{t-L: t}^{(i)}-\varphi_{b, t}^{(i)}\right)\right)+\varphi_{h, t}^{(i)}\)</li>
    </ul>
  </li>
</ul>

<h3 id="43-a-simple-and-intuitive-instance-of-conet">4.3. A Simple and Intuitive Instance of Conet</h3>

<ul>
  <li>실제 CONET에서의 연산은 다음과 같다.</li>
  <li>lookback level coefficient : \(\varphi_{b, t}^{(i)}=\sigma\left(\sum_{\tau=1}^{\operatorname{dim}\left(\mathbf{v}_{b, i}^{\ell}\right)} \mathbf{v}_{b, i \tau}^{\ell} x_{\tau-L+t}^{(i)}\right),\)</li>
  <li>horizons level coefficient : \(\varphi_{h, t}^{(i)}=\sigma\left(\sum_{\tau=1}^{\operatorname{dim}\left(\mathbf{v}_{h, i}^{\ell}\right)} \mathbf{v}_{h, i \tau}^{\ell} x_{\tau-L+t}^{(i)}\right)\)​</li>
  <li>lookback scaling coefficient : \(\xi_{b, t}^{(i)}=\sqrt{\mathbb{E}\left(x_t^{(i)}-\varphi_{b, t}^{(i)}\right)^2}\)</li>
  <li>horizons scaling coefficient : \(\xi_{h, t}^{(i)}=\sqrt{\mathbb{E}\left(x_t^{(i)}-\varphi_{h, t}^{(i)}\right)^2}\)</li>
</ul>

<h3 id="44-prior-knowledge-induced-training-strategy">4.4. Prior Knowledge-Induced Training Strategy</h3>

<ul>
  <li>HORICONET은 미래의 정보인 \(\mathcal{X}_{\text {output }}^{(i)}\)의 분포를 infer(predict)해야 하기 때문에 intractable하다.</li>
  <li>그러므로 prior(mean of horizons)을 soft-target으로 줘서 학습의 난이도를 낮춘다.</li>
  <li>final loss는 \(\sum_{k=1}^K \sum_{i=1}^N[\left(\hat{x}_{t_k: t_k+H}^{(i)}-x_{t_k: t_k+H}^{(i)}\right)^2+\underbrace{\left.\alpha\left(\frac{1}{H} \sum_{t=t_k+1}^{t_k+H} x_t^{(i)}-\varphi_{h, t_k}^{(i)}\right)^2\right]}_{\text {Prior Knowledge Guidance }}\)이다.
    <ul>
      <li>MSE term에 prior knowledge를 \(\alpha\)의 weight로 준다.</li>
    </ul>
  </li>
</ul>

<h2 id="5-experiment">5. Experiment</h2>

<p><img src="/assets/img/timeseries/Dish-TS/table1.png" alt="사진3" /></p>

<p><img src="/assets/img/timeseries/Dish-TS/table2.png" alt="사진4" /></p>

<p><img src="/assets/img/timeseries/Dish-TS/table3.png" alt="사진5" /></p>

<p>Dish-TS를 적용하면 Informer, Autoformer, N-BEATS의 성능이 향상되고, 그 정도는 RevIN보다 크다.</p>

<h2 id="6-conclusion">6. Conclusion</h2>

<ul>
  <li>Systematically summarize the distribution shift in time series forecasting</li>
  <li>as intra-space shift and interspace shift.</li>
  <li>Dish-TS better alleviates the two shift
    <ul>
      <li>prior knowledge-induced training strategy, for effectiveness</li>
    </ul>
  </li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[AAAI 2023](https://arxiv.org/pdf/2302.14829.pdf)]]></summary></entry><entry><title type="html">MGF(Moment Generating Function) and Characteristic Function에 대해서</title><link href="http://localhost:4000/stat/2024-04-12-MGF/" rel="alternate" type="text/html" title="MGF(Moment Generating Function) and Characteristic Function에 대해서" /><published>2024-04-12T00:00:00+09:00</published><updated>2024-04-13T15:39:49+09:00</updated><id>http://localhost:4000/stat/MGF</id><content type="html" xml:base="http://localhost:4000/stat/2024-04-12-MGF/"><![CDATA[<h2 id="moments">Moments</h2>

<ul>
  <li>Definition
    <ul>
      <li>For each integer \(n\), the \(n\)th moment of \(X\) is \(\mu_n=\mathbb{E}\left[X^n\right]\).</li>
      <li>The \(n\)th central moment of \(X\) is \(\mu_n^{\prime}=\mathbb{E}\left[(X-\mu)^n\right]\) where \(\mu=\mu_1^{\prime}=\mathbb{E}[X]\)</li>
    </ul>
  </li>
  <li><u>확률변수의 moments는 tail probability와 밀접한 연관이 있다.</u>
    <ul>
      <li>
        <p>Let \(X\) is non-negative random variable</p>

        <p>: \(\begin{aligned}\mathbb{E}[X]&amp;=\mathbb{E}\left[\int_0^{\infty} \mathbb{1}(t&lt;X) d t\right]\\&amp;=\int_0^{\infty} \mathbb{E}[\mathbb{1}(t&lt;X)] d t\\&amp;=\int_0^{\infty} P(t&lt;X) d t\\&amp;=\int_0^{\infty}\left[1-F_X(x)\right] d x \end{aligned}\)</p>
      </li>
      <li>
        <p>위 결과를 확장하면 아래와 같다.</p>

        <p>: \(\begin{aligned} \mathbb{E}\left[\mid X\mid ^p\right] &amp; =\int_0^{\infty}\left[1-F_{\mid X\mid ^p}(y)\right] d y \\ P\left(\mid X\mid ^p&gt;y\right) &amp; =P\left(\mid X\mid &gt;y^{\frac{1}{p}}\right) \\ &amp; =1-F_{\mid X\mid }\left(y^{\frac{1}{p}}\right) \\ \text{Let } y&amp;=x^p, \text{then } \frac{d y}{d x}=p x^{p-1} \\ \mathbb{E}\left[\mid X\mid ^p\right] &amp; =\int_0^{\infty}\left[1-F_{\mid X\mid }(x)\right] p x^{p-1} d x \\ &amp; =\int_0^{\infty} p x^{p-1} P(\mid X\mid &gt;x) d x \end{aligned}\)</p>
      </li>
    </ul>
  </li>
</ul>

<h2 id="moment-generating-function">Moment Generating Function</h2>

<ul>
  <li>
    <p>Definition : \(M_X(t)=\mathbb{E}\left[e^{t X}\right]\)</p>
  </li>
  <li>
    <p>MGF가 왜 중요할까 ?</p>

    <ul>
      <li><u>첫째, 확률변수 X의 MGF는 X의 모든 moments를 생성한다.</u></li>
      <li><u>둘째, 확률변수 X의 MGF는 X의 분포를 uniquely 결정한다.</u></li>
      <li><u>셋째, MGF의 수렴은 분포수렴(convergence in distribution)을 의미한다.</u></li>
      <li><u>넷째, MGF로 probability tail bound를 구한다. (Hoeffding's inequality)</u></li>
    </ul>
  </li>
</ul>

<h3 id="첫째-확률변수-x의-mgf는-x의-모든-moments를-생성한다">첫째, 확률변수 X의 MGF는 X의 모든 moments를 생성한다.</h3>

<ul>
  <li>
    <p>Step1) MGF가 존재한다고 가정했다면 \(\mathbb{E}\left[e^{\mid t X\mid }\right] \leq \mathbb{E}\left[e^{t X}\right]+\mathbb{E}\left[e^{-t X}\right]&lt;\infty \quad \text { for all }\mid t\mid &lt;\epsilon\)​</p>
  </li>
  <li>
    <p>c.f. <strong>(Dominated Convergence Theorem)</strong>. If \(\left\{f_n: \mathbb{R} \mapsto \mathbb{R}\right\}\) is a sequence of measurable functions which converge pointwise almost everywhere to \(f\), and if there exists an integrable function \(g\) (that is \(\left.\int_{-\infty}^{\infty}\mid g(x)\mid  d x&lt;\infty\right)\) such that \(\mid f_n(x)\mid  \leq\mid g(x)\mid\) for all \(n\) and for all \(x\), then \(f\) is integrable and</p>

    <ul>
      <li>\(\int_{-\infty}^{\infty} f(x) d x=\int_{-\infty}^{\infty} \lim _{n \rightarrow \infty} f_n(x) d x=\lim _{n \rightarrow \infty} \int_{-\infty}^{\infty} f_n(x) d x\)​​</li>
      <li>즉 \(\mid f_n(x)\mid\)의 bound 역할을 하는 \(\mid g(x)\mid\)가 \(\int_{-\infty}^{\infty}\mid g(x)\mid  d x&lt;\infty\)이면 \(\int_{-\infty}^{\infty} \lim _{n \rightarrow \infty} f_n(x) d x\)의 \(\int\)와 \(\lim\)의 위치를 바꿀 수 있다.</li>
    </ul>
  </li>
  <li>
    <p>Step2) DCT에 의해 X의 MGF는 아래와 같다.</p>

    <ul>
      <li>MGF</li>
    </ul>

    <p>: \(\begin{aligned}\int_{-\infty}^{\infty} e^{t x} f_X(x) d x &amp; =\lim _{n \rightarrow \infty} \int_{-\infty}^{\infty} \sum_{j=0}^n t^j \frac{x^j}{j !} f_X(x) d x \\ &amp; =\lim _{n \rightarrow \infty} \sum_{j=0}^n \frac{t^j}{j !} \underbrace{\int_{-\infty}^{\infty} x^j f_X(x) d x}_{=\mu_j} \\ &amp; =\sum_{j=0}^{\infty} \frac{t^j \mu_j}{j !} \end{aligned}\)</p>

    <ul>
      <li>moment</li>
    </ul>

    <p>: \(\begin{aligned} M_X^{(m)}(t) &amp; =\frac{d^m}{d t^m}\left(\sum_{k=0}^{\infty} \frac{t^k \mu_k}{k !}\right) \\ &amp; =\sum_{k=0}^{\infty} \frac{\mu_k}{k !} \frac{d^m\left(t^k\right)}{d t^m} \\ &amp; =\sum_{k=m}^{\infty} \mu_k \frac{t^{k-m}}{(k-m) !} \\ &amp; =\sum_{j=0}^{\infty} \mu_{m+j} \frac{t^j}{j !} \quad(j \equiv k-m) \end{aligned}\)</p>
    <ul>
      <li>Thus, \(M_X^{(m)}(0)=\mathbb{E}\left[X^m\right] \text { by noting } 0^0=1,0^j=0 \text { for } j \geq 1\)</li>
    </ul>
  </li>
</ul>

<h3 id="둘째-확률변수-x의-mgf는-x의-분포를-uniquely-결정한다">둘째, 확률변수 X의 MGF는 X의 분포를 uniquely 결정한다.</h3>

<ul>
  <li>
    <p>확률변수 X와 Y의 분포가 같다면 \(\to\) MGF가 같다는 것을 보이는 것은 쉽다.</p>
  </li>
  <li>
    <p>반대로 두 확률변수 X와 Y의 MGF가 같으면 같은 분포를 따름은 아래와 같이 증명한다.</p>
  </li>
  <li>
    <p>Suppose that \(X\) and \(Y\) have the same MGF for all \(t\) : \(\sum_{x=0}^n e^{t x} f_X(x)=\sum_{y=0}^n e^{t y} f_Y(y)\)
  Let \(s=e^t\) and \(c_i=f_X(i)-f_Y(i)\) for \(i=0,1, \ldots, n\)</p>
  </li>
</ul>

<p>: \(\begin{aligned} \sum_{x=0}^n e^{t x} f_X(x)-\sum_{y=0}^n e^{t y} f_Y(y)=0 \\ \Rightarrow \sum_{x=0}^n s^x f_X(x)-\sum_{y=0}^n s^y f_Y(y)=0 \\ \Rightarrow \sum_{x=0}^n s^x f_X(x)-\sum_{x=0}^n s^x f_Y(x)=0 \\ \Rightarrow \sum_{x=0}^n s^x\left[f_X(x)-f_Y(x)\right]=0 \\ \Rightarrow \sum_{x=0}^n s^x c_x=0 \quad \forall s&gt;0 \end{aligned}\)</p>

<ul>
  <li>
    <p>The above is simply a polynomial in \(\mathrm{s}\) with coefficients \(c_0, c_1, \ldots, c_n\). The only way it can be zero for all values of \(\mathrm{s}\) is if \(c_0=c_1=\cdots=c_n=0\)</p>
  </li>
  <li>
    <p>Therefore, \(0=c_i=f_X(i)-f_Y(i)\) for \(i=0,1, \ldots, n\), which means \(f_X(i)=f_Y(i)\) for \(i=0,1, \ldots, n\).</p>
  </li>
</ul>

<h3 id="셋째-mgf의-수렴은-분포수렴convergence-in-distribution을-의미한다">셋째, MGF의 수렴은 분포수렴(convergence in distribution)을 의미한다.</h3>

<ul>
  <li>즉 \(\lim _{n \rightarrow \infty} M_{X_n}(t)=M_X(t)\)이면 \(\lim _{n \rightarrow \infty} F_{X_n}(x)=F_X(x)\)이다.</li>
  <li><strong>(Portmanteau lemma)</strong> For random vector \(Y_n\) and \(Y\) with \(Y_n \sim P_n\) and \(Y \sim P\), the following are equivalent :
    <ul>
      <li>\(Y_n \xrightarrow{d} Y\);</li>
      <li>\(P\left(Y_n \leq t\right) \rightarrow P(Y \leq t)\) for all continuous points \(t\) of \(t \mapsto P(Y \leq t)\);</li>
      <li>\(\mathbb{E}\left[g\left(Y_n\right)\right] \rightarrow \mathbb{E}[g(Y)]\) for all bounded, continuous \(g: \mathbb{R}^d \rightarrow \mathbb{R}\)​;</li>
      <li>(Skip the proof)</li>
      <li>그러므로 아래 (Lévy’s continuity theorem)가 성립한다.</li>
    </ul>
  </li>
  <li>
    <p><strong>(Lévy’s continuity theorem)</strong> Let \(X_n\) and \(X\) be random vectors in \(\mathbb{R}^d\). Then \(X_n \xrightarrow{d} X\) if and only if \(\lim _{n \rightarrow \infty} \mathbb{E}\left[e^{i t^{\top} X_n}\right]=\mathbb{E}\left[e^{i t^{\top} X}\right]\) for every \(t \in \mathbb{R}^d\)</p>
  </li>
  <li>위의 high-dimension에서의 증명은 (Cramér–Wold device)를 통해 1-dimension에서도 성립된다.</li>
  <li><strong>(Cramér-Wold device)</strong> If \(t^{\top} X_n \xrightarrow{d} t^{\top} X\) for all \(t \in \mathbb{R}^d\), then \(X_n \xrightarrow{d} X\)</li>
</ul>

<h3 id="넷째-mgf로-probability-tail-bound를-구한다-hoeffdings-inequality">넷째, MGF로 probability tail bound를 구한다. (Hoeffding’s inequality)</h3>
<ul>
  <li>pass</li>
</ul>

<h2 id="characteristic-function">Characteristic Function</h2>

<ul>
  <li>Definitnion : \(\phi_X(t)=\mathbb{E}[\exp (i t X)]=\mathbb{E}[\cos (t X)+i \sin (t X)], \quad t \in \mathbb{R},\)
    <ul>
      <li>where \(i=\sqrt{-1}\) is the imaginary unit (note Euler’s formula: \(e^{i x}=\cos (x)+i \sin (x)\)​)</li>
    </ul>
  </li>
  <li>
    <p>characteristic function은 언제 사용할까</p>

    <ul>
      <li>MGF가 존재하지 않는 분포(ex. Cauchy)에 대한 특성을 파악할 때</li>
      <li>Lévy’s continuity theorem 증명할 때</li>
    </ul>
  </li>
  <li>
    <p>Element properties:</p>

    <ul>
      <li>
        <p>If \(Y=a X+b, \phi_Y(t)=e^{i b t} \phi_X(a t)\).</p>
      </li>
      <li>
        <p>If \(X\) and \(Y\) are independent, then \(\phi_{X+Y}(t)=\phi_X(t) \phi_Y(t)\)​</p>
      </li>
    </ul>
  </li>
  <li>
    <p>아래 4가지 properties를 하나씩 증명한다.</p>

    <ul>
      <li>
        <p>첫째, \(\phi_X(0)=1\) and \(\mid \phi_X(t)\mid \leq 1\) for all \(t \in \mathbb{R}\)​</p>
      </li>
      <li>둘째, \(\phi_X(t)\) is uniformly continuous on  \(\mathbb{R}\)​​
        <ul>
          <li>즉 \(h \to 0\)에 따라 \(\psi(h) \rightarrow 0\) s.t.  \(\mid \phi_X(t+h)-\phi_X(t)\mid \leq \psi(h)\)</li>
        </ul>
      </li>
      <li>
        <p>셋째, The characteristic function of a symmetric random variable, that is  \(X \stackrel{d}{=}-X\), is real-valued</p>
      </li>
      <li>넷째, MGF처럼 두 확률변수의 characteristic function이 같으면 같은 분포를 따른다.</li>
    </ul>
  </li>
</ul>

<h3 id="첫째-phi_x01-and-mid-phi_xtmid-leq-1-for-all-t-in-mathbbr">첫째, \(\phi_X(0)=1\) and \(\mid \phi_X(t)\mid \leq 1\) for all \(t \in \mathbb{R}\)</h3>

<ul>
  <li>\(\mid e^{i t x}\mid =\sqrt{\cos ^2(t x)+\sin ^2(t x)}=1\) for all \(t\) and \(x\). Therefore \(\mid \phi_X(t)\mid =\mid \mathbb{E}\left[e^{i t X}\right]\mid  \leq \mathbb{E}\left[\mid e^{i t X}\mid \right]=1\)</li>
</ul>

<h3 id="둘째-phi_xt-is-uniformly-continuous-on--mathbbr">둘째, \(\phi_X(t)\) is uniformly continuous on  \(\mathbb{R}\)</h3>

<ul>
  <li>\(\mid \underbrace{\mathbb{E}\left[e^{i(t+h) X}\right]}_{=\phi_X(t+h)}-\underbrace{\mathbb{E}\left[e^{i t X}\right]}_{=\phi_X(t)}\mid =\mid \mathbb{E}\left[e^{i t X}\left(e^{i h X}-1\right)\right]\mid  \leq \mathbb{E}\left[\mid e^{i h X}-1\mid \right]\) 이고</li>
  <li>Let \(g_X(h)=\mid e^{i h X}-1\mid , \text{ Then } g_X(h) \rightarrow 0 \text{ as } h \to 0\) 이므로</li>
</ul>

<p>: \(\begin{aligned} g_X(h) &amp; =\mid e^{i h X}-1\mid  \\ &amp; =\mid \{\cos (h X)-1\}+i \sin (h X)\mid  \\ &amp; =\sqrt{\{\cos (h X)-1\}^2+\sin ^2(h X)} \\ &amp; =\sqrt{2-2 \cos (h X)} \leq 2 \end{aligned}\)</p>

<ul>
  <li>\(g_X(h)\)가 uniformly bounded by 2이므로 DCT에 의해 \(\mathbb E[g_X(h)] \rightarrow 0 \text{ as } h \to 0\)</li>
</ul>

<h3 id="셋째-x-stackreld-x-characteristic-function-of-x는-real-valued">셋째, \(X \stackrel{d}{=}-X\), characteristic function of \(X\)는 real-valued</h3>

<ul>
  <li>
    <p>: \(\begin{aligned} \mathbb{E}\left[e^{i t X}\right] &amp; =\mathbb{E}[\cos (t X)]+i \mathbb{E}[\sin (t X)] \stackrel{(\mathrm{i})}{=} \mathbb{E}[\cos (t X)]+i \mathbb{E}[\sin (-t X)] \\ &amp; \stackrel{(\mathrm{ii})}{=} \mathbb{E}[\cos (t X)]-i \mathbb{E}[\sin (t X)] \end{aligned}\).</p>
  </li>
  <li>
    <p>(i)는 \(X \stackrel{d}{=}-X\) 때문이고, (ii)는 sin의 성질 \(\sin (-x)=-\sin (x)\) 때문이다.</p>
  </li>
</ul>

<h3 id="넷째-mgf처럼-두-확률변수의-characteristic-function이-같으면-같은-분포를-따른다">넷째, MGF처럼 두 확률변수의 characteristic function이 같으면 같은 분포를 따른다.</h3>

<ul>
  <li>두 확률변수가 characteristic function이 같으면 같은 분포를 따름만 증명한다.</li>
  <li>본 증명에는 다양한 기법이 사용되는데 그 중 몇 가지를 소개한다. 아래와 같다.
    <ul>
      <li>Convolution : \(X\)와 \(Y\)가 독립이면 \(Z=X+Y\)의 density function은 \(f_Z(z)=\int_{-\infty}^{\infty} f_X(x) f_Y(z-x) d x\)​</li>
      <li>Characteristic function of \(Z \sim N(0, \sigma^2)\) : \(\mathbb{E}\left[e^{i t Z}\right]=e^{-\frac{\sigma^2 t^2}{2}} \text { for all } t \in \mathbb{R}\)​</li>
      <li>Fubini’s theorem : \(\int_{X \times Y}\mid f(x, y)\mid  d(x, y)&lt;\infty\) 이면 \(\int\)의 순서를 바꿀 수 있다.</li>
    </ul>
  </li>
  <li>\(X+Z\)와 \(Y+Z\)가 같은 분포를 따른다는 것을 증명하고 Slutsky’s theorem으로  \(X\)와 \(Y\)가 같은 분포를 따름을 증명한다.</li>
  <li>\(\begin{aligned}
f_{X+Z}(t) &amp; =\int_{-\infty}^{\infty} f_Z(w) f_X(t-w) d w \\
&amp; =\int_{-\infty}^{\infty} f_Z(-w) f_X(t-w) d w \quad \text { since } f_Z(-w)=f_Z(w) \\
&amp; =\int_{-\infty}^{\infty} f_Z(w) f_X(t+w) d w \quad \text { by the change of variables }(-w \rightarrow w) \\
&amp; =\frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{\infty} e^{-\frac{w^2}{2 \sigma^2}} f_X(t+w) d w \\
&amp; =\frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{\infty} \mathbb{E}_Z\left[e^{i w Z \sigma^{-2}}\right] f_X(t+w) d w \\ &amp; \text {by Characteristic function of } Z \sim N(0, \sigma^2) \text { and } Z \sigma^{-2} \sim N\left(0, \sigma^{-2}\right) \\
&amp; =\frac{1}{\sqrt{2 \pi} \sigma} \mathbb{E}_Z\left[\int_{-\infty}^{\infty} e^{i w Z \sigma^{-2}} f_X(t+w) d w\right] \quad \text { by Fubini's theorem } \\
&amp; =\frac{1}{\sqrt{2 \pi} \sigma} \mathbb{E}_Z\left[e^{-i t Z \sigma^{-2}} \int_{-\infty}^{\infty} e^{i(t+w) Z \sigma^{-2}} f_X(t+w) d w\right] \\
&amp; =\frac{1}{\sqrt{2 \pi} \sigma} \mathbb{E}_Z\left[e^{-i t Z \sigma^{-2}} \int_{-\infty}^{\infty} e^{i w Z \sigma^{-2}} f_X(w) d w\right] \\ &amp;\text { by the change of variables }(t+w \rightarrow w) \\ &amp; =\frac{1}{\sqrt{2 \pi} \sigma} \mathbb{E}_Z\left[e^{-i t Z \sigma^{-2}} \phi_X\left(Z \sigma^{-2}\right)\right] = \frac{1}{\sqrt{2 \pi} \sigma} \mathbb{E}_Z\left[e^{-i t Z \sigma^{-2}} \phi_Y\left(Z \sigma^{-2}\right)\right] \\ &amp;( \because \phi_X = \phi_Y ) \\ &amp;=f_{Y+Z}(t)
\end{aligned}\)​</li>
  <li>By Slutsky’s theorem, \(X\)와 \(Y\)는 같은 분포를 따른다.</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="stat" /><summary type="html"><![CDATA[Moments]]></summary></entry><entry><title type="html">Revisiting Long-term Time Series Forecasting: An Investigation on Linear Mapping</title><link href="http://localhost:4000/timeseries/2024-04-04-RTSF/" rel="alternate" type="text/html" title="Revisiting Long-term Time Series Forecasting: An Investigation on Linear Mapping" /><published>2024-04-04T00:00:00+09:00</published><updated>2024-04-05T09:40:54+09:00</updated><id>http://localhost:4000/timeseries/RTSF</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-04-04-RTSF/"><![CDATA[<ul>
  <li>이전에 review했던 <a href="https://arxiv.org/abs/2205.13504">DLinear</a> paper에서는 ‘Time series의 properties가 무엇인지’, 그리고 ‘왜 Transformer-based model이 완벽할 수 없는지’에 집중했다면, 본 논문은 ‘왜 linear mapping이 단순한데도 성능이 좋은지’에 집중한다.</li>
</ul>

<h2 id="abstract">Abstract</h2>

<ul>
  <li>Linear mapping is critical to prior long-term time series forecasting efforts</li>
  <li>RevIN (reversible normalization) and CI (Channel Independent) play a vital role for performance</li>
  <li>Linear mapping can effectively capture periodic features in TS</li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>

<ul>
  <li>Transformer-based model
    <ul>
      <li>Non-autoregressive methods (to capture long-term temporal correlations)</li>
      <li><a href="https://arxiv.org/pdf/2012.07436.pdf">Informer(AAAI 2021)</a>, <a href="https://arxiv.org/pdf/2106.13008.pdf">Autoformer(NeurIPS 2021)</a>, <a href="https://arxiv.org/pdf/2201.12740.pdf">Fedformer(PMLR 2022)</a>, <a href="https://openreview.net/pdf?id=0EXmFzUn5I">Pyraformer(ICLR 2022)</a>, <a href="https://arxiv.org/pdf/2206.04038.pdf">Scaleformer(ICLR 2023)</a>, <a href="https://openreview.net/pdf?id=vSVLM2j9eie">Crossformer(ICLR 2023)</a></li>
      <li>However, autoregressive에 비해 non-autoregressive의 성능이 좋았던 것이지 transformer가 TS forecasting에 효과적인 것은 아님 <a href="https://arxiv.org/pdf/2205.13504.pdf">DLinear(AAAI 2022)</a></li>
    </ul>
  </li>
  <li>Subsequent approaches (patching)
    <ul>
      <li>Encoder-decoder(ex.transformer) 구조를 버리고 temporal feature extractor 모델링 (attention을 안쓴 건 아님)</li>
      <li><a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/266983d0949aed78a16fa4782237dea7-Paper-Conference.pdf">SCINet(NeurIPS 2022)</a>, <a href="https://arxiv.org/pdf/2211.14730.pdf">PatchTST(ICLR2023)</a>, <a href="https://arxiv.org/pdf/2302.04501.pdf">MTS-Mixers(Arxiv 2023)</a>, <a href="https://openreview.net/pdf?id=ju_Uqw384Oq">Timesnet(ICLR 2023)</a></li>
      <li>But, adjustable hyper-parameters가 너무 많이 필요하다.</li>
    </ul>
  </li>
  <li>본 논문의 Questions
    <ul>
      <li>(1) Are temporal feature extractors effective for long-term time series forecasting?</li>
      <li>(2) What are the <u>underlying mechanisms</u> explaining the effectiveness of <u>linear mapping</u> in time series forecasting?</li>
      <li>(3) What are the limits of linear models and how can we improve them?</li>
    </ul>
  </li>
</ul>

<h2 id="2-problem-definition-and-experimental-setup">2. Problem Definition and Experimental Setup</h2>

<ul>
  <li>\(\mathbf{X}=\left[\boldsymbol{x}_1, \boldsymbol{x}_2, \ldots, \boldsymbol{x}_n\right] \in \mathbb{R}^{c \times n}\) 으로 \(\mathbf{Y}=\left[\boldsymbol{x}_{n+1}, \boldsymbol{x}_{n+2}, \ldots, \boldsymbol{x}_{n+m}\right] \in \mathbb{R}^{c \times m}\) 예측(mapping)하는 함수 \(\mathcal{F}: \mathbf{X}^{c \times n} \mapsto \mathbf{Y}^{c \times m}\) 를 학습</li>
  <li><a href="https://arxiv.org/pdf/2211.14730.pdf">PatchTST(ICLR2023)</a>와 동일한 dataset split, Adam optimizer, Nvidia V100 32GB GPU 사용</li>
</ul>

<h2 id="3-are-temporal-feature-extractors-effective-">3. Are Temporal Feature Extractors Effective ?</h2>

<ul>
  <li>TSF 일반적인 Framework는 <strong>RevIN</strong> \(\to\) <strong>temporal feature extractor</strong>(Attention, MLP, Conv, …) \(\to\) <strong>linear projection</strong>
    <ul>
      <li>다른 모델들의 temporal feature extractor를 살펴보면 PatchTST(attention), MTS-Mixers(MLP), TimesNet(conv), SCINet(conv), …</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/timeseries/RTSF/fig2.png" alt="사진1" /></p>

<ul>
  <li>Fig2 - RLinear : linear projection layer with RevIN</li>
  <li>Fixed random extractor : only initialize the temporal feature extractor randomly and do not update its parameters in the training phase</li>
  <li>Fig2는 RevIN이 예측 성능을 향상시킨다 정도를 보여줄 뿐. simple linear layer가 RevIIN 도움 받으면 PatchTST보다 성능이 좋다.</li>
</ul>

<p><img src="/assets/img/timeseries/RTSF/fig3.png" alt="사진2" /></p>

<ul>
  <li>Fig3는 복잡한 모델들이 결국에는 가장 왼쪽에 있는 simple linear layer의 weights와 비슷한 weights를 학습하게 됨을 보여준다.</li>
</ul>

<h2 id="4-theoretical-and-empirical-study-on-the-linear-mapping">4. Theoretical and Empirical Study on the Linear Mapping</h2>

<h3 id="41-roles-of-linear-mapping-in-forecasting">4.1. Roles of Linear Mapping in Forecasting</h3>

<ul>
  <li>
    <dl>
      <dt><strong>Linear mapping learns periodicity</strong></dt>
      <dd>single linear layer는 periodicity를 학습할 수 있다. (trend는 잘 학습하지 못한다.)</dd>
    </dl>

    <p>아래 가정들과 정리들의 의미를 이해해보자.</p>

    <ul>
      <li>
        <p>single linear layers : \(\mathbf{Y}=\mathbf X \mathbf{W}+\mathbf{b}\)  라 하자.</p>
      </li>
      <li>
        <p><strong>Assumption 1</strong>. A general time series \(x(t)\) can be disentangled into seasonality part \(s(t)\) and trend part \(f(t)\) with tolerable noise, denoted as \(x(t)=s(t)+f(t)+\epsilon\)</p>

        <ul>
          <li>즉 시계열 = seasonality + trend + noise로 분해할 수 있다는 의미이다.</li>
        </ul>
      </li>
      <li><strong>Theorem 1</strong>. Given a seasonal time series satisfying \(x(t)=s(t)=s(t-p)\) where \(p \leq n\) is the period, there always exists an analytical solution for the linear model as
        <ul>
          <li>\(\left[\boldsymbol{x}_1, \boldsymbol{x}_2, \ldots, \boldsymbol{x}_n\right] \cdot \mathbf{W}+\mathbf{b}=\left[\boldsymbol{x}_{n+1}, \boldsymbol{x}_{n+2}, \ldots, \boldsymbol{x}_{n+m}\right]\) 이고</li>
          <li>\(\mathbf{W}_{i j}^{(k)}=\left\{\begin{array}{ll} 1, &amp; \text { if } i=n-k p+(j \bmod p) \\ 0, &amp; \text { otherwise } \end{array}, 1 \leq k \in \mathbb{Z} \leq\lfloor n / p\rfloor, b_i=0\right.\) 이다.</li>
          <li>input historical sequence의 길이가 주기보다 길다면 linear mapping은 periodicity를 예측할 수 있다는 의미이다.</li>
          <li>하지만 위 정리는 \(x(t)=s(t)=s(t-p)\) 즉 trend가 없는 경우에 해당한다.</li>
          <li><img src="/assets/img/timeseries/RTSF/fig4.png" alt="사진3" /></li>
          <li>Fig4는 linear model이 seasonality는 잘 학습하지만 trend가 있을 때에는 성능이 좋지 못함을 보여준다.</li>
        </ul>
      </li>
      <li>
        <p><strong>Theorem 2</strong>. Let \(x(t)=s(t)+f(t)\) where \(s(t)\) is a seasonal signal with period \(p\) and \(f(t)\) satisfies \(K\)-Lipschitz continuous. Then there exists a linear model as \(\mathbf{Y}=\mathbf X \mathbf{W}+\mathbf{b}\) with input horizon size \(n=p+\tau, \tau \geq 0\) such that \(\mid x(n+j)-\hat x(n+j) \mid \leq K(p+j), j=1, \ldots, m\).</p>

        <ul>
          <li>linear model의 trend term에 대한 forecasting error의 upper bound를 제시하는 정리이지만, trend에 대해 성능이 좋지 않다는 건 여전하다.</li>
          <li><img src="/assets/img/timeseries/RTSF/proof.png" alt="사진4" /></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="42-disentanglement-and-normalization"><strong>4.2. Disentanglement and Normalization</strong></h3>

<ul>
  <li>
    <p><strong>Problems in Disentanglement</strong></p>

    <ul>
      <li>
        <p>시계열에서 trend와 seasonality를 분리할 수 있으면 성능을 높일 수 있을 것</p>

        <ul>
          <li>
            <p>moving average(by an average pooling layer with a sliding window)로 trend를 분리할 수 있다.</p>
          </li>
          <li>
            <p>하지만, sliding window의 크기가 seasonality의 최대 주기보다 커야만 효과적이고</p>

            <p>average pooling layer를 사용할 때 input TS의 양 끝에 padding을 해줘야 하는데, 그러면 원본 시퀀스가 왜곡된다.</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Turning trend into seasonality</strong></p>
    <ul>
      <li>Disentanglement의 핵심은 원본 TS에서 movind average를 빼는 것인데, 이건 normalization과 관련이 있다.
        <ul>
          <li>TS의 statistical information(평균, 분산)은 distribution shift로 인해 계속 바뀌기 때문에 RevIN이 사용된다.</li>
          <li>RevIN : Normalization the input \(\to\) Forecasting module \(\to\) Denormalization the output</li>
        </ul>
      </li>
      <li>하지만 input 데이터에 directly normalization하면 오히려 statistical information을 지우는 것과 같다.</li>
      <li><img src="/assets/img/timeseries/RTSF/fig5.png" alt="사진5" /></li>
      <li>RevIN의 경우에는 scaling을 하지만 periodicity는 바꾸지 않는다. 그리고 reversible하다.</li>
      <li><img src="/assets/img/timeseries/RTSF/fig6.png" alt="사진6" /></li>
      <li><img src="/assets/img/timeseries/RTSF/fig7.png" alt="사진7" /></li>
      <li>RevIN은 continuously changing trends를 multiple segments with a fixed and similar trend로 바꾼다.</li>
      <li>그러면 accumulated timesteps in the past로 인한  errors in trend prediction이 완화된다.</li>
    </ul>
  </li>
</ul>

<h2 id="5-experimental-evaluation">5. Experimental Evaluation</h2>

<h3 id="51-comparison-on-real-world-datasets">5.1 Comparison on Real-world Datasets</h3>

<p><img src="/assets/img/timeseries/RTSF/table3.png" alt="사진8" /></p>

<ul>
  <li>learning of periodicity via linear mapping, 그리고 efficiency of reversible normalization 덕분에 well-designed models보다 RLinear의 성능이 좋다.</li>
</ul>

<h3 id="52-when-linear-meets-multiple-periods-among-channels">5.2. When Linear Meets Multiple Periods among Channels</h3>

<p><img src="/assets/img/timeseries/RTSF/table4.png" alt="사진9" /></p>

<ul>
  <li>Multi-channel datasets의 경우에는 Channel Independent(CI) modeling으로 TS의 각 채널을 독립적으로 처리할 때 성능이 좋다.</li>
</ul>

<p><img src="/assets/img/timeseries/RTSF/fig10.png" alt="사진10" /></p>

<ul>
  <li>Channels가 많아지면 channel마다 periodicity가 달라져서 예측이 어려워지는데 input horizon을 늘리면 완화된다.</li>
</ul>

<h2 id="6-conclusion">6. Conclusion</h2>

<ul>
  <li>Linear mapping와 foreacsting methods가 학습하는 것은 비슷하다. (input historical observations에서 periodic patterns)</li>
  <li>RevIN과 Channel Independent는 periodicity를 단순하게 만들어 학습을 용이하게 하므로 성능 향상에 필요하다.</li>
  <li>Linear mapping은 MTS에 대해서도 input horizon만 충분하다면 예측 성능이 뛰어나다.</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[Arxiv 2023](https://arxiv.org/pdf/2305.10721.pdf)]]></summary></entry><entry><title type="html">(Time-LLM) Time Series Forecasting by Reprogramming Large Language Models</title><link href="http://localhost:4000/timeseries/2024-04-01-TimeLLM/" rel="alternate" type="text/html" title="(Time-LLM) Time Series Forecasting by Reprogramming Large Language Models" /><published>2024-04-01T00:00:00+09:00</published><updated>2024-04-05T09:40:54+09:00</updated><id>http://localhost:4000/timeseries/TimeLLM</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-04-01-TimeLLM/"><![CDATA[<h2 id="abstract">Abstract</h2>

<ul>
  <li>CV, NLP는 single large model (또는 pre-trained foundation model)이 거의 모든 tasks에서 성능이 좋음</li>
  <li>반면 TS는 <strong>dat sparsity</strong> 때문에 tasks마다 모델 디자인이 다름</li>
  <li>본 논문에서는 TS와 NLP의 modality gap을 align하기 위해 Time-LLM을 제안</li>
  <li><strong>Prompt-as-Prefix</strong>(PaP, reprogramming the input TS) \(\to\) frozen LLM \(\to\) forecasting</li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>LLM을 forecasting model로 발전시키기 위해 필요한 것들
    <ul>
      <li><strong>Generalizability</strong> : Capability for few-shot and zero-shot transfer learning, w/o pre-task retraining</li>
      <li><strong>Data efficiency</strong> : Performance new tasks with only a few examples(limited data)</li>
      <li><strong>Reasoning</strong> : Sophisticated reasoning \(\to\) learned higher-level concepts \(\to\) highly precise forecasting</li>
      <li><strong>Multimodal knowledge</strong> :  Diverse knowledge across modalities \(\to\) synergistic forecasting that fuses different data types</li>
      <li><strong>Easy optimization</strong> : Once on massive computing \(\to\) can be applied to forecasting tasks (without learning from scratch)</li>
    </ul>
  </li>
  <li><strong>Align the modalities of TS &amp; NLP</strong> : Why challenging ?
    <ul>
      <li>첫째로 NLP는 discrete tokens, TS는 본질적으로 continuous</li>
      <li>둘째로 TS reasoning 지식이 LLM pre-training 안에 없다.</li>
    </ul>
  </li>
  <li>So, <strong>Time-LLM</strong>
    <ul>
      <li>Core idea : TS input을 LLM이 활용하기 쉬운 <strong>text prototype</strong>으로 reprogramming하는 framework (backbone model은 그대로)</li>
      <li><strong>Prompt-as-Prefix (PaP)</strong> : 1) enrich the input TS with additional context and 2) providing task instructions in the modality of NLP</li>
    </ul>
  </li>
</ul>

<h2 id="2-related-work">2. Related Work</h2>
<p><img src="/assets/img/timeseries/TimeLLM/fig1.jpeg" alt="사진1" /></p>
<ul>
  <li>TS models는 task-specific \(\to\) ex. ARIMA는 UTS를, LSTM은 seq를, TCN과 Transformer는 longer temporal dependencies를 위해 디자인 \(\to\) versatility and generalizability 부족</li>
  <li>In-modality Adaptation : Pre-training (representation learning) \(\to\)​ fine-tuning (for downstream tasks) ! But <strong>TS data sparsity.</strong>..</li>
  <li>Cross-modality Adaptation (multimodal fine tuning) : Voice2Series(2021)은 TS를 acoustic model에 맞게 editing했고 LLM4TS는 first supervised pre-training on time series, then task-specific fine-tuning</li>
  <li>Time-LLM은 1) input TS를 수정하지도 않고, 2) backbone LLM을 fine tuning하지도 않는다. LLM이 잠재력을 발휘할 수 있도록 TS를 reprogramming</li>
</ul>

<h2 id="3-methodology">3. Methodology</h2>
<ul>
  <li>Goal : <strong>Reprogram an embedding-visible language foundation model for general time series forecasting</strong> without requiring any fine-tuning of the backbone model.</li>
  <li>\(f(\ \mathbf{X} \in \mathbb{R}^{N \times T}\ )= \hat{\mathbf{Y}} \in \mathbb{R}^{N \times H}\), \(f\)는 input TS를 이해하고 예측.
Loss : \(\frac{1}{H} \sum_{h=1}^H\left\|\hat{\mathbf{Y}}_h-\mathbf{Y}_h\right\|_F^2\)​
<img src="/assets/img/timeseries/TimeLLM/fig2.jpeg" alt="사진2" /></li>
  <li>3-main components
    <ul>
      <li>(1) input transformation</li>
      <li>(2) a pre-trained and frozen LLM</li>
      <li>(3) output projection</li>
    </ul>
  </li>
  <li>Step 1) Channel independence : MTS \(\to\)​ N개의 UTS <br />
Step 2) Normalization, Patching, Embedding prior <br />
Step 3) Augment the LLM’s Ts reasoning ability <br />
Step 4) Project to the final forecast \(\hat{\mathbf{Y}}^{i}\)</li>
  <li>Efficiency
    <ul>
      <li>only the parameters of the <strong>lightweight input transformation and output projection</strong> are updated. (backbone LLM is frozen)</li>
      <li>directly optimizing \(\to\) <strong>small set of TS and a few training epochs</strong></li>
      <li>for reduce memory footprint, <strong>off-the-shelf techniques (e.g., quantization)</strong></li>
    </ul>
  </li>
</ul>

<h3 id="31-model-structure">3.1. Model Structure</h3>
<ul>
  <li><strong>Input Embedding</strong>
    <ul>
      <li>step 1) RevIN \(\mathbf X^{(i)}\)</li>
      <li>step 2) Patching with length \(L_p\)
        <ul>
          <li>Total number of input patches : \(P=\left\lfloor\frac{\left(T-L_p\right)}{S}\right\rfloor+2\)</li>
          <li>Underlying motivations :
            <ul>
              <li>Better preserving local semantic information by aggregating local information into each patch</li>
              <li>Serving as tokenization to form a compact sequence of input tokens, reducing computational burdens.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>step 3) Embedding w/ simple linear layer
        <ul>
          <li>\(\mathbf{X}_P^{(i)} \in \mathbb{R}^{P \times L_p} \to \mathbf{\hat X}_P^{(i)} \in \mathbb{R}^{P \times d_m}\)​</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Patch Reprogramming</strong>
<img src="/assets/img/timeseries/TimeLLM/fig3.png" alt="사진3" />
    <ul>
      <li>Goal : to align the modalities of TS and natural language (TS 직접적인 수정 없이)</li>
      <li>How : pre-trained word embedding \(\mathbf E \in \mathbb R^{V \times D}\) in backbone.
        <ul>
          <li>But! no prior knowledge indicating which source token are directly relevant.</li>
          <li>So, simply leveraging small collection of text prototypes by linearly probing \(\mathbf E\), denoted as \(\mathbf E' \in \mathbb R^{V' \times D}, V^{\prime} \ll V\)</li>
          <li>: efficient &amp; allows for the adaptive selection of relevant source information</li>
        </ul>
      </li>
      <li>Multi-head cross-attention
        <ul>
          <li>query matrices \(\mathbf{Q}_k^{(i)}=\hat{\mathbf{X}}_P^{(i)} \mathbf{W}_k^Q\)
key matrices \(\mathbf{K}_k^{(i)}=\mathbf{E}^{\prime} \mathbf{W}_k^K\)
value matrices \(\mathbf{V}_k^{(i)}=\mathbf{E}^{\prime} \mathbf{W}_k^V\)
where \(\mathbf{W}_k^Q \in \mathbb{R}^{d_m \times d}\) and \(\mathbf{W}_k^K, \mathbf{W}_k^V \in \mathbb{R}^{D \times d}\)
\(D\) is the hidden dimension of the backbone model, and \(d=\left\lfloor\frac{d_m}{K}\right\rfloor\)</li>
          <li>i-layer : \(\mathbf{Z}_k^{(i)}=\operatorname{ATTENTION}\left(\mathbf{Q}_k^{(i)}, \mathbf{K}_k^{(i)}, \mathbf{V}_k^{(i)}\right)=\operatorname{SOFTmax}\left(\frac{\mathbf{Q}_k^{(i)} \mathbf{K}_k^{(i) \top}}{\sqrt{d_k}}\right) \mathbf{V}_k^{(i)}\)</li>
          <li>By aggregating each \(\mathbf{Z}_k^{(i)} \in \mathbb{R}^{P \times d}\) in every head, \(\mathbf{Z}^{(i)} \in \mathbb{R}^{P \times d_m}\),
then linearly projected \(\to \mathbf{O}^{(i)} \in \mathbb{R}^{P \times D}\)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Patch-as-Prefix</strong> (constraints…)
    <ul>
      <li>natural language로 표현된 TS를 예측</li>
      <li>Constraints :
        <ul>
          <li>LLM은 <strong>high-precision numerals</strong> 연산에 sensitivity 떨어지고</li>
          <li>LLM별로 서로 다른 후처리가 필요 ex.  0.61이 [’ 0 ‘, ‘, ‘, 6 ‘, ‘ 1 ‘] 또는 [’ 0 ‘, ‘, ‘, ‘61’]로 표시</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Prompt-as-Prefix</strong> (avoid constraints !)
    <ul>
      <li>(1) Dataset context : input TS의 essential background information을 LLM에 제공
(2) Task instruction : task에 따른 patch embedding 가이드를 LLM에 제공
(3) Input statistics : Enrich the input TS with additional statistics (trends, lags, …)</li>
    </ul>
  </li>
  <li><strong>Output Projection</strong>
    <ul>
      <li>Prefixal part 버리고 output representation 얻어서 flatten하고 linear projection  \(\to \hat{\mathbf{Y}}^{(i)}\)</li>
    </ul>
  </li>
</ul>

<h2 id="4-main-results">4. Main Results</h2>
<h3 id="41-42-longshort-term-forecasting">4.1, 4.2. Long/Short-term Forecasting</h3>
<p><img src="/assets/img/timeseries/TimeLLM/table12.png" alt="사진4" /></p>
<h3 id="43-few-shot-forecasting">4.3. Few-shot Forecasting</h3>
<p><img src="/assets/img/timeseries/TimeLLM/table3.png" alt="사진5" />
<img src="/assets/img/timeseries/TimeLLM/table4.png" alt="사진6" /></p>
<h3 id="44-zero-shot-forecasting">4.4. Zero-shot Forecasting</h3>
<p><img src="/assets/img/timeseries/TimeLLM/table5.png" alt="사진7" /></p>
<h3 id="45-model-analysis">4.5. Model Analysis</h3>
<p><img src="/assets/img/timeseries/TimeLLM/table67.png" alt="사진8" /></p>

<h2 id="5-conclusion-and-future-work">5. Conclusion and Future work</h2>
<ul>
  <li>TS를 test prototype으로 reprogramming해서 frozen LLM 통과</li>
  <li>Prompt-as-Prefix로 guidance를 LLM에 제공</li>
  <li>TS forecasting을 language task로 casting</li>
  <li>결론적으로 Patching + Prompting으로 성능을 더 올린 모델</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[ICLR 2024](https://arxiv.org/pdf/2310.01728.pdf)]]></summary></entry><entry><title type="html">(Survey paper) Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects (Arxiv 2023)</title><link href="http://localhost:4000/timeseries/2024-03-25-SSL4TS/" rel="alternate" type="text/html" title="(Survey paper) Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects (Arxiv 2023)" /><published>2024-03-25T00:00:00+09:00</published><updated>2024-03-25T19:43:09+09:00</updated><id>http://localhost:4000/timeseries/SSL4TS</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-03-25-SSL4TS/"><![CDATA[<h2 id="abstract">Abstract</h2>

<ul>
  <li>Self-supervised learning (SSL) : for reducing the dependence of labeled data</li>
  <li>will review SOTA SSL for TS</li>
  <li>will provide taxonomy of SSL for TS : generative-based, contrastive-based, adversarial-based
    <ul>
      <li>intuitions, main frameworks, (dis)advantages</li>
    </ul>
  </li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>To extract useful and informative features, (=hidden patterns and features of the data)
    <ul>
      <li>SSL utilizes pretext tasks to derive supervision signals from unlabeled data (=creating valuable representation for downstream tasks)</li>
    </ul>
  </li>
  <li>Challenges:
    <ul>
      <li>대부분의 pre-text tasks(이미지, 언어, …) designed 모델들은 TS의 unique properties(seasonality, trend, frequency, …)를 고려하기 위한 것이 아니다.</li>
      <li>SSL을 위해 data augmentation할 때 rotation이나 crop과 같은 방식은 TS의 temporal dependency를 학습하기 어렵게 만든다.</li>
      <li>MTS에서 몇몇의 dimension(=channel, variate)에만 유용한 정보가 있는 경우에는 이를 고려해야 한다.</li>
    </ul>
  </li>
  <li>SSL for TS:
    <ul>
      <li>Generative-based : autoregressive-based forecasting / auto-encoder-based reconstruction / diffusion-based generation</li>
      <li>Contrastive-based : sampling contrast / prediction contrast / augmentation contrast / prototype contrast / expert knowledge contrast</li>
      <li>Adversarial-based : generation and imputation and auxiliary representation enhancement
<img src="/assets/img/timeseries/SSL4TS/fig1.png" alt="사진1" />
<img src="/assets/img/timeseries/SSL4TS/fig5.png" alt="사진5" /></li>
    </ul>
  </li>
</ul>

<h2 id="2-related-surveys">2. Related Surveys</h2>

<h3 id="21-definition-of-time-series-data">2.1. Definition of time series data</h3>
<ul>
  <li>Univariate TS : \(X=\left(x_0, x_1, x_2, \ldots, x_t\right)\) where \(x_i\) is  the point at timestamp \(i\)​</li>
  <li>Multivariate TS : \(\mathbf{X}=\left[X_0, X_1, X_2, \ldots, X_p\right]\), where \(p\) is the number of variables</li>
  <li>Multiple multivariate TS : \(\mathcal{X}=\left\{\mathbf{X}_0, \mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_n\right\}\), where \(n\) is the number of multivariate TS</li>
</ul>

<h3 id="22-surveys-on-ssl">2.2. Surveys on SSL</h3>
<ul>
  <li>pretext tasks 의 핵심은 pseudo-supervision signals을 만드는 것</li>
  <li>Basic intuition : pull positive samples closer and push negative samples away
    <ul>
      <li>positive and negative samples : multisensory signals / data augmentation(noise injection, …) / local-global consistency / temporal consistency</li>
      <li>pretext task : Context prediction / Instance discrimination / Instance generation</li>
      <li>model architecture</li>
      <li>training loss : contrastive loss functions generally include scoring functions (cosine similarity), energy-based margin functions (pair loss and triplet loss), probabilistic NCE-based functions, and mutual information based functions</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/timeseries/SSL4TS/table3.png" alt="사진7" /></p>

<h2 id="3-generative-based-models">3. Generative-based Models</h2>
<ul>
  <li>pretext task : to generate the expected data based on a given view of the data
<img src="/assets/img/timeseries/SSL4TS/fig2.png" alt="사진2" /></li>
</ul>

<h3 id="31-autoregressive-based-forecasting">3.1. Autoregressive-based forecasting</h3>
<ul>
  <li>Forecasting : \(\hat{x}_{[t+1: t+K]}=f\left(x_{[1: t]}\right)\)</li>
  <li>Loss : \(\mathcal{L}=\frac{1}{K} \sum_{k=1}^K\left(\hat{x}_{[t+k]}-x_{[t+k]}\right)^2\)​</li>
  <li>RNN-based
    <ul>
      <li>Adv : Long-term dependencies / Adaptable to varying lengths / Global context information extraction</li>
      <li>Dis-adv : Vanishing or exploding gradients / Computational efficiency</li>
      <li>ex : <a href="https://proceedings.neurips.cc/paper/2020/file/97e401a02082021fd24957f852e0e475-Paper.pdf">THOC</a> : Temporal Self-supervision(TSS), which takes the L-layer dilated RNN with skip-connection structure \(\to\)​ different resolutions at the same time</li>
    </ul>
  </li>
  <li>CNN-based
    <ul>
      <li>Adv : Local pattern extraction / Computational efficiency</li>
      <li>Dis-adv : Long-termdependencies / Information loss</li>
    </ul>
  </li>
  <li>GNN-based
    <ul>
      <li>Adv : Adaptability to graph structures / Dynamic relationship capture</li>
      <li>Dis-adv : Computational and storage complexity</li>
      <li>ex : <a href="https://arxiv.org/pdf/2106.06947.pdf">GDN</a> : the correlation among variables</li>
    </ul>
  </li>
</ul>

<h3 id="32-autoencoder-based-reconstruction">3.2. Autoencoder-based reconstruction</h3>
<ul>
  <li>basic autoencoder (BAE)
    <ul>
      <li>Encoder \(x \to z\) , Decoder \(z \to \hat {x}\)  / Loss : \(\mathcal{L}=\|x-\tilde{x}\|_2\)</li>
      <li>E(), D() 같이 train, D() 제거하고 E()를 feature extractor로 사용</li>
      <li>ex. <a href="https://arxiv.org/pdf/1706.08838.pdf">TimeNet</a>, <a href="https://www.nature.com/articles/s41598-019-55320-6">PT-LSTM-SAE</a>, <a href="https://arxiv.org/pdf/1810.10107.pdf">Autowarp</a></li>
    </ul>
  </li>
  <li>Denoising autoencoder (DAE)
    <ul>
      <li>\(x_n=\mathcal{T}(x), \quad Z=E\left(x_n\right), \quad \tilde{x}=D(z)\), \(\quad \mathcal{T}\): add noise  / Loss : \(\mathcal{L}=\|x-\tilde{x}\|_2\)</li>
    </ul>
  </li>
  <li>Mask autoencoder (MAE)
    <ul>
      <li>Intuition : pre-training할 때에 input의 일부를 mask하고 un-mask part 보고 예측</li>
      <li>form : \(\begin{gathered}x_m=\mathcal{M}(x), \quad z=E\left(x_m\right), \quad \tilde{x}=D(z),\ \mathcal{L}=\mathcal{M}\left(\|x-\tilde{x}\|_2\right),\end{gathered}\)</li>
      <li>TS에서는 time-step-wise masking은 interpolation 해버리기 때문에, segment-wise masking or variable-wise masking</li>
      <li>ex. <a href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539329">TARNet</a> : 중요한 역할을 하는 data를 선정하고, 해당 데이터를 masking 하여 reconstruction</li>
    </ul>
  </li>
  <li>Variational autoencoder (VAE)
    <ul>
      <li>Encoder \(x \to P(z\mid x)\), instead of explicit representation \(z\), Decoder는 sampling from \(P(z \mid x)\)​</li>
      <li>\(P(z \mid x)=E(x), \quad z=\mathcal{S}(P(z \mid x)), \quad \tilde{x}=D(z)\) / Loss : \(\mathcal{L}=\|x-\tilde{x}\|_2+\operatorname{KL}(\mathcal{N}(\mu, \delta), \mathcal{N}(0, I))\)</li>
      <li>ex. <a href="https://dl.acm.org/doi/10.1145/3447548.3467075">InterFusion</a>, <a href="https://arxiv.org/pdf/2101.10318.pdf">mTANs</a>, <a href="https://arxiv.org/pdf/2107.11350.pdf">HetVAE</a>(extract seasonal and trend via VAE)</li>
    </ul>
  </li>
</ul>

<h3 id="33-diffusion-based-generation">3.3. Diffusion-based generation</h3>
<ul>
  <li>reverse transition kernel을 NN으로 approximate</li>
  <li>Denoising diffusion probabilistic models <a href="https://arxiv.org/pdf/2006.11239.pdf">DDPM</a>,
    <ul>
      <li>\(p_\theta\left(\boldsymbol{x}_{\boldsymbol{t}-\mathbf{1}} \mid \boldsymbol{x}_{\boldsymbol{t}}\right)=$ $\mathcal{N}\left(\boldsymbol{x}_{t-1} ; \mu_\theta\left(\boldsymbol{x}_t, t\right), \sum_\theta\left(\boldsymbol{x}_t, t\right)\right)\) 일 때,</li>
      <li>Jensen’s inequality에 의해, training loss는 \(\begin{array}{r}\mathbf{K L}\left(q\left(\boldsymbol{x}_1, \boldsymbol{x}_2, \ldots, \boldsymbol{x}_T\right) \| p_\theta\left(\boldsymbol{x}_0, \boldsymbol{x}_1, \ldots, \boldsymbol{x}_T\right)\right) \geq \mathbf{E}\left[-\log p_\theta\left(\boldsymbol{x}_0\right)\right]+\text { const. }\end{array}\)</li>
    </ul>
  </li>
  <li>Score matching diffusion models <a href="https://arxiv.org/pdf/1907.05600.pdf">score matching</a>
    <ul>
      <li>per- turb data with a sequence of Gaussian noise \(\to\) estimating the score function for all the noisy data</li>
    </ul>
  </li>
</ul>

<h2 id="4-contrastive-based-methods">4. Contrastive-based Methods</h2>
<ul>
  <li>positive는 가깝게, negative는 멀게 representation하도록 학습 \(\to\) positive / negative 정하는 룰이 중요함
<img src="/assets/img/timeseries/SSL4TS/fig3.png" alt="사진3" /></li>
  <li><strong>Sampling contrast</strong>
    <ul>
      <li>가정 : 시점이 가까울수록 유사도가 높을 것</li>
      <li>하지만 실제로 꼭 그런 것은 아니다. contextual information으로 pos / neg 정하기가 쉽지 않다</li>
      <li>ex. <a href="https://arxiv.org/pdf/2106.00750.pdf">TNC</a> : augmented Dickey-Fuller (ADF) statistical test 해서 neg samples를 unknown으로 취급, weights 할당, <a href="https://arxiv.org/pdf/2004.11362.pdf">Supervised contrastive learning</a></li>
    </ul>
  </li>
  <li><strong>Prediction contrast</strong>
    <ul>
      <li>maximally preserve the mutual information of the context and the target</li>
      <li>Ex. <a href="https://arxiv.org/pdf/1807.03748.pdf">Contrastive predictive coding (CPC)</a> : Context와 target의 mutual information을 최대한 유지한 채로 prediction</li>
      <li>variants : <a href="https://arxiv.org/pdf/2202.03944.pdf">LNT</a>, <a href="https://arxiv.org/pdf/2106.14112.pdf">TS-TCC</a> <a href="https://arxiv.org/pdf/2208.06616.pdf">CA-TCC</a> (TS data augmentation techniques)</li>
    </ul>
  </li>
  <li><strong>Augmentation contrast</strong>
    <ul>
      <li>different views of an input sample 생성 (같은 sample의 view끼리는 positive) \(\to\) similarity <a href="https://arxiv.org/pdf/2002.05709.pdf">SimCLR</a></li>
      <li>variants : <a href="https://arxiv.org/pdf/2106.10466.pdf">TS2Vec</a> (week augmentation e.g. jitter-and-scale), <a href="https://arxiv.org/pdf/2202.01575.pdf">CoST</a>, <a href="https://arxiv.org/pdf/2206.08496.pdf">TF-C</a> (frequency domain), <a href="https://arxiv.org/pdf/2306.10347.pdf">DCdetector</a>, <a href="https://pdf.sciencedirectassets.com/271505/1-s2.0-S0950705122X00075/1-s2.0-S0950705122002726/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHAaCXVzLWVhc3QtMSJIMEYCIQDgmFUeLriQDh4DVodXqV0y990PZCUCjyqFZw5tbaaWOQIhAJJXI3FfJlWxRX7ERxHJD52xqRrpOHF7bO5s8CcvR%2BObKrwFCIn%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBRoMMDU5MDAzNTQ2ODY1Igz9LqUqaUEhwALsmIAqkAVKSauBGYOJAgLt97GY2VGTuMQnRA7AgMmTvZNbQR13nb0eSyB3AddrtMNpzfTApqlafitG63sIURfGc04jk0%2BqiLp73hS3BmM6J9f3LNclZKHKiIQ%2BfUjQppBf9%2BSzb2GYgwcFIWgWQCR5PtN2siu0UfPOBUAUFniH5sww3WHYgzisgA4woX%2F%2B1lpEeSZAfoqOLu%2BD70QDpxoC0KgT%2FXhLrNhBehAy%2FZqTdVfSNmO8PnYW%2BbOc6HJ8zuTY5RATpiy9V7EMrdnYFYXvqu%2F1qW2x%2FtdeEZ0RfWCu524fQvnPpB8zVmySXJH4TXT4LA7QJE%2B1QwAHRqUatsaSoMpckzyqhP4LGwWneO%2Fq9RiEEqDkaOCpaL5F%2F%2B5i1tibhhFGI9ACzd814laQtq%2BIcvidp9986C1DHHJjTFHEXHUgMObbcOMXVA8xcpjCf5yFKcLC42BCHss82InfazC%2BJ8X4if%2BIhr7C%2B4MnowAGueEbmt5yQhoYboaD1tk%2FKKIohIhI2hghsk%2Fj%2BwhkWCn5KyLfoONkWJmJW1CXLDORF38jJLFEREaAQr3LRwExugVvijVdQLlWMyzPoCNRSLI5zkotkTprBsrs6iaJrS7hLn3mxOjCh9mZyJI2yV6%2Brr7jzg5XQ6VHiYlrkcfYuw9OFK5jv5OsoGoi4E46toRGV7X2p9jKlrg7T4m61BP5khSxzLJq61nOGlO%2Bx3zUvUT3dMyvkGMkKtaSk1%2FKXT4RovxkHp%2Bmpc3QUR7j6hzf5z0n9IIsv8FzAtzg58kKHg9OBQmHtCehUyLOErVo7P9Qxj5SIP7umI%2F%2Fe9p%2BK%2BGGZKNKv4LyjUqeB7XdlwPp2x2ysLv4d4o%2BIPtvkyjLqxhNu6sOYmb6VjCX1oSwBjqwAfzu66rFmDL30GLaRAVAW1ntG5mkCnwKEF3lFukhkQUOfwCxm7RM9jOJeG4%2Bmi3EJkTk7YzUpDz3XnUhEC9%2BvejsHkC1qETTJrb0bcqMFFW3EaZrZZYvZ4zodutAKA%2BUzMn5Df82EqEjSmeySV18YkkkKDNTM0usR%2FHaNfviRepwNslRryoSwTWiPWMwiV9tIIbZaIFpcs6nZlQB%2BGqMP1tw1rZAozE5PSe1E%2Btz1kLS&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20240325T090224Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTYQXRPBKFN%2F20240325%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=2f8baa651eec4fdd10cde55f49d1477a95f8710aa9c8758546ef1df59d330c78&amp;hash=4538839e76c3c485eb651626f2c825dd66a6195b3060bbed9553996335a29682&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S0950705122002726&amp;tid=spdf-baf2cd37-88cd-4f95-a9ab-f50f1a42eb98&amp;sid=fc89350759b08043e82bbad-52465f639e79gxrqa&amp;type=client&amp;tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&amp;ua=0f11585559020c5807&amp;rr=869db8c7e9f3a7c3&amp;cc=kr">TimeCLR</a></li>
    </ul>
  </li>
  <li><strong>Prototype contrast</strong>
    <ul>
      <li>minimize the distance btw samples and prototype(=virtual sequences, centor, …)
but maximize the distance btw prototype(=virtual sequences, centor, …)</li>
    </ul>
  </li>
  <li><strong>Expert knowledge contrast</strong>
    <ul>
      <li>incorporates expert prior knowledge or information into deep neural networks to guide model training</li>
    </ul>
  </li>
</ul>

<h2 id="5-adversarial-based-methods">5. Adversarial-based Methods</h2>
<ul>
  <li>pre-text tasks를 GAN으로 푼다. (generator \(\mathcal{G}\) and a discriminator \(\mathcal{D}\))</li>
  <li>Learning objective : \(\mathcal{L}=\mathbb{E}_{x \sim \mathcal{P}_{\text {data }}(x)}[\log \mathcal{D}(x)]+\mathbb{E}_{z \sim \mathcal{P}_{\mathbf{z}}(z)}[\log (1-\mathcal{D}(\mathcal{G}(\mathbf{z})))]\)
<img src="/assets/img/timeseries/SSL4TS/fig4.png" alt="사진4" /></li>
  <li><strong>Time series generation and imputation</strong>
    <ul>
      <li>Complete time series generation : <a href="https://papers.nips.cc/paper_files/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf">TimeGAN</a> (autoregressive GAN), <a href="https://arxiv.org/pdf/2202.02691.pdf">TTS-GAN</a> (Transformer treating TS as image)</li>
      <li>time series imputation : pass</li>
    </ul>
  </li>
  <li><strong>Auxiliary representation enhancement</strong>
    <ul>
      <li>pass</li>
    </ul>
  </li>
</ul>

<h2 id="6-applications-and-datasets">6. Applications and Datasets</h2>
<p><img src="/assets/img/timeseries/SSL4TS/table2.png" alt="사진6" /></p>

<h2 id="7-discussion-and-future-directions">7. Discussion and Future Directions</h2>
<h3 id="71-selection-and-combination-of-data-augmentation">7.1. <strong>Selection and combination of data augmentation</strong></h3>
<ul>
  <li>augmentation methods :  jitter, scaling, rotation, permutation, and warping, …</li>
  <li>permutation + rotation + time warping &gt; single method
    <h3 id="72-inductive-bias-for-time-series-ssl">7.2. <strong>Inductive bias for time series SSL</strong></h3>
  </li>
  <li>특히 데이터가 충분하지 않을 수록 합리적인 inductive bias는 필요할 수 있음
    <h3 id="73-ssl-for-irregular-and-sparse-time-series">7.3. <strong>SSL for irregular and sparse time series</strong>=</h3>
  </li>
  <li>Irregular and sparse time series를 interpolation해서 쓰려고 하다보면 undesirable noise가 낄 수도 있으니 그대로 SSL로 활용</li>
</ul>

<h2 id="8-conclusion">8. Conclusion</h2>
<p>Pass</p>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[Arxiv 2023](https://arxiv.org/pdf/2306.10125.pdf)]]></summary></entry><entry><title type="html">(Survey paper) Time Series Forecasting With Deep Learning A Survey (Philos Trans R Soc A. 2020)</title><link href="http://localhost:4000/timeseries/2024-03-19-TSwDLsurvey/" rel="alternate" type="text/html" title="(Survey paper) Time Series Forecasting With Deep Learning A Survey (Philos Trans R Soc A. 2020)" /><published>2024-03-19T00:00:00+09:00</published><updated>2024-03-19T13:15:52+09:00</updated><id>http://localhost:4000/timeseries/TSwDLsurvey</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-03-19-TSwDLsurvey/"><![CDATA[<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>Time series forecasting
    <ul>
      <li>traditional methods : parametric models informed by domain expertise (ex. autoregressive(AR))</li>
      <li>machine learning : learn temporal dynamics in a puerly data-driven manner</li>
      <li>deep learning : learn complex data representation
        <ul>
          <li>CNN, RNN, Attention-based mechanism</li>
        </ul>
      </li>
      <li>hybrid model : Quantitative TS model + deep learning model</li>
    </ul>
  </li>
  <li>Time series forecasting의 application
    <ul>
      <li>interpretability and counterfactual prediction</li>
    </ul>
  </li>
</ul>

<h2 id="2-deep-learning-architectures-for-tsf">2. Deep Learning Architectures for TSF</h2>
<ul>
  <li>One-step-ahead forecasting : \(\hat{y}_{i, t+1}=f\left(y_{i, t-k: t}, \boldsymbol{x}_{i, t-k: t}, \boldsymbol{s}_i\right)\)
    <ul>
      <li>\(\hat{y}_{i, t+1}\) : model forecast</li>
      <li>\(y_{i, t-k: t}=\left\{y_{i, t-k}, \ldots, y_{i, t}\right\}, \boldsymbol{x}_{i, t-k: t}=\left\{\boldsymbol{x}_{i, t-k}, \ldots, \boldsymbol{x}_{i, t}\right\}\) : observation over look-back window</li>
      <li>\(f(\cdot)\) : the prediction function learntby the model
        <h3 id="2a-basic-building-blocks">2.(a) Basic building blocks</h3>
      </li>
    </ul>
  </li>
  <li>Encoder : \(\boldsymbol{z}_t=g_{\mathrm{enc}}\left(y_{t-k: t}, \boldsymbol{x}_{t-k: t}, \boldsymbol{s}\right)\)</li>
  <li>Decoder : \(f\left(y_{t-k: t}, \boldsymbol{x}_{t-k: t}, \boldsymbol{s}\right)=g_{\mathrm{dec}}\left(\boldsymbol{z}_t\right)\)
    <ul>
      <li>Encoder에서 observations를 latent vector로 representation</li>
      <li>(1) Convolution Neural Networks : \(\begin{aligned} \boldsymbol{h}_t^{l+1} &amp; =A((\boldsymbol{W} * \boldsymbol{h})(l, t)) \\ (\boldsymbol{W} * \boldsymbol{h})(l, t) &amp; =\sum_{\tau=0}^k \boldsymbol{W}(l, \tau) \boldsymbol{h}_{t-\tau}^l \end{aligned}\)
        <ul>
          <li>Convolution과 pooling을 반복하는 구조. TS에서는 과거의 값만 보도록 설계</li>
          <li>\(\boldsymbol{h}_t^l \in \mathbb{R}^{\mathcal{H}_{i n}}\) : intermediate state at layer \(l\) at time \(t\)</li>
          <li>
            <p>\(*\) : convolution operator</p>
          </li>
          <li>\(\boldsymbol{W}(l, \tau) \in$ $\mathbb{R}^{\mathcal{H}_{\text {out }} \times \mathcal{H}_{\text {in }}}\) : fixed filter weight at layer \(l\)</li>
          <li>\(A(.)\) : activation function</li>
        </ul>
      </li>
      <li>Dilated Convolution : \((\boldsymbol{W} * \boldsymbol{h})\left(l, t, d_l\right)=\sum_{\tau=0}^{\left\lfloor k / d_l\right\rfloor} \boldsymbol{W}(l, \tau) \boldsymbol{h}_{t-d_l \tau}^l\)
        <ul>
          <li>\(d_l\) : layer-specific dilation rate</li>
          <li>(WaveNet) \(d_l = 2^l\) at layer \(l\) (fig1.(a))
<img src="/assets/img/timeseries/TSwDLsurvey/fig1.png" alt="사진1" /></li>
        </ul>
      </li>
      <li>(2) Recurrent Neural Networks
        <ul>
          <li>Memory state를 통해 과거 정보를 기억하는 sequential data에 적합한 구조</li>
          <li>
            <p>Gradient vanishing으로 인한 long-range dependency \(\to\) LSTM</p>
          </li>
          <li>
            <p>Memory update funciton : \(\boldsymbol{z}_t=\nu\left(\boldsymbol{z}_{t-1}, y_t, \boldsymbol{x}_t, \boldsymbol{s}\right)\)</p>
          </li>
          <li>Network : \(\begin{aligned} y_{t+1} &amp; =\gamma_y\left(\boldsymbol{W}_y \boldsymbol{z}_t+\boldsymbol{b}_y\right) \\ \boldsymbol{z}_t &amp; =\gamma_z\left(\boldsymbol{W}_{z_1} \boldsymbol{z}_{t-1}+\boldsymbol{W}_{z_2} y_t+\boldsymbol{W}_{z_3} \boldsymbol{x}_t+\boldsymbol{W}_{z_4} \boldsymbol{s}+\boldsymbol{b}_z\right) \end{aligned}\)
            <ul>
              <li>\(W_{.}, \boldsymbol{b}\) : the linear weights and bias</li>
              <li>\(\gamma_y(.), \gamma_z(.)\) : network activation functions</li>
            </ul>
          </li>
          <li>Long Short Term Memory(LSTM)
<img src="/assets/img/timeseries/TSwDLsurvey/fig2.png" alt="사진2" /></li>
        </ul>
      </li>
      <li>(3) Attention mechanisms
        <ul>
          <li>form : \(\boldsymbol{h}_t=\sum_{\tau=0}^k \alpha\left(\boldsymbol{\kappa}_t, \boldsymbol{q}_\tau\right) \boldsymbol{v}_{t-\tau}\)
            <ul>
              <li>key \(\boldsymbol{\kappa}_t\), query \(\boldsymbol{q}_\tau\) and value \(\boldsymbol{v}_{t-\tau}\) are intermediate features produced at different time steps by lower levels of the network</li>
              <li>\(\alpha\left(\boldsymbol{\kappa}_t, \boldsymbol{q}_\tau\right) \in[0,1]\) is the attention weight for \(t-\tau\) generated at time \(t\)</li>
              <li>\(\boldsymbol{h}_t\) is the context vector output of the attention layer
                <h3 id="2b-multi-horizon-forecasting-models">2.(b) Multi-horizon Forecasting Models</h3>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>단순히 다음 한 시점에 대한 예측이 아닌 미래 여러 시점에 대한 예측</li>
  <li>(1) Iterative Methods : Autoregressive forecasting. 각 time step에서의 작은 오차가 누적된다는 단점이 있다.</li>
  <li>(2) Direct Methods : Encoder의 정보를 활용해서 한 번에 target time steps를 예측</li>
</ul>

<h2 id="3-incorporating-domain-knowledge-with-hybrid-models">3. Incorporating Domain Knowledge with Hybrid Models</h2>
<ul>
  <li>Machine learning의 underperformance의 이유는 1) flexibility로 인한 overfitting, 2) pre-processed input에 대한 sensitivity</li>
  <li>Hybrid models
    <ul>
      <li>combine well-studied quantitative time series models together with deep learning</li>
      <li>use domain knowledge \(\to\) hypothesis space를 줄여준다</li>
      <li>(a) Non-probabilistic Hybrid models : forecasting equations를 modify</li>
      <li>(b) Probabilistic Hybrid models : predictive distribution으로 parameters 생성</li>
    </ul>
  </li>
</ul>

<h2 id="4-facilitating-decision-support-using-deep-neural-networks">4. Facilitating Decision Support Using Deep Neural Networks</h2>
<ul>
  <li>연구하는 입장에서는 model의 성능(MSE, Accuracy, …)가 중요하지만, user는 future action에 대한 guide의 지표</li>
  <li>그러므로 Local Interpretable Model-Agnostic Explanations (LIME), Shapley additive explanations (SHAP)과 같은 post-hoc 분석, Attention weights를 통한 inherent interpretability를 이해할 필요가 있다.</li>
  <li>그러면 counterfactual forecast(determining what would have happened if a different set of circumstances had occurred) 가능</li>
</ul>

<h2 id="5-conclusions-and-future-directions">5. Conclusions and Future Directions</h2>
<ul>
  <li>Survey the main architectures used for TS forecasting</li>
  <li>Hybrid DL models : combine statistical and deep learning components</li>
  <li>Limitation : irregular TS나 hierarchical structure에 대한 고민은 하기 이전</li>
</ul>

<h2 id="추가">추가</h2>
<ul>
  <li>2020년에 발표된 survey 논문이지만 최근 Long-term Time Series Forecasting(LTSF)에 활용되는 모델에 대한 내용을 잘 정리한 논문이다.</li>
  <li>본 논문 이후 현재까지 최신 연구들을 이해한 상태로 읽는다면 최신 연구들의 motivation을 이해하는 데에 도움이 되는 논문이다.</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[Philos Trans R Soc A. 2020](https://arxiv.org/pdf/2004.13408.pdf)]]></summary></entry></feed>