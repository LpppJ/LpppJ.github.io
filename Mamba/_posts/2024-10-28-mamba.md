---
layout: post
related_posts:
  _
title: 
description: >
  [Arxiv 2023](https://arxiv.org/pdf/2312.00752)
sitemap:
    changefreq: daily
    priority: 1.0
hide_last_modified: true
---

# Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Arxiv 2023)

## Abstract

- ë§ì€ subquadratic-time architectures (linear attention, gated convolution and recurrent models, and structured state space models (SSMs))ê°€ Transformerì˜ ì—°ì‚° íš¨ìœ¨ì„±ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì•ˆë˜ì—ˆì§€ë§Œ
  - content-based reasoningì—ì„œëŠ” ì—¬ì „íˆ ì•½í•œ ëª¨ìŠµ
- ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œ ì œì‹œí•˜ëŠ” MambaëŠ”
  - **SSM parametersë¥¼ inputì˜ í•¨ìˆ˜ í˜•íƒœ**ë¡œ ë†“ì•„ì„œ ëª¨ë¸ì´ selectively propagate or forget information í•  ìˆ˜ ìˆë„ë¡ í•¨
  - ê·¸ë¦¬ê³  recurrent ëª¨ë“œë¡œ í•™ìŠµì„ ì§„í–‰í•˜ê²Œ ë˜ë©´ ì¤‘ê°„ Hidden State í¬ê¸°ê°€ ë§¤ìš° ì»¤ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì—
    - **hardware-aware parallel algorithm**ì„ ì‚¬ìš©í•˜ì—¬ hidden Stateë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ì§€ ì•Šê³  ë³‘ë ¬ì ìœ¼ë¡œ scan ì—°ì‚°í•¨

## 1. Introduction

- **Selection Mechanism**
  - parameterizing the SSM parameters based on the input
    - $$\to$$ í•„ìš”í•œ ì •ë³´ë§Œ ê¸°ì–µí•˜ê³  í•„ìš”ì—†ëŠ” ì •ë³´ filter out
- **Hardware-aware Algorithm**
  - ì—°ì‚° ì»¤ë„ì„ ê²°í•©í•˜ëŠ” ë°©ì‹(ì»¤ë„ ìœµí•©)ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì…ì¶œë ¥ ê³¼ì •ì„ ìµœì í™”í•˜ê³  ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì„
  - ê³ ì† ë©”ëª¨ë¦¬(SRAM)ë¥¼ í™œìš©í•´ ëŠë¦° GPU ë©”ëª¨ë¦¬(HBM) ì˜ì¡´ë„ë¥¼ ì¤„ì—¬ ì—°ì‚° ì†ë„ë¥¼ ë†’ì´ê² ë‹¤ëŠ” ê²ƒ
  - backpropagation í•  ë•Œì—ëŠ” hidden stateë¥¼ ì €ì¥í•˜ì§€ ì•Šê³  í•„ìš”í•  ë•Œë§ˆë‹¤ ì¬ê³„ì‚°í•¨ìœ¼ë¡œì¨ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”

![ê·¸ë¦¼1](/assets/img/mamba/mamba/fig1.png)

- **Architecture**
  - ê¸°ì¡´ SSM architecturesì™€ Transformerì˜ MLP blocksì„ í•©ì³ì„œ Mambaë¥¼ ë§Œë“¬

## 2. State Space Models

- Structured state space sequence models (S4)
  - inspired by a particular continuous system :
    - 1-dimensional function or sequence $x(t) \in \mathbb{R} \mapsto y(t) \in \mathbb{R}$ through an implicit latent state $h(t) \in \mathbb{R}^N$.
    - $$\begin{aligned} h^{\prime}(t) & =A h(t)+B x(t) \\ y(t) & =C h(t)\end{aligned}$$ (1)
    - 4ê°œì˜ parameters $$(\Delta, A, B, C)$$ë¡œ ì •ì˜ë¨ (ì•„ì§ inputì˜ í•¨ìˆ˜ í˜•íƒœê°€ ì•„ë‹˜)
- **Discretization**
  - ì²«ë²ˆì§¸ ë‹¨ê³„ëŠ” "continuous parameters" $$(\Delta, A, B)$$ë¥¼ "discrete parameters" $$(\bar{A}, \bar{B})$$ë¡œ ë°”ê¾¸ëŠ” ê²ƒ
    - fixed formulas $$\overline{A}=f_A(\Delta, A)$$ and $$\overline{B}=f_B(\Delta, A, B)$$ë¥¼ ì‚¬ìš©
    - $$\left(f_A, f_B\right)$$ëŠ” discretization rule
- **Computation**
  - $$(\Delta, A, B, C) \mapsto(\bar{A}, \bar{B}, C)$$ ë³€í™˜ì´ ëë‚¬ìœ¼ë©´ ê·¸ ë‹¤ìŒì—ëŠ” ë‹¤ìŒ ë‘ ê°€ì§€ í˜•íƒœì˜ computation ê°€ëŠ¥
    - a linear recurrence :
      - $$\begin{aligned} h_t & =\overline{A} h_{t-1}+\overline{B} x_t \\ y_t & =C h_t\end{aligned}$$ (2) ë˜ëŠ”
    - a global convolution :
      - $$\begin{aligned} \bar{K} & =\left(C \bar{B}, C \overline{A B}, \ldots, C \bar{A}^k \bar{B}, \ldots\right) \\ y & =x * \bar{K}\end{aligned}$$ (3)
- **Linear Time Invariance (LTI)**
  - ìœ„ (1) (2) (3) ëª¨ë¸ë“¤ì€ modelâ€™s dynamicsê°€ time-invariant
  - í•˜ì§€ë§Œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ LTI propertyê°€ ê·¼ë³¸ì ì¸ í•œê³„ê°€ ìˆìŒì„ ë°íˆê³ 
    - LTIë¥¼ ì œê±°í•˜ë©´ì„œë„ efficiency bottlenecksë¥¼ ê·¹ë³µí•¨ì„ ì œì‹œí•¨
- **Structure and Dimensions**
  - $$A$$ matrixë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— SSMì¸ê±°ê³ , ì´ë•Œ $$A \in \mathbb{R}^{N \times N}, B \in \mathbb{R}^{N \times 1}, C \in \mathbb{R}^{1 \times N}$$
  - total hidden state has dimensionì€: $$ğ·ğ‘$$ per input
  - the sequence length requires $$ğ‘‚(ğµğ¿ğ·ğ‘)$$

## 3. Selective State Space Models

- 3.1ì ˆì—ì„œëŠ” selection mechanismì„ ì†Œê°œí•˜ê³ 
- 3.2ì ˆì—ì„œëŠ” ì–´ë–»ê²Œ selection mechanismì´ SSMê³¼ ê°™ì´ ì“°ì¼ ìˆ˜ ìˆëŠ”ì§€ ë³´ê³ 
- 3.3ì ˆì—ì„œëŠ” hardware-aware algorithmì„ ì•Œì•„ë³´ê³ 
- 3.4ì ˆì—ì„œëŠ” simple SSMì„ attentionì´ë‚˜ MLPì—†ì´ ì•Œì•„ë³´ê³ 
- 3.5ì ˆì—ì„œëŠ” additional properties of selection mechanismsë¥¼ ë…¼ì˜í•œë‹¤

### 3.1. Motivation: Selection as a Means of Compression

- sequence modelingì˜ ë³¸ì§ˆì ì¸ ë¬¸ì œëŠ” **small stateì— contextë¥¼ ì••ì¶•**í•˜ëŠ” ê²ƒ
  - Trade off : ì••ì¶•ì„ ì•ˆí•˜ë©´ inefficientí•˜ê³ (Transformer) efficientí•˜ë©´ ì••ì¶•ì„ ë„ˆë¬´ ë§ì´ í•˜ê³ (RNN)

![ê·¸ë¦¼1](/assets/img/mamba/mamba/fig2.png)

- Synthetic task 2ê°€ì§€
  - **Selective Copying** 
    - í•„ìš”í•œ tokensì™€ ì•„ë‹Œ ê²ƒë“¤ì„ êµ¬ë³„í•˜ê¸° ìœ„í•´ content-aware reasoningí•˜ëŠ” task
  - **Induction Heads**
    - ë‹¤ìŒì— ë­ê°€ ì˜¬ì§€ ì¶”ë¡ í•˜ê¸° ìœ„í•´ context-aware reasoningí•˜ëŠ” task
  - ì´ ë‘ ê°€ì§€ëŠ” ìœ„ì—ì„œ ì†Œê°œí•œ LTI modeë¡œëŠ” í•˜ê¸° ì–´ë µë‹¤
- ê²°êµ­ì—ëŠ” efficientí•˜ë ¤ë©´ small stateë¥¼ ê°€ì ¸ì•¼ í•˜ëŠ”ë°, ê·¸ê±¸ "ì˜" í•˜ë ¤ë©´ selectivityë¥¼ "ì˜" í•´ì•¼ í•¨

### 3.2.  Improving SSMs with Selection

- ë³¸ ë…¼ë¬¸ì—ì„œ ì†Œê°œí•˜ëŠ” selection mechanismì€ modelì˜ parametersë¥¼ input-dependentí•˜ê²Œ ë§Œë“œëŠ” ê²ƒ
  - $$\Delta, B, C$$ì„ length dimension $$L$$ë¡œ ë§Œë“¬ (ì¦‰ time-invariantì—ì„œ time-varyingìœ¼ë¡œ)

![ê·¸ë¦¼1](/assets/img/mamba/mamba/algorithm12.png)

### 3.3 Efficient Implementation of Selective SSMs

- Convolutionì´ë‚˜ attentionì²˜ëŸ¼ GPU-friendlyí•˜ê²Œ Selective SSMì„ ë§Œë“¤ê³  ì‹¶ì€ ê±°ê³ 
- ì¦‰ ì‹œê°„ì— ë”°ë¼ í•„ìš”í•œ ì •ë³´ë¥¼ ì„ íƒì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê² ë‹¤ëŠ” ê²ƒ. ê·¸ëŸ¬ë©´ ë” ë¹ ë¥´ê²Œ ê¸´ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬

**3.3.1 Motivation of Prior Models**

- paying speed and memory costs ì—†ì´ maximize hidden state dimensioní•˜ê³  ì‹¶ìŒ
- Recurrent modeëŠ” hiddenì´ inputë³´ë‹¤ í›¨ì”¬ ì»¤ì„œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë§ìŒ
  - ê·¸ë˜ì„œ inputì˜ shape (=outputì˜ shape)ê³¼ ê°™ì€ convë¥¼ ì“°ê² ë‹¤
- ê¸°ì¡´ LTIëŠ” ë°ì´í„° íŠ¹ì„±ì„ ì˜ ë°˜ì˜ ëª»í–ˆì§€ë§Œ MambaëŠ” ìˆœí™˜ì  ìš”ì†Œì™€ ì»¨ë³¼ë£¨ì…˜ì  ìš”ì†Œë¥¼ ë™ì‹œì— ì‚¬ìš©í•´ ëª¨ë¸ì˜ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™” !

**3.3.2 Overview of Selective Scan: Hardware-Aware State Expansion**

- LTIì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” selection mechanismì„ ì†Œê°œ:
- ë¬¸ì œëŠ” (1) the sequential nature of recurrence, and (2) the large memory usage
  - (2) the large memory usageëŠ” kernel fusionìœ¼ë¡œ í•´ê²°
    - scan input $$(\bar{A}, \bar{B})$$ of size $$(B, L, D, N)$$ì„ HBMì— ì €ì¥í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼
    - the SSM parameters $$(\triangle, A, B, C)$$ì˜ final output $$(B, L, D)$$ë§Œ ì €ì¥
    - discretizationì´ë‘ recurrenceëŠ” SRAMì—ì„œ ìˆ˜í–‰
  - (1) the sequential nature of recurrenceëŠ” recomputationìœ¼ë¡œ í•´ê²°
    - intermediate statesë¥¼ ì €ì¥í•˜ì§€ ì•ŠëŠ”ë° ì´ê±´ backpropagationì—ì„œ í•„ìš”í•˜ë‹ˆê¹Œ
    - ê·¸ëƒ¥ ë‹¤ì‹œ ê³„ì‚°í•¨ (recomputation)
    - ê·¸ ê²°ê³¼ FlashAttentionê³¼ ìœ ì‚¬í•œ memory efficiency

### 3.4 A Simplified SSM Architecture

- MambaëŠ” linear attentionê³¼ MLPë¥¼ ê²°í•©í•´ì„œ gated attention unit(GAP)ì²˜ëŸ¼ ë§Œë“¬
- model dimensionì„ Dì—ì„œ expansion factor Eë¥¼ ì‚¬ìš©í•´ì„œ ëŠ˜ë ¤ì¤Œ
  - ëŒ€ë¶€ë¶„ì˜ model parameters $$3ED^2$$ê°œ $$2ED^2$$ê°œê°€ input projectionì—, $$ED^2$$ê°œê°€ output projectionì— ìˆìŒ
  - ë°˜ë©´ SSM ì•ˆì—ëŠ” parametersê°€ ë³„ë¡œ ì—†ëŠ”ë°, MambaëŠ” ì´ê±¸ ë°˜ë³µí•´ì„œ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— íš¨ìœ¨ì ì´ë‹¤

### 3.5 Properties of Selection Mechanisms

- The selection mechanismì€ RNNì´ë‚˜ CNNì— ì“¸ ìˆ˜ ìˆëŠ” broader conceptì„

**3.5.1 Connection to Gating Mechanisms**

- SSMì˜ ê²Œì´íŠ¸ ì—­í• ì„ í•˜ëŠ” $$\Delta$$ê°€ RNNì˜ ê²Œì´íŠ¸ì™€ ìœ ì‚¬í•˜ê²Œ ì‘ë™
  - ì…ë ¥ëœ ì •ë³´ ì¤‘ ì–´ë–¤ ê²ƒì„ ìœ ì§€í•˜ê³  ì–´ë–¤ ê²ƒì„ ë²„ë¦´ì§€ ê²°ì •í•˜ëŠ” ì—­í• ì¸ ì ë„ ë¹„ìŠ·
  - When $N=1, A=-1, B=1, s_{\Delta}=\operatorname{Linear}(x)$, and $\tau_{\Delta}=$ softplus,
  - $$\begin{aligned} & g_t=\sigma\left(\operatorname{Linear}\left(x_t\right)\right) \\ & h_t=\left(1-g_t\right) h_{t-1}+g_t x_t\end{aligned}$$ .
  - ì´ëŸ° ì‹ìœ¼ë¡œ $$g_t$$ê°€ í˜„ì¬ ì…ë ¥ $$x_t$$ê°€ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ í‘œí˜„í•˜ê²Œ í•˜ê³ 
    - $$g_t$$ê°€ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ $$x_t$$ë¥¼ ë§ì´ ë°˜ì˜, 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì´ì „ state $$h_{t-1}$$ì„ ë§ì´ ë°˜ì˜

**3.5.2 Interpretation of Selection Mechanisms**

- **Variable Spacing**
  - Selectivityì˜ ì—­í• ì€ filtering out irrelevant noise tokens that may occur between inputs of interest
- **Filtering Context**
  - contextê°€ ê¸¸ì–´ì§„ë‹¤ê³  ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ëŠ” ê²ƒì´ ì•„ë‹˜. ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì´ ë„ˆë¬´ ê¸´ sequenceì—ì„œ ë¶ˆí•„ìš”í•œ ì •ë³´ë¥¼ ì œê±°í•˜ì§€ ëª»í•´ì„œ ì„±ëŠ¥ ì €í•˜ê°€ ë°œìƒ
  - selective modelì€ stateë¥¼ ì–¸ì œë“  ì´ˆê¸°í™” í•  ìˆ˜ ìˆìœ¼ë‹ˆ ê¸´ sequenceê°€ ë“¤ì–´ì™”ì„ ë•Œ ì„±ëŠ¥ì´ ë” ì¢‹ì•„ì§€ë„ë¡ ì‘ë™
- **Boundary Resetting**
  - LTIëŠ” sequenceì˜ ê²½ê³„ì—ì„œ ì •ë³´ê°€ ì„ì´ëŠ” ë¬¸ì œê°€ ìˆì—ˆëŠ”ë°, selective SSMì€ ê·¸ëŸ° ë¬¸ì œ ì—†ìŒ
    - ì–¸ì œë“ ì§€ stateë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìœ¼ë‹ˆ ê·¸ëƒ¥ boundariesì—ì„œ ì´ˆê¸°í™” í•˜ë©´ ë¨ ($$g_t=1$$)

- **Interpretation of $$\Delta$$**
  - $$\Delta$$ê°€ í¬ë©´ ë‹¤ ìŠê³  í˜„ì¬ ì •ë³´ë¥¼ ìœ„ì£¼ë¡œ stateë¥¼ ë§Œë“œëŠ”ê±°ê³ , ì‘ìœ¼ë©´ ì´ì „ stateë¥¼ ìœ ì§€
- **Interpretation of A**
  - ì‚¬ì‹¤ $$\bar{A}=\exp (\Delta A)$$ë„ $$\Delta$$ë¥¼ í†µí•´ ë§Œë“¤ì–´ì§€ë‹ˆ í¬ê²Œ ê±´ë“œë¦¬ì§€ ë§ê³  ë‹¨ìˆœí•˜ê²Œ ë‘”ë‹¤
- **Interpretation of ğ‘© and ğ‘ª.**
  - ê²°êµ­ Selectivityì˜ ì—­í• ì€ filtering out.
  - Bì™€ CëŠ” ì…ë ¥ì„ ìƒíƒœë¡œ ì „ë‹¬í• ì§€, ìƒíƒœë¥¼ ì¶œë ¥ìœ¼ë¡œ ë‚´ë³´ë‚¼ì§€ë¥¼ ê²°ì •
  - ëª¨ë¸ì´ state(context)ë¥¼ ë” ì„¸ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆìŒ

### 3.6 Additional Model Details

pass

## 4. Empirical Evaluation

### 4.1 Synthetic Tasks

**4.1.1 Selective Copying**

**4.1.2 Induction Heads**

![ê·¸ë¦¼1](/assets/img/mamba/mamba/table12.png)

### 4.2. Language Modeling

![ê·¸ë¦¼1](/assets/img/mamba/mamba/table3.png)

### 4.5 Speed and Memory Benchmarks

![ê·¸ë¦¼1](/assets/img/mamba/mamba/fig8.png)

### 4.6. Model Ablations

![ê·¸ë¦¼1](/assets/img/mamba/mamba/table6.png)

![ê·¸ë¦¼1](/assets/img/mamba/mamba/table78.png)

## 5. Discussion

Pass

## 6. Conclusion

- a selection mechanism to structured state space models
  - to perform context-dependent reasoning
  - Without attention ! (simple attention-free architecture)