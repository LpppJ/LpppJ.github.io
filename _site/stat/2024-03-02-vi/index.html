<!DOCTYPE html>
<html lang="en"><!--
 __  __                __                                     __
/\ \/\ \              /\ \             __                    /\ \
\ \ \_\ \   __  __    \_\ \      __   /\_\      __       ___ \ \ \/'\
 \ \  _  \ /\ \/\ \   /'_` \   /'__`\ \/\ \   /'__`\    /'___\\ \ , <
  \ \ \ \ \\ \ \_\ \ /\ \L\ \ /\  __/  \ \ \ /\ \L\.\_ /\ \__/ \ \ \\`\
   \ \_\ \_\\/`____ \\ \___,_\\ \____\ _\ \ \\ \__/.\_\\ \____\ \ \_\ \_\
    \/_/\/_/ `/___/> \\/__,_ / \/____//\ \_\ \\/__/\/_/ \/____/  \/_/\/_/
                /\___/                \ \____/
                \/__/                  \/___/

Powered by Hydejack v9.1.6 <https://hydejack.com/>
-->







<head>
  






  
    
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Advanced Variational Inference(VI), Variational Autoencoder(VAE) | LpppJ</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="Advanced Variational Inference(VI), Variational Autoencoder(VAE)" />
<meta name="author" content="GW Jeong" />
<meta property="og:locale" content="en" />
<meta name="description" content="This is blog about machine learning, deep learning, artificial intelligence." />
<meta property="og:description" content="This is blog about machine learning, deep learning, artificial intelligence." />
<link rel="canonical" href="http://localhost:4000/stat/2024-03-02-vi/" />
<meta property="og:url" content="http://localhost:4000/stat/2024-03-02-vi/" />
<meta property="og:site_name" content="LpppJ" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-03-02T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Advanced Variational Inference(VI), Variational Autoencoder(VAE)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"GW Jeong"},"dateModified":"2024-03-04T16:34:37+09:00","datePublished":"2024-03-02T00:00:00+09:00","description":"This is blog about machine learning, deep learning, artificial intelligence.","headline":"Advanced Variational Inference(VI), Variational Autoencoder(VAE)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/stat/2024-03-02-vi/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/me/logo.jpg"},"name":"GW Jeong"},"url":"http://localhost:4000/stat/2024-03-02-vi/"}</script>
<!-- End Jekyll SEO tag -->


  

  



  <meta name="theme-color" content="rgb(230, 217, 195)">


<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta http-equiv="x-ua-compatible" content="ie=edge">

<meta name="mobile-web-app-capable" content="yes">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-title" content="LpppJ">
<meta name="apple-mobile-web-app-status-bar-style" content="default">

<meta name="application-name" content="LpppJ">

<meta name="generator" content="Hydejack v9.1.6" />


<link rel="alternate" href="http://localhost:4000/stat/2024-03-02-vi/" hreflang="en">

<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="LpppJ" />


<link rel="shortcut icon"    href="/assets/icons/favicon.ico">
<link rel="apple-touch-icon" href="/assets/icons/icon-192x192.png">

<link rel="manifest" href="/assets/site.webmanifest">

<link rel="dns-prefetch" href="https://fonts.googleapis.com"><link rel="dns-prefetch" href="https://fonts.gstatic.com">



<link rel="preload" href="/assets/img/swipe.svg" as="image" id="_hrefSwipeSVG">






<script>!function(r,c){"use strict";function a(e,t,n,o){e.addEventListener?e.addEventListener(t,n,o):e.attachEvent?e.attachEvent("on"+t,n):e["on"+t]=n}r.loadJS=function(e,t){var n=c.createElement("script"),e=(n.src=e,t&&a(n,"load",t,{once:!0}),c.scripts[0]);return e.parentNode.insertBefore(n,e),n},r._loaded=!1,r.loadJSDeferred=function(e,t){var n=c.createElement("script");function o(){r._loaded=!0,t&&a(n,"load",t,{once:!0});var e=c.scripts[0];e.parentNode.insertBefore(n,e)}return n.src=e,r._loaded?o():a(r,"load",o,{once:!0}),n},r.setRel=r.setRelStylesheet=function(e){a(c.getElementById(e),"load",function(){this.rel="stylesheet"},{once:!0})}}(window,document);
!function(a){"use strict";var b=function(b,c,d){function e(a){return h.body?a():void setTimeout(function(){e(a)})}function f(){i.addEventListener&&i.removeEventListener("load",f),i.media=d||"all"}var g,h=a.document,i=h.createElement("link");if(c)g=c;else{var j=(h.body||h.getElementsByTagName("head")[0]).childNodes;g=j[j.length-1]}var k=h.styleSheets;i.rel="stylesheet",i.href=b,i.media="only x",e(function(){g.parentNode.insertBefore(i,c?g:g.nextSibling)});var l=function(a){for(var b=i.href,c=k.length;c--;)if(k[c].href===b)return a();setTimeout(function(){l(a)})};return i.addEventListener&&i.addEventListener("load",f),i.onloadcssdefined=l,l(f),i};"undefined"!=typeof exports?exports.loadCSS=b:a.loadCSS=b}("undefined"!=typeof global?global:this);
!function(a){if(a.loadCSS){var b=loadCSS.relpreload={};if(b.support=function(){try{return a.document.createElement("link").relList.supports("preload")}catch(b){return!1}},b.poly=function(){for(var b=a.document.getElementsByTagName("link"),c=0;c<b.length;c++){var d=b[c];"preload"===d.rel&&"style"===d.getAttribute("as")&&(a.loadCSS(d.href,d,d.getAttribute("media")),d.rel=null)}},!b.support()){b.poly();var c=a.setInterval(b.poly,300);a.addEventListener&&a.addEventListener("load",function(){b.poly(),a.clearInterval(c)}),a.attachEvent&&a.attachEvent("onload",function(){a.clearInterval(c)})}}}(this);
!function(w) {
  w._baseURL = '/';
  w._publicPath = '/assets/js/';
  w._noPushState = false;
  w._noDrawer = false;
  w._noNavbar = false;
  w._noToc = false;
  w._noSearch = false;
  w._search = {
    DATA_URL: '/assets/sitedata.json?no-cache',
    STORAGE_KEY: 'mini-search/',
    INDEX_KEY: 'index--2024-03-04T20:55:02+09:00',
  };
  w._clapButton = true;
}(window);</script>


<script async src="/assets/bower_components/MathJax/es5/tex-mml-chtml.js" id="_MathJax"></script>


<!--[if gt IE 8]><!---->

  




<link rel="stylesheet" href="/assets/css/hydejack-9.1.6.css" id="_stylePreload">
<link rel="stylesheet" href="/assets/icomoon/style.css" id="_iconsPreload">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700%7CNoto+Sans:400,400i,700,700i&display=swap" id="_fontsPreload">



  <style id="_pageStyle">

html{--accent-color: rgb(94, 97, 94);--accent-color-faded: rgba(94, 97, 94, 0.5);--accent-color-highlight: rgba(94, 97, 94, 0.1);--accent-color-darkened: #4b4e4b;--theme-color: rgb(230, 217, 195)}
</style>


<!--<![endif]-->




</head>

<body class="no-break-layout">
  


<hy-push-state
  id="_pushState"
  replace-selector="#_main"
  link-selector="a[href]:not([href^='/assets/']):not(.external):not(.no-push-state)"
  script-selector="script"
  duration="500"
  hashchange
>
  
  
  <div id="_navbar" class="navbar fixed-top">
  <div class="content">
    <span class="sr-only">Jump to:</span>
    <div class="nav-btn-bar">
      <a id="_menu" class="nav-btn no-hover" href="#_drawer--opened">
        <span class="sr-only">Navigation</span>
        <span class="icon-menu"></span>
      </a>
      <div class="nav-span"></div>
    </div>
  </div>
</div>
<hr class="sr-only" hidden />

  <main
  id="_main"
  class="content layout-post"
  role="main"
>
  <nav id="breadcrumbs" class="screen-only"><ul>
  
  
    <li><a href="/">home</a></li>
    
      <li>
        
          <span>/</span>
          
          
          <a href="/stat/">stat</a>
        
      </li>
    
      <li>
        
          <span>/</span>
          <span>2024-03-02-vi</span>
        
      </li>
    
  
</ul></nav>
  










<article id="post-stat-vi" class="page post mb6" role="article">
  <header>
    <h1 class="post-title flip-project-title">
      
        Advanced Variational Inference(VI), Variational Autoencoder(VAE)
      
    </h1>

    <div class="post-date">
      
      <span class="ellipsis mr1">
        <time datetime="2024-03-02T00:00:00+09:00">02 Mar 2024</time> in <span>Stat</span> 
      </span>
      
    </div>

    
    

    



  <div class="hr pb0"></div>


  </header>

  
    <ul>
  <li>Paper : <a href="https://arxiv.org/abs/1601.00670">Variational Inference : A Review for Statisticians</a></li>
  <li>Paper : <a href="https://arxiv.org/pdf/1711.05597.pdf">Advances in Variational Inference</a></li>
  <li>Paper : <a href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes</a></li>
</ul>

<h2 id="1-probabilistic-ml-model">1. Probabilistic ML Model</h2>
<ul>
  <li>\(x\) : set of observed variables <br />
\(y\) : set of hidden / latent variables <br />
\(\theta\) : model parameters</li>
  <li>Discriminative probabilistic ML model
    <ul>
      <li>\(p(Y \mid X)\) : 데이터 \(X\)가 주어졌을 때 결과 \(y\) 예측하기 (Classification, Regression, …)</li>
    </ul>
  </li>
  <li>
    <p>Generative probabilistic ML model</p>

    <ul>
      <li>Bayes Theorem : \(p(Y \mid X)=\frac{p(X, Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{\int p(X \mid Y) p(Y) d Y}\)
<img src="/assets/img/stat/vi/fig1.png" alt="그림1" /></li>
    </ul>
  </li>
  <li>Discriminative model은 클래스(y) 사이의 차이를 의미하는 decision boundary를 학습하고, (\(p(Y\mid X)\))
Generative model은 분포 \(p(X), p(X,Y)\)를 학습하여 posterior \(p(Y\mid X)\)를 추정한다.</li>
  <li>\(Y\)의 차원이 높아질수록 분모에 있는 \(Y\)에 대한 적분이 어려워지기 때문에(intractable), 아래 두 가지 방법으로 \(p(Y\mid X)\)를 추정한다.
    <ul>
      <li>Variational Inference (optimization)</li>
      <li>Markov chain Monte Carlo (sampling)</li>
      <li>MCMC는 분포를 근사하기 위해 sampling으로 inference하는 것이고, VI는 분포를 근사하기 위해 optimization 문제로 바꾼 것이다.</li>
      <li>일반적으로 VI는 빠르고, MCMC는 정확하다.(상대적으로 그렇다는 것)</li>
    </ul>
  </li>
</ul>

<h2 id="2-variational-inference">2. Variational Inference</h2>
<ul>
  <li>The model: \(p_\theta(x)\) <br />
The data: \(\stackrel{}{D}=\left\{x_1, \ldots, x_N\right\}\) <br />
Maximum likelihood fit: \(\theta \leftarrow \operatorname{argmax}_\theta \frac{1}{N} \sum_i \log p_\theta\left(x_i\right)\) 
    <ul>
      <li>i.e. \(\theta \leftarrow \operatorname{argmax}_\theta \frac{1}{N} \sum_i \log \left(\int p_\theta\left(x_i \mid z\right) p(z) d z\right)\)</li>
      <li>i.e. \(\theta \leftarrow \operatorname{argmax}_\theta \frac{1}{N} \sum_i E_{z \sim p\left(z \mid x_i\right)}\left[\log p_\theta\left(x_i, z\right)\right]\)</li>
    </ul>
  </li>
  <li>log-likelihood \(\log p_\theta\)를 maximize : 
\(\begin{aligned}
  \log p\left(x_i\right) &amp; =\log \int p\left(x_i \mid z\right) p(z) d z \\
  &amp; =\log \int p\left(x_i \mid z\right) p(z) \frac{q_i(z)}{q_i(z)} d z \\
  &amp; =\log E_{z \sim q_i(z)}\left[\frac{p\left(x_i \mid z\right) p(z)}{q_i(z)}\right] \quad \left(\because E_{q(z)}[f(Z)]=\int f(z)q(z) dz\right) \\
  &amp; \geq E_{z \sim q_i(z)}\left[\log \frac{p\left(x_i \mid z\right) p(z)}{q_i(z)}\right] \quad (\because \text{Jensen's Inequality} : \varphi(E[X]) \geq E[\varphi(X)] (\varphi \ \text{is concave fn})) \\
  &amp; =E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]-E_{z \sim q_i(z)}\left[\log q_i(z)\right] \\
  &amp; =E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]+H\left(q_i\right) \quad (\text{where} \ H \ \text{is Entropy}) \\
  &amp; =E_{z \sim q_i(z)}\left[\log p_\theta \left(x_i, z\right)\right]+H\left(q_i\right) \\
  \\
  &amp; = \mathcal{L}_{i}\left(p, q_{i}\right)
  \end{aligned}\)</li>
  <li>위 식에서 \(E_{z \sim q_i(z)}\left[\log p\left(x_i, z\right)\right]\)은 \(q_i(z)\)가 \(p(x_i, z)\)의 density가 높은 곳에서 높은 density를 가질 때 커지고, \(H\left(q_i\right)\)는 \(q_i(z)\)가 고르게 퍼져있을 때 커진다.</li>
  <li>
    <p>위 전개식에서 부등식 앞뒤 식의 차이가 \(D_{\mathrm{KL}}\left(q_i\left(z_i\right) \| p\left(z \mid x_i\right)\right)\)가 되고, 그러므로 \(\mathcal{L}_{i}\left(p, q_{i}\right)\)를 maximize한다는 것은 \(D_{\mathrm{KL}}\left(q_i\left(z_i\right) \| p\left(z \mid x_i\right)\right)\)를 minimize한다는 것과 같다. (아래 전개식 참고)</p>

    <p><br />
\(\begin{aligned}
  D_{\mathrm{KL}}\left(q_i\left(x_i\right) \| p\left(z \mid x_i\right)\right) &amp; =E_{z \sim q_i(z)}\left[\log \frac{q_i(z)}{p\left(z \mid x_i\right)}\right]=E_{z \sim q_i(z)}\left[\log \frac{q_i(z) p\left(x_i\right)}{p\left(x_i, z\right)}\right] \\
  &amp; =-E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]+E_{z \sim q_i(z)}\left[\log q_i(z)\right]+E_{z \sim q_i(z)}\left[\log p\left(x_i\right)\right] \\
  \\
  &amp; =-E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]-\mathcal{H}\left(q_i\right)+\log p\left(x_i\right) \\
  &amp; =-\mathcal{L}_i\left(p, q_i\right)+\log p\left(x_i\right)
  \end{aligned}\)
\(\begin{aligned}
  &amp;\log p\left(x_i\right)=D_{\mathrm{KL}}\left(q_i(z) \| p\left(z \mid x_i\right)\right)+\mathcal{L}_i\left(p, q_i\right)
  \end{aligned}\)</p>
  </li>
  <li>\(\log p\left(x_i\right)\)가 고정되어 있다면, \(\mathcal{L}_i\left(p, q_i\right)\)를 maximize할 때 \(D_{\mathrm{KL}}\left(q_i(z) \| p\left(z \mid x_i\right)\right)\)가 minimize된다. <br />
(\(\mathcal{L}_i\left(p, q_i\right)\)은 ELBO이고, \(D_{\mathrm{KL}}\left(q_i(z) \| p\left(z \mid x_i\right)\right)\)은 variational distribution)</li>
  <li>이 때 학습되는 parameters는 아래와 같다.
    <ul>
      <li>\(z\)를 \(\hat x\)으로 mapping시키는 \(\theta\) (\(\theta\)는 \(\hat x\)가 \(x\)와 비슷해지도록 학습)</li>
      <li>\(z\)의 분포인 \(q_i(z)\)의 평균과 분산 (Gaussian을 가정)</li>
      <li>총 \(\mid \theta \mid +\left(\mid \mu_i\mid +\mid \sigma_i\mid \right) \times N\)개</li>
    </ul>
  </li>
</ul>

<h2 id="21-amortized-variational-inference">2.1. Amortized Variational Inference</h2>
<ul>
  <li>\(\mid \theta \mid +\left(\mid \mu_i\mid +\mid \sigma_i\mid \right) \times N\)개의 parameters는 데이터 개수가 늘어날수록 커진다는 단점이 있다.</li>
  <li>
    <p>Amortized Variational Inference는 \(q_i(z)\)가 아니라 \(q_\phi(z \mid x)=\mathcal{N}\left(\mu_\phi(x), \sigma_\phi(x)\right)\)가 \(p(x \mid z)\)와 비슷해지도록 학습한다.</p>

    <p><img src="/assets/img/stat/vi/fig2.png" alt="그림2" /></p>
  </li>
  <li>Basic Variational Inference는 sampled \(z\)로 \(\hat x\)를 만들어내는 것인데, Amortized Variational Inference는 \(x\)가 input으로 들어가면 latent vector \(z\)의 분포가 결정되고 그 분포에서 \(z\)를 sampling해서 \(\hat x\)를 만들어내기 때문에, autoencoder의 아이디어와 같다. 즉 VAE는 Amortized Variational Inference의 예시 중 하나이다.</li>
  <li>\(x\)가 input으로 들어가서 \(z\)의 분포가 결정되는 네트워크(\(\phi\))를 encoder, inference network가 되고, \(z\)로 \(\hat x\)을 만드는 네트워크(\(\theta\))를 decoder, generative network가 된다.</li>
  <li>\(p_\theta(x_i \mid z)\)를 Gaussian으로 가정한다는 것은, log를 씌웠을 때 exp 안에 있는 L2 term만 남기 때문에 \(\hat x\)과 \(x\)를 비교할 때 euclidean distance를 사용한다는 의미이다.</li>
  <li>이외에도 많은 variants of VI가 있지만 Amortized VI만 소개하는 이유는 VAE와 관련이 있기 때문이다.</li>
</ul>

<h2 id="22-mean-field-variational-inference">2.2. Mean-field Variational Inference</h2>
<ul>
  <li>Assumption : all latent variables are mutually independent (i.e. \(q(\mathbf{z})=\prod_{j=1}^m q_j\left(z_j\right) .\))</li>
  <li>Mean-field 가정을 하면 true posterior의 variables가 highly dependent인 경우에 approximation의 정확도가 다소 떨어지는 단점이 있지만, fully factorized distribution으로 계산이 간단해진다.</li>
  <li>ELBO를 maximize하는 \(q(z_i)\)들을 각각 찾고 다 곱해서 \(q(z)=q(z_1) \times ... \times q(z_M)\)을 계산하기 때문이다</li>
  <li>Mean-filed 가정을 하면 아까 봤던 식이 아래와 같이 전개된다.
\(\begin{aligned}
\mathrm{ELBO} &amp; =E_{q(z)}[\log p(x, z)-\log q(z)] \\
&amp; =E_{\prod_i q_i}\left[\log p(x, z)-\log \prod_i q_i\right] \ (\because \text{Mean-field assumption})\\
&amp; =\int \prod_i q_i\left\{\log p(x, z)-\log \prod_i q_i\right\} d z \ (\text{The definition of Expectation})\\
\\
&amp; =\int \prod_i q_i\left\{\log p(x, z)-\sum_i \log q_i\right\} d z \ (\text{Property of logarithm}) \\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int \prod_i q_i \sum_i \log q_i d z \ (\text{j번째 적분만 바깥으로 뺀 것})\\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int \prod_i q_i \log q_1 d z+\ldots \int \prod_i q_i \log q_M d z \\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int \prod_i q_i \log q_j d z+\text{(Constant)} \\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int q_j \log q_j d z_j+\text{(Constant)} \ (q_j\text{와 무관한 항들은 constant}) \\
&amp; =\int q_j E_{i \neq j}[\log p(x, z)] d z_j-\int q_j \log q_j d z_j+\text{(Constant)} \\
\\
&amp; =\int q_j \log \widetilde{p}\left(x, z_j\right) d z_j-\int q_j \log q_j d z_j+\text{(Constant)} \\
&amp; =\int q_j \log \frac{\widetilde{p}\left(x, z_j\right)}{q_j} d z_j+\text{(Constant)} \\
&amp; =-\mathrm{KL}\left[q_j \| \widetilde{p}\left(x, z_j\right)\right]+\text{(Constant)}
\end{aligned}\)</li>
  <li>위 결과로부터 \(q_j\)가 \(\tilde p(x,z_j)\)와 비슷해져야 한다는 것을 알 수 있다. 그러므로 \(q_j\)를 전개하고 normalization하면 아래와 같다. <br />
\(\begin{aligned}
q_j &amp; =\widetilde{p}\left(x, z_j\right) \\
\log q_j &amp; =\log \widetilde{p}\left(x, z_j\right) \\
\log q_j &amp; \propto E_{i \neq j}[\log p(x, z)] \\
q_j &amp; \propto \exp \left(E_{i \neq j}[\log p(x, z)]\right) \\
q_j &amp; =\frac{\exp \left(E_{i \neq j}[\log p(x, z)]\right)}{\int \exp \left(E_{i \neq j}[\log p(x, z)]\right) d z_j}
\end{aligned}\)</li>
  <li>optimal \(q^*_j\)를 알기 위해서 \(i\ne j\)에 대해 \(log\ p(x,z)\)의 expectation을 계산한다.</li>
</ul>

<h2 id="3-variational-autoencoder">3. Variational Autoencoder</h2>
<ul>
  <li>VAE는 2개의 neural network로 구성된다. 을 사용한다. (2개의 NN)
    <ul>
      <li>1) top-down generative model(=decoder) : mapping from the latent variable \(z\) to the data \(x\)</li>
      <li>2) bottom-up inference model(=encoder) : approximates the posterior \(p(z \mid x)\) (using amortized mean-field variational distribution)
<img src="/assets/img/stat/vi/fig3.png" alt="그림3" /></li>
    </ul>
  </li>
  <li>위 그림에서 나와있듯이 encoder를 거치면 deterministic하게 latent variable이 output으로 나오는 것이 아니다. output은 mean vector와 std dev vector이고, 이렇게 결정된 gaussian 분포에서 sampling을 통해 latent variable을 만든다. (VAE가 generative model인 이유이다.)</li>
  <li>Reparameterization trick : \(N(mean, std)\)에서 sampling하지 않고 \(N(0,1)\)에서 생성한 뒤 std를 곱하고 mean을 더해줌으로써 미분이 가능하도록 (backpropagation이 가능하도록) 한다.</li>
  <li>latent variable이 decoder를 거치면 input과 유사한(ideally) 새로운 데이터가 생성된다.</li>
  <li>
    <p>VAE의 loss는 다음과 같다.</p>

    <p>\(\arg \min _{\theta, \phi} \sum_i-\mathbb{E}_{q_\phi\left(z \mid x_i\right)}\left[\log \left(p\left(x_i \mid g_\theta(z)\right)\right)\right] \oplus K L\left(q_\phi\left(z \mid x_i\right) \| p(z)\right)\)</p>
    <ul>
      <li>학습 parameters는 encoder의 \(\phi\)와 decoder의 \(\theta\)이다.</li>
      <li>Reconstruction Error \(-\mathbb{E}_{q_\phi\left(z \mid x_i\right)}\left[\log \left(p\left(x_i \mid g_\theta(z)\right)\right)\right]\)
        <ul>
          <li>\(x\)가 주어졌을 때 encoder \(q_\phi\)를 지나 \(z\)생성 : \(q_\phi(z \mid x)\)</li>
          <li>그 \(z\)가 decoder \(g_\theta\)를 지나 \(x\) 생성 : \(g_\theta(z)\)</li>
          <li>이렇게 생성한 \(\hat x\)에 대한 \(x\)의 negative log-likelihood</li>
        </ul>
      </li>
      <li>Regularization Error \(K L\left(q_\phi\left(z \mid x_i\right) \| p(z)\right)\)
        <ul>
          <li>\(x\)가 주어졌을 때 encoder \(q_\phi\)를 지나 \(z\)생성 : \(q_\phi(z \mid x)\)</li>
          <li>그 \(z\)와 gaussian의 KL-divergence</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

  
</article>



  <hr class="dingbat related mb6" />






  
     


  <aside class="about related mt4 mb4" role="complementary">
    
    

<div class="author mt4">
  

  
    


<img
  
    src="https://via.placeholder.com/128x128"
    srcset="/assets/img/me/me.JPG 1x,/assets/img/me/me.JPG 2x"
    
  
  alt="GW Jeong"
  class="avatar"
  
  width="120"
  height="120"
  loading="lazy"
/>

  

  
  
  <h2  class="page-title hr-bottom">
    About
  </h2>

  <p>Bachelor’s degree in Applied Statistics. Yonsei Univ. (2018~2024) <br />
DataScienceLab 8th 학회장 (2022~2023) <br />
Master’s degree in Statitstics. Yonsei Univ. (2024~)</p>


  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/lpppj" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="mailto:wjdrjsdn39@yonsei.ac.kr" title="Email" class="no-mark-external">
      <span class="icon-mail"></span>
      <span class="sr-only">Email</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>

  </aside>


  

  
  

  
    


  

  
  

  
    

  


  
<footer class="content" role="contentinfo">
  <hr/>
  
    <p><small class="copyright">© Geonwoo Jeong.
</small></p>
  
  
    <p><small>Powered by <a class="external" href="https://hydejack.com/">Hydejack</a> v<span id="_version">9.1.6</span></small></p>
  <hr class="sr-only"/>
</footer>


</main>

  <hy-drawer
  id="_drawer"
  class=""
  side="left"
  threshold="10"
  noscroll
  
>
  <header id="_sidebar" class="sidebar" role="banner">
    




<div class="sidebar-bg sidebar-overlay" style="background-color:rgb(230, 217, 195);background-image:url(/assets/img/me/sidebar.jpg)"></div>

    <div class="sidebar-sticky">
  <div class="sidebar-about">
    
      <a class="no-hover" href="/" tabindex="-1">
        <img src="/assets/img/me/logo.jpg" class="avatar" alt="LpppJ" width="120" height="120" loading="lazy" />
      </a>
    
    <a class="sidebar-title" href="/"><h2 class="h1">LpppJ</h2></a>
    
    
      <p class="">
        DataScience and AI

      </p>
    
  </div>

  <nav class="sidebar-nav heading" role="navigation">
    <span class="sr-only">Navigation:</span>
<ul>
  
    
      
      <li>
        <a
          id="_drawer--opened"
          href="/timeseries/"
          class="sidebar-nav-item "
          
        >
          TimeSeries
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/stat/"
          class="sidebar-nav-item "
          
        >
          Statistics
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/project/"
          class="sidebar-nav-item "
          
        >
          Project
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/presentation/"
          class="sidebar-nav-item "
          
        >
          Presentation
        </a>
      </li>
    
  
</ul>

  </nav>

  
  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/lpppj" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="mailto:wjdrjsdn39@yonsei.ac.kr" title="Email" class="no-mark-external">
      <span class="icon-mail"></span>
      <span class="sr-only">Email</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>
  </header>
</hy-drawer>
<hr class="sr-only" hidden />

</hy-push-state>


  <!--[if gt IE 10]><!---->
  <script nomodule>!function(){var t,n=document.createElement("script");!("noModule"in n)&&"onbeforeload"in n&&(t=!1,document.addEventListener("beforeload",function(e){if(e.target===n)t=!0;else if(!e.target.hasAttribute("nomodule")||!t)return;e.preventDefault()},!0),n.type="module",n.src=".",document.head.appendChild(n),n.remove())}();
</script>
  <script src="/assets/js/hydejack-9.1.6.js" type="module"></script>
  <script src="/assets/js/LEGACY-hydejack-9.1.6.js" nomodule defer></script>
  

  

<!--<![endif]-->
  <!-- <script>
  document.querySelector('hy-push-state').setAttribute('prefetch', '');

  document.querySelectorAll('.sidebar a[href^="/"]').forEach(function (el) { 
    el.addEventListener('click', function (e) {
      if (el.pathname === window.location.pathname) {
        e.preventDefault();
        e.stopPropagation();
        document.querySelector('hy-drawer').close();
      }
    });
  });
</script> -->

<!--
Code for integrating CloudFlare's email protection with Hydejack's single page app loading.
-->
<script>
  document.getElementById('_pushState').addEventListener('hy-push-state-after', function (e) {
    function e(e){
      (console.error?console.error:console.log).call(console,e)
    }

    function t(e){
      return l.innerHTML='<a href="'+e.replace(/"/g,"&quot;")+'"></a>',l.childNodes[0].getAttribute("href")
    }

    function r(e,t){
      var r=e.substr(t,2);return parseInt(r,16)
    }

    function n(e,n){
      for(var o="",c=r(e,n),a=n+2;a<e.length;a+=2){
        var l=r(e,a)^c;
        o+=String.fromCharCode(l)
      }
      return t(o)
    }

    var o="/cdn-cgi/l/email-protection#",
        c=".__cf_email__",
        a="data-cfemail",
        l=document.createElement("div");

    !function(){
      for(var t=document.getElementsByTagName("a"),r=0;r<t.length;r++)
        try{
          var c=t[r],a=c.href.indexOf(o);
          a>-1&&(c.href="mailto:"+n(c.href,a+o.length))
        }catch(t){
          e(t)
        }
    }(),
    function(){
      for(var t=document.querySelectorAll(c),r=0;r<t.length;r++)
        try{
          var o=t[r],l=n(o.getAttribute(a),0),i=document.createTextNode(l);
          o.parentNode.replaceChild(i,o)
        }catch(t){
          e(t)
        }
    }()
  });
</script>





<div hidden>
  
  <h2 class="sr-only">Templates (for web app):</h2>

  <template id="_animation-template">
  <div class="animation-main fixed-top">
    <nav id="breadcrumbs" class="screen-only"><ul>
  
  
</ul></nav>
    <div class="content">
      <div class="page"></div>
    </div>
  </div>
</template>

  <template id="_loading-template">
  <div class="loading nav-btn fr">
    <span class="sr-only">Loading…</span>
    <span class="icon-cog"></span>
  </div>
</template>

  <template id="_error-template">
  <div class="page">
    <h1 class="page-title">Error</h1>
    
    
    <p class="lead">
      Sorry, an error occurred while loading <a class="this-link" href=""></a>.

    </p>
  </div>
</template>

  <template id="_permalink-template">
  <a href="#" class="permalink">
    <span class="sr-only">Permalink</span>
    <span class="content-hash"></span>
  </a>
</template>

</div>


</body>
</html>
