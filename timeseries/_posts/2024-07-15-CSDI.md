---
layout: post
related_posts:
  _
title: 
description: >
  [NeurIPS 2021](https://arxiv.org/pdf/2107.03502)
sitemap:
    changefreq: daily
    priority: 1.0
hide_last_modified: true
---

# CSDI: Conditional Score-based Diffusion Models for Probabilistic Time Series Imputation

## Abstract

- Imputation에서 autoregressive models보다 score-based diffusion models의 성능이 좋음
- Conditional Score-based Diffusion models for Imputation (CSDI)
  - explicitly trained for imputation
  - can exploit correlations between observed values

## 1. Introduction

![그림1](/assets/img/timeseries/CSDI/fig1.png)

- Conditional diffusion modeld을 위해서 필요한 것들
  - observed values (i.e., conditional information) 
  - ground-truth missing values (i.e., imputation targets)
  - 하지만 실제로는 ground-truth missing values를 모르기 때문에
  - masked language modeling처럼 self-supervised training
    -  separates observed values into conditional information and imputation targets

## 2. Related Work

- RNN $$\to$$ GAN and self-training(deterministic) $$\to$$ GP-VAE(probabilistic)
- [TimeGrad(ICML 2021)](https://arxiv.org/pdf/2101.12072)에서 diffusion probabilistic models 사용하여 SOTA
  - but 과거를 보는 RNNs을 썼기 때문에 time series imputation으로 활용되기는 어려움

## 3. Background

### 3.1. Multivariate time series imputation

- $$\mathbf{X}=\left\{x_{1: K, 1: L}\right\} \in \mathbb{R}^{K \times L}$$, $$K$$는 the number of features, $$L$$은 length of sequence
- observation mask : $$\mathbf{M}=\left\{m_{1: K, 1: L}\right\} \in\{0,1\}^{K \times L}$$
  - $$x_{k, l}$$가 missing이면 $$m_{k, l}=0$$, observed이면 $$m_{k, l}=1$$
- Timestamps of the time series $$\mathbf{s}=\left\{s_{1: L}\right\} \in \mathbb{R}^L$$
- 즉 각각의 time series는 $$\{\mathbf{X}, \mathbf{M}, \mathbf{s}\}$$로 표현됨

### 3.2. Denoising diffusion probabilistic models

- forward process : $$q\left(\mathbf{x}_{1: T} \mid \mathbf{x}_0\right):=\prod_{t=1}^T q\left(\mathbf{x}_t \mid \mathbf{x}_{t-1}\right) \text { where } q\left(\mathbf{x}_t \mid \mathbf{x}_{t-1}\right):=\mathcal{N}\left(\sqrt{1-\beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I}\right)$$
- reverse process : $$\begin{aligned}
  & p_\theta\left(\mathbf{x}_{0: T}\right):=p\left(\mathbf{x}_T\right) \prod_{t=1}^T p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right), \quad \mathbf{x}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
  & p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right):=\mathcal{N}\left(\mathbf{x}_{t-1} ; {\mu}_\theta\left(\mathbf{x}_t, t\right), \sigma_\theta\left(\mathbf{x}_t, t\right) \mathbf{I}\right)
  \end{aligned}$$

### 3.3 Imputation with diffusion models

- conditional observation $$\mathbf{x}_0^{\mathrm{co}} \in \mathcal{X}^{\mathrm{co}}$$를 활용해서 Imputation target $$\mathbf{x}_0^{\mathrm{ta}} \in \mathcal{X}^{\mathrm{ta}}$$을 생성
- Reverse process에 conditional 추가 : modeling $$p_\theta\left(\mathbf{x}_{t-1}^{\mathrm{ta}} \mid \mathbf{x}_t^{\mathrm{ta}}, \mathbf{x}_0^{\mathrm{co}}\right)$$

## 4. Conditional score-based diffusion model for imputation (CSDI)

- Reverse process of the conditional diffusion model, and self-supervised training method

### 4.1. Imputation with CSDI

- all observed values of $$\mathbf{x}_0$$ as conditional observations $$\mathbf{x}_0^{\mathrm{co}}$$,
  - all missing values as imputation targets $$\mathbf{x}_0^{\mathrm{ta}}$$
- Parameterization with $${\epsilon}_\theta$$: $${\mu}_\theta\left(\mathbf{x}_t^{\mathrm{ta}}, t \mid \mathbf{x}_0^{\mathrm{co}}\right)={\mu}^{\mathrm{DDPM}}\left(\mathbf{x}_t^{\mathrm{ta}}, t, {\epsilon}_\theta\left(\mathbf{x}_t^{\mathrm{ta}}, t \mid \mathbf{x}_0^{\mathrm{co}}\right)\right), \quad \sigma_\theta\left(\mathbf{x}_t^{\mathrm{ta}}, t \mid \mathbf{x}_0^{\mathrm{co}}\right)=\sigma^{\mathrm{DDPM}}\left(\mathbf{x}_t^{\mathrm{ta}}, t\right)$$

### 4.2. Training of CSDI

![그림2](/assets/img/timeseries/CSDI/fig2.png)

![그림6](/assets/img/timeseries/CSDI/fig6.png)

- Train $${\epsilon}_\theta$$ by minimizing the loss function : $$\min _\theta \mathcal{L}(\theta):=\min _\theta \mathbb{E}_{\mathbf{x}_0 \sim q\left(\mathbf{x}_0\right), {\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}), t}\left\|\left({\epsilon}-{\epsilon}_\theta\left(\mathbf{x}_t^{\mathrm{ta}}, t \mid \mathbf{x}_0^{\mathrm{co}}\right)\right)\right\|_2^2$$
- fig2는 Masked modeling에서 아이디러를 얻은 CSDI의 self-supervised learning method
  - 흰색은 missing, 파랑색은 observed이다.
  - observed의 일부를 imputation target(빨강색)으로 분리하고 noise를 씌운다.
  - 남은 observed와 noisy target을 보고 imputation target을 맞추도록 학습한다.
  - 학습 할 때에만 이렇게 하고 실제 sampling(imputation)은 missing(흰색)에 하는 것

![그림11](/assets/img/timeseries/CSDI/table1.png)

### 4.3. Choice of imputation targets in self-supervised learning

- *Random* strategy : missing patterns 모를 때 일정 비율만큼 imputation target으로 설정
- *Historical* strategy : exploits missing patterns in the training dataset. training과 test의 missing pattern이 highly correlated일 때
- *Mix* strategy : 위 두 가지 방법 mix. Training의 missing pattern에 overfitting되는 것을 방지
- *Test* pattern strategy : test의 missing pattern 알 때

## 5. Implementation of CSDI for time series imputation

![그림3](/assets/img/timeseries/CSDI/fig3.png)

- $$\mathbf{x}_t^{\mathrm{ta}}$$와 $$\mathbf{x}_0^{\mathrm{co}}$$를 $$\mathbb{R}^{K \times L}$$로 만들어주기 위해 zero-padding
  - 모델의 input에 conditional mask $$\mathbf{m}^{\mathrm{co}} \in\{0,1\}^{K \times L}$$를 추가
- The conditional denoising function $${\epsilon}_\theta\left(\mathbf{x}_t^{\mathrm{ta}}, t \mid \mathbf{x}_0^{\mathrm{co}}, \mathbf{m}^{\mathrm{co}}\right)$$은 $${\epsilon}_\theta:\left(\mathbb{R}^{K \times L} \times \mathbb{R} \mid \mathbb{R}^{K \times L} \times\{0,1\}^{K \times L}\right) \rightarrow \mathbb{R}^{K \times L}$$로 표현됨

### Attention mechanism

- Multivariate time series의 temporal and feature dependency를 파악하기 위해
  - two dimensional attention mechanism 활용 (conv 대신)
  - 각각을 temporal Transformer layer and a feature Trans- former layer라 함

## 6. Experimental results

### 6.1. Time series imputation

![그림12](/assets/img/timeseries/CSDI/table2.png)

![그림4](/assets/img/timeseries/CSDI/fig4.png)

![그림13](/assets/img/timeseries/CSDI/table3.png)

### 6.2. Interpolation of irregularly sampled time series

![그림14](/assets/img/timeseries/CSDI/table4.png)

### 6.3. Time series Forecasting

![그림15](/assets/img/timeseries/CSDI/table5.png)

## 7. Conclusion

- CSDI : novel approach to impute multivariate time series with conditional diffusion models
- Future works
  - improve the computation efficiency
  - extend CSDI to downstream tasks such as classifications