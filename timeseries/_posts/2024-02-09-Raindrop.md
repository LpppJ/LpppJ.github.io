---
layout: post
related_posts:
  _
title: 
description: >
  [ICLR 2022](https://arxiv.org/abs/2110.05357)
sitemap: false
hide_last_modified: true
---

# (Raindrop) Graph-guided Network for Irregularly Sampled Multivariate Time Series

## Abstract

- 헬스케어, 기후 등 많은 도메인에서 irregularly sample이 발생한다.
- 본 논문에서 제안하는 Raindrop 모델은 latent sensor graph structure를 추정하고,
irregularity로 인한 misalign readouts를 예측하기 위해 인접한 관측치를 활용한다.
- 결국 하나의 다변량 시계열 데이터에 대한 classification (# timepoints) x (# sensors) → (pred cls)

## 1. Introduction

- Irregularity의 원인은 센서고장, 의료처방 등으로 인한 missing observations.
- 언뜻 생각하면 missing values를 채워넣은 뒤 irregularity가 없는 상황처럼 접근하면 될 것 같고,
실제로도 다양한 방법으로 [imputation → optimize] 2단계 접근방법을 사용하였다.
- 하지만 missing이 발생했다는 사실도 하나의 정보인데, 이를 활용할 수가 없으니 정보를 최대한 활용하는 방식은 아니라는 점에서 suboptimal performance를 보여주었다.
- Time series에서는 inter-sensor correlation에 많은 정보가 있다고 알려져 있기 때문에, 본 논문에서는 graph neural network로 sample-varying and time varying structure를 학습한다. (즉 dependency structure가 sample에 따라서도 다르고, 하나의 sample에 대해서도 시간에 따라 달라진다.)
- 모델명이 Raindrop인 이유는 관측값 측정이 마치 빗방울이 떨어지는 것과 비슷하기 때문이다. 빗방울이 표면(i.e. 지면)에 떨어질 때 빗방울이 표면의 모든 지점에 동시에 떨어지지 않고, 표면에 떨어지는 빗방울은 작은 잔물결을 만드는데 - 이처럼 각 관측치(i.e. 빗방울)는 센서(i.e. surface)에 의해서 비동시다발적으로 측정되고, 모든 관측치는 다른 센서에 영향을 주는 모습(passing message)이 빗방울이 떨어지는 모습과 비슷하다.

## 2. Related Work

- Abstract에서 언급한 것처럼, 직관적으로는 irregular time series를 다룰 때에 imputation을 해서 regular하게 생각하면 될 것 같은데, 그랬을 경우에는 underlying distribution을 왜곡하거나, 우리가 원하지 않는 distribution shift가 발생할 수 있기 때문에, irregular한 시계열을 그대로 활용하는 것이 일반적이다.
- GRU-D, SeFT, mTAND, IP-Net, DGM가 Raindrop과 비슷한 task를 하는 모델들이라고 할 수 있다.
- 다만 Raindrop만의 차별점은 message passing network(edges btw sensors)를 고정된 것이 아니라, 학습 가능한 adjacency matrices로 명시하였다는 점이다.

## 3. Raindrop

- $$\cal D=\{(\cal S_i, y_i) \mid i=1,...,N \}$$ : 하나의 irregular time series. 이 때 $$y_i \in \{ 1,...,C\}$$는 라벨의 개수가 C개임을 의미한다. 하나의 시계열 $$\cal S_i$$는 M개의 센서로 구성되고, time stamp의 길이는 T인데 센서마다 모든 $$t\in T$$마다 측정된 것은 아니다. 예를 들어 센서가 2개이고 센서 u가 1,3,5 시점에 측정되고 센서 v가 2,4,6 시점에 측정 되었다면 $$T=\{1,2,3,4,5,6 \}$$이 된다.
- 결국 풀고자 하는 문제는 $$f:\cal S_i \to z_i$$ 라는 함수를 학습하는 것이며, 이 때 $$z_i$$는 downstream-task를 위한 fixed-length representation이다. 본 논문에서는 classification을 수행했으므로 $$z_i \to \hat y_i\in\{1,...,C\}$$를 하겠지만, 핵심은 $$z_i$$를 만들어내는 과정이다.
- Raindrop은 observation embedding → sensor embedding → sample embedding 이라는 3단계를 거친다.
    
- observation embedding : 먼저 모든 t에 대해서, t 시점에 기록된 센서 u의 관측치 $$x^t_{i,u}$$을 emnbedding하고, u와 연결된 센서로 messages를 보낸다. 그러면 t 시점에 기록된 센서 u는 물론, 기록되지 않은 센서 v에 대해서도 t시점의 관측값은 embedding이 된다.
    
- sensor embedding : 센서별로 모든 observation embeddings를 합친다. 이 때 temporal attention을 사용한다.
    
- sample embedding : 모든 sensor embedding을 모아서 하나의 sample에 대한 embedding을 만든다.

## 4. Experiments

![그림1](/assets/img/timeseries/raindrop/table1.png)

- Setting 1) Training(80%) : Validation(10%) : Test(10%)로 랜덤하게 나누고 각 Method로 classification을 했을 때의 결과이다. P19와 P12는 binary, PAM은 8-class이다.

![그림2](/assets/img/timeseries/raindrop/table2.png)
- Setting 2,3) 일정 비율의 센서를 missing으로 만든다. 해당 센서들은 training 부분에 대해서는 그대로 두고, validation과 test 부분을 모두 0으로 바꾼다. setting 2는 가장 중요하다고 판단되는 센서들을 0으로 바꾸었고, setting 3는 랜덤하게 센서들을 0으로 바꾸었다.

## 5. Conclusion

- Raindrop은 하나의 다변량 시계열을 하나의 그래프로 보고, 각 그래프의 sample-varying & time-varying -sensor dependency를 학습했다. 그래프의 구조를 misaligned observations를 다루기 위해 활용했다는 점에서 다른 모델과 방법론적 차별점이 있다.

## Implementation

![그림3](/assets/img/timeseries/raindrop/implementation.png)
- P19 데이터셋에 대해서 Table1과 동일한 조건으로 모델을 실행했을 때 Table1과 유사한 성능이 나오는지 확인하였다.

## 추가

- 본 논문에서는 각 센서를 embedding하고, 센서들의 embedding들을 합쳐서 시계열에 대한 embedding을 얻는다. 각 시계열에 대해 센서별 embedding은 얻을 수 있지만, 특정 시점에서의 모든 센서의 상태를 표현하는 embedding은 얻을 수 없다. 각 시계열에 대해 센서별 embedding과 시점별 embedding을 모두 구할 수 있다면 더 좋은 성능을 낼 수 있을지 생각해봐야겠다.