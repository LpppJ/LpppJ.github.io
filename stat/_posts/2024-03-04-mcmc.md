---
layout: post
related_posts:
  _
title: 
description: >
sitemap:
    changefreq: daily
    priority: 1.0
hide_last_modified: true
---

# MCMC with Implementation (1) : Metropolis Hastings algorithm

## 1. Probabilistic ML Model
- $$x$$ : set of observed variables \
  $$y$$ : set of hidden / latent variables \
  $$\theta$$ : model parameters
- Discriminative probabilistic ML model
  
  - $$p(Y \mid X)$$ : 데이터 $$X$$가 주어졌을 때 결과 $$y$$ 예측하기 (Classification, Regression, ...)
- Generative probabilistic ML model

  - Bayes Theorem : $$p(Y \mid X)=\frac{p(X, Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{\int p(X \mid Y) p(Y) d Y}$$
  ![그림1](/assets/img/stat/vi/fig1.png)
- Discriminative model은 클래스(y) 사이의 차이를 의미하는 decision boundary를 학습하고, ($$p(Y\mid X)$$)
  Generative model은 분포 $$p(X), p(X,Y)$$를 학습하여 posterior $$p(Y\mid X)$$를 추정한다.
- $$Y$$의 차원이 높아질수록 분모에 있는 $$Y$$에 대한 적분이 어려워지기 때문에(intractable), 아래 두 가지 방법으로 $$p(Y\mid X)$$를 추정한다.
  - Variational Inference (optimization)
  - Markov chain Monte Carlo (sampling)
  - MCMC는 분포를 근사하기 위해 sampling으로 inference하는 것이고, VI는 분포를 근사하기 위해 optimization 문제로 바꾼 것이다.
  - 일반적으로 VI는 빠르고, MCMC는 정확하다.(상대적으로 그렇다는 것)

## 2. Markov Chain Monte Carlo
### 2.1. The properties of MC
- **Markov Chain** : $$\operatorname{Pr}\left\{X_{t+1}=j_{t+1} \mid X_t=j_t, X_{t-1}=j_{t-1}, \cdots, X_0=j_0\right\} = \operatorname{Pr}\left\{X_{t+1}=j_{t+1} \mid X_t=j_t\right\}$$
- **Transition probability** : $$\mathbf{P}=\left(\left(p_{i j}\right)\right) ; \quad \operatorname{Pr}\left\{X_t=j \mid X_0=i\right\}=\left(\mathbf{P}^t\right)_{i j}$$ \
  where $$p_{i j}=\operatorname{Pr}\left\{X_{t+1}=j \mid X_t=i\right\}$$
  ![그림2](/assets/img/stat/mcmc/fig1.jpeg)
- **Irreducible** : $$\left(\mathbf{P}^t\right)_{i j}=\operatorname{Pr}\left\{X_t=j \mid X_0=i\right\}>0$$ for some $$t>0, and all $i$ and $j$ in $\Omega$.$$
  - 현재 state가 무엇이든, 모든 state에 언젠가는 도달할 수 있어야 한다.
  - Markov Chain이 irreducible하면 unique한 stationary probabilities를 가진다. \
    i.e. $$\pi_j=\lim _{n \rightarrow \infty} \frac{1}{n} \sum_{t=1}^n I\left(X_t=j\right) \text { w.p.1 for all initial states}$$
  - Indicator의 expectation은 probability이므로 $$\pi_j=\lim _{n \rightarrow \infty} \frac{1}{n} \sum_{t=1}^n \operatorname{Pr}\left\{X_t=j \mid X_0=i\right\}, \text { for all initial states}$$
- **Aperiodic** : $$\operatorname{Pr}\left\{X_t=j \mid X_0=j\right\}>0 \text { and } \operatorname{Pr}\left\{X_{t+1}=j \mid X_0=j\right\}>0$$
  - 주기가 없다는 것을 수학적으로 표현하면 위와 같다. Irreducible한 Markov Chain이 하나 이상의 self-loop를 가진다면 aperiodic하다.
- **Time-reversible** : $$\pi_i p_{i j}=\pi_j p_{j i}, \quad \forall i \neq j$$
  - `i에 도달하고 i에서 j가 될 확률`과 `j에 도달하고 j에서 i가 될 확률`이 같다는 의미
- 많은 경우의 Markov Chains는 irreducible, aperiodic, time-reversible하다.
- 결국 하고자 하는 것은 $$E[h(X)]=\sum_{j=1}^N h(j) \pi_j$$를 $$\frac{1}{n} \sum_{t=1}^n h\left(X_t\right)$$로 추정하는 것이다.

### 2.2. Metropolis-Hastings algorithm
- Goal : (MCMC를 왜 할까?)
  - $$X \sim F$$ with density f를 sampling하고 싶은데 independent sampling이 불가능하기 때문에 최대한 independent한 samples를 만드는 것
- $$F$$로부터 직접 sampling하기 어려운 경우에, sampling이 쉬운 proposal density $$q(x' \mid x)$$에서 propose
- $$q(x' \mid x)$$에서의 proposed sample은 $$\alpha=\min \left(\frac{f\left(x^{\prime}\right) q\left(x \mid x^{\prime}\right)}{f(x) q\left(x^{\prime} \mid x\right)}, 1\right)$$확률로 sample에 추가, 아니면 stay $$x$$
- 정리하면
  - Step1. Proposal density $$q(x' \mid x)$$를 선택한다.
  - Step2. 적당한 initial state $$X_0 = x_0$$를 정한다.
  - Step3. $$X' \sim q(x' \mid X_t)$$와 $$U \sim Unif(0,1)$$을 생성한다.
  
  - Step4. $$U<\frac{f\left(X^{\prime}\right) q\left(X_t \mid X^{\prime}\right)}{f\left(X_t\right) q\left(X^{\prime} \mid X_t\right)}, \text { then } X_{t+1}=X^{\prime} . \text { Else } X_{t+1}=X_t$$
  - Step5. $$t = t + 1$$, Go to Step3
- 이 때 proposal density가 symmetric density이면 $$\frac{q\left(X_t \mid X^{\prime}\right)}{q\left(X^{\prime} \mid X_t\right)}=1$$이 되어 계산할 필요가 없어진다.
- ![그림3](/assets/img/stat/mcmc/fig2.png)
- 예를 들어, MCMC로 생성한 samples의 trace plot이 위와 같다면 target distribution은 $$(-2,2)$$에서 높은 density를 갖는다는 것을 알 수 있고, initial state와 무관하게 빠르게 수렴하는 것을 볼 수 있다.

## 3. R Implementation : MH-algorithm
- 예시를 통해 MH-algorithm을 구현해본다.
  - Target density : $$g(x)=\exp \left(-(x+1)^2-y^2\right)+\exp \left(-150\left(x^2-y\right)^2-150\left(x-y^2\right)^2\right)$$
    - 복잡한 un-normalized density이므로 직접 sampling하기가 어렵기 때문에 MH-algorithm으로 sampling한다.
  - Proposal distribution : $$\left(\begin{array}{l} x_{new} \\ y_{new} \end{array}\right) \sim N\left(\left(\begin{array}{l} x_{now} \\ y_{now} \end{array}\right), \sigma^2\left(\begin{array}{ll} 1 & \rho \\ \rho & 1 \end{array}\right)\right)$$ where $$\sigma^2 > 0, \rho \in (-1,1)$$'
- 먼저 target density를 visualization해서 파악한다.
- ~~~r
  g <- function(x, y) {
    exp(-(x + 1)^2 - y^2) + exp(-150*(x^2 - y)^2 - 150*(x - y^2)^2)}

  x <- seq(-3, 2, length.out = 100);y <- seq(-2, 2, length.out = 100)
  z <- outer(x, y, g)
  par(mfrow=c(1,1))
  contour(x, y, z, xlab = "X", ylab = "Y",
          main="The contour plot of density g")
  ~~~
  ![그림4](/assets/img/stat/mcmc/fig3.png)
  ~~~r
  par(mfrow=c(1,2))
  x <- seq(-3, 2, length.out = 100); y <- seq(-2, 2, length.out = 100)
  z <- outer(x, y, g)
  res1 <- persp(x, y, z, theta = 30, phi = 20, expand = 0.5,
                col = "green", xlab = "X", ylab = "Y", zlab = "Z",
                main = "The density plot of g")
  res2 <- persp(x, y, z, theta = 70, phi = 20, expand = 0.5,
                col = "green", xlab = "X", ylab = "Y", zlab = "Z",
                main = "The density plot of g")
  ~~~
  ![그림5](/assets/img/stat/mcmc/fig4.png)
- MH-algorithm을 함수로 작성한다.
  ~~~r
  MCMC.MH <- function(n, init, sigma, rho) {
  
  ############################################################
  # n : sample size
  # init : starting value (initialization)
  # sigma, rho : parameters for covariance matrix of proposal distribution
  ############################################################

  # sample space for x, y
  x <- rep(NA, n); y <- rep(NA, n)

  # initialization
  x[1] <- init[1]; y[1] <- init[2]
  
  # run the loop until sample space is full
  for (i in 2:n) {

    # 현재값(=current, =now)이 new x, new y의 분포를 결정한다. (Markov chain의 property)
    current <- c(x[i-1], y[i-1])

    # Proposed sample
    proposal <- rmvnorm(1, mean = current,
                           sigma = matrix(c(1, rho, rho, 1) * sigma^2, ncol = 2))

    # Accept probability
    # Note: Proposal function이 normal(symmetric)이므로 q항이 약분된다.                       
    a <- g(proposal[1], proposal[2]) / g(current[1], current[2])
    
    # Accept or Reject
    if (runif(1) < a) {x[i] <- proposal[1]; y[i] <- proposal[2]}
    else {x[i] <- current[1]; y[i] <- current[2]}}

  # when sample space is full, we will return  
  return(list(x = x, y = y))}
  ~~~
- 이제 MCMC를 실행하고 결과를 본다.
  ~~~r
  n <- 1e6
  samples.1 <- MCMC.MH(n = n, init = c(-10, -10), sigma = 0.1, rho = 0)
  plot(samples.1$x, samples.1$y, main = "Scatter plot of x and y", pch = 20, cex = 0.1)
  ~~~
  ![그림6](/assets/img/stat/mcmc/fig5.png)
  - 생성된 samples가 점점 target density가 높은 방향으로 움직인다.
- Density plot가 target density와 비슷한지, trace plot으로 chain이 잘 수렴하는지, acf plot으로 얼마나 dependent한지 눈으로 확인할 수 있다.
  ~~~r
  # density plot
  par(mfrow = c(1,2))
  hist(samples.1$x, main = "Histogram of x", freq=FALSE, breaks=100)
  hist(samples.1$y, main = "Histogram of y", freq=FALSE, breaks=100)

  # trace plot
  ts.plot(samples.1$x, main = "Trace plot of x")
  ts.plot(samples.1$y, main = "Trace plot of y")

  # acf plot
  acf(samples.1$x, main = "Autocorrelation of x")
  acf(samples.1$y, main = "Autocorrelation of y")
  ~~~
  ![그림7](/assets/img/stat/mcmc/fig6.jpg)
- Tuning :
  - initial point가 (-10, 10)이므로 x와 y가 모두 커져야 target density가 높은 방향으로 움직인다.
    - $$rho>0$$으로 설정
  - initial point가 target density가 높은 곳과 멀리 떨어져있다
    - $$sigma >> 0.1$$으로 설정
  - 결과는 아래와 같다.
  ~~~r
  samples.4 <- MCMC.MH(n = n, init = c(-10, -10), sigma = 4, rho = 0.8)
  par(mfrow=c(1,1))
  plot(samples.4$x, samples.4$y, main = "Scatter plot of x and y", pch = 20, cex = 0.1)
  # 얼마나 빠르게 수렴하는지 보기 위해 첫 10개 sample을 색칠을 해주었다.
  for (i in 1:10){points(samples.4$x[i], samples.4$y[i], col = i, pch = 20, cex = 1)}
  ~~~
  ![그림8](/assets/img/stat/mcmc/fig7.png)
  - Scatter plot으로부터 수렴이 훨씬 빠르게 되었음을 확인할 수 있다. sigma로 보폭을, rho로 방향을 적절하게 설정했기 때문이다.
  - 물론 burn-in을 통해 수렴하기 전의 samples를 제거할 수 있다. 하지만 target distribution이 퍼져있는 정도를 고려했을 때, sigma를 늘리지 않을 이유는 없다.
  ![그림9](/assets/img/stat/mcmc/fig8.jpeg)
  - Acf plot이 유의미하게 낮아졌다. sigma가 커짐에 따라 현재값으로부터 멀리 떨어진 new sample이 proposed되었기 때문이다.
  - 그렇다고 sigma가 클수록 좋다는 것은 아니다. sigma가 충분히 큰 덕분에 빠르게 수렴했지만, sigma가 너무 크면 target density가 낮은 위치에서 sample이 생성될 확률이 높아지기 때문에 acceptance rate가 낮아지고 sampling에 시간이 지나치게 오래 걸린다.