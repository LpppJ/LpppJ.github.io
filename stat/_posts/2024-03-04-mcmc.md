---
layout: post
related_posts:
  _
title: 
description: >
sitemap:
    changefreq: daily
    priority: 1.0
hide_last_modified: true
---

# 

## 1. Probabilistic ML Model
- $$x$$ : set of observed variables \
  $$y$$ : set of hidden / latent variables \
  $$\theta$$ : model parameters
- Discriminative probabilistic ML model
  - $$p(Y \mid X)$$ : 데이터 $$X$$가 주어졌을 때 결과 $$y$$ 예측하기 (Classification, Regression, ...)
- Generative probabilistic ML model

  - Bayes Theorem : $$p(Y \mid X)=\frac{p(X, Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{\int p(X \mid Y) p(Y) d Y}$$
  ![그림1](/assets/img/stat/vi/fig1.png)
- Discriminative model은 클래스(y) 사이의 차이를 의미하는 decision boundary를 학습하고, ($$p(Y\mid X)$$)
  Generative model은 분포 $$p(X), p(X,Y)$$를 학습하여 posterior $$p(Y\mid X)$$를 추정한다.
- $$Y$$의 차원이 높아질수록 분모에 있는 $$Y$$에 대한 적분이 어려워지기 때문에(intractable), 아래 두 가지 방법으로 $$p(Y\mid X)$$를 추정한다.
  - Variational Inference (optimization)
  - Markov chain Monte Carlo (sampling)
  - MCMC는 분포를 근사하기 위해 sampling으로 inference하는 것이고, VI는 분포를 근사하기 위해 optimization 문제로 바꾼 것이다.
  - 일반적으로 VI는 빠르고, MCMC는 정확하다.(상대적으로 그렇다는 것)