---
layout: post
related_posts:
  _
title: 
description: >
  [ICLR 2024](https://arxiv.org/abs/2312.16424)
sitemap:
    changefreq: daily
    priority: 1.0
hide_last_modified: true
---

# (SoftCLT) Soft Contrastive Learning for Time Series

## Abstract
  


- 하나의 batch에는 N개의 TS : $$\mathcal{X}=\left\{x_1, \ldots, x_N\right\}$$가 있고
  - $$f_\theta = x_i \in \mathbb{R}^{T \times D} \to r_i=\left[r_{i, 1}, \ldots, r_{i, T}\right]^{\top} \in \mathbb{R}^{T \times M}$$를 학습
  - $$D$$는 input feature dim, $$M$$은 embedded feature dim

- Q1) Soft assignment for a pair of data indice $$(i, i')$$
  - $$w_I\left(i, i^{\prime}\right)=2 \alpha \cdot \sigma\left(-\tau_I \cdot D\left(x_i, x_{i^{\prime}}\right)\right)$$로 정의되는데,
  - $$(i, i')$$에서 $$i$$와 $$i'$$는 $$x$$의 index이니까 서로 다른 시계열이고, 그러므로 $$(i, j), i \ne j$$로 생각해도 되는지 ?
  - 아니면 $$x_{i'}$$가 $$x_i$$로부터 파생된거라던가 그러한 $$x_i$$와 $$x_{i'}$$의 관계가 있어서 의도적으로 $$j, i \ne j$$가 아닌 $$i'$$로 표기한건지... (밑에 식(2)에서 분모에 $$j$$라는 index를 써서인가 싶기도 하고)
- Q2) $$r_{i, t}=r_{i+2 N, t} \text { and } \tilde{r}_{i, t}=r_{i+N, t}$$가 the embedding vectors from two augmentations of $$x_i$$ at timestamp t for conciseness라고 나오는데,
  - $$r_{i, t} = r_{i+2N, t}$$에서 $$r$$의 아래 첨자 중 왼쪽(i파트)가 배치 내에서 시계열의 index이라면 $$i=1,...,N$$인데 $$r_{i+2N, t}$$가 무엇을 의미하는지 ?
  - $$r$$의 아래 첨자 중 왼쪽(i파트)가 다른데... "from two augmentations of $$x_i$$"가 무슨 의미인지 ...