---
layout: post
related_posts:
  _
title: 
description: >
  [Arxiv 2023](https://arxiv.org/pdf/2306.10125.pdf)
sitemap:
    changefreq: daily
    priority: 1.0
hide_last_modified: true
---

# (Survey paper) Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects (Arxiv 2023)

## Abstract

- Self-supervised learning (SSL) : for reducing the dependence of labeled data
- will review SOTA SSL for TS
- will provide taxonomy of SSL for TS : generative-based, contrastive-based, adversarial-based
  - intuitions, main frameworks, (dis)advantages

## 1. Introduction
- To extract useful and informative features, (=hidden patterns and features of the data)
  - SSL utilizes pretext tasks to derive supervision signals from unlabeled data (=creating valuable representation for downstream tasks)
- Challenges:
  - 대부분의 pre-text tasks(이미지, 언어, ...) designed 모델들은 TS의 unique properties(seasonality, trend, frequency, ...)를 고려하기 위한 것이 아니다.
  - SSL을 위해 data augmentation할 때 rotation이나 crop과 같은 방식은 TS의 temporal dependency를 학습하기 어렵게 만든다.
  - MTS에서 몇몇의 dimension(=channel, variate)에만 유용한 정보가 있는 경우에는 이를 고려해야 한다.
- SSL for TS:
  - Generative-based : autoregressive-based forecasting / auto-encoder-based reconstruction / diffusion-based generation
  - Contrastive-based : sampling contrast / prediction contrast / augmentation contrast / prototype contrast / expert knowledge contrast
  - Adversarial-based : generation and imputation and auxiliary representation enhancement
![사진1](/assets/img/timeseries/SSL4TS/fig1.png)
![사진5](/assets/img/timeseries/SSL4TS/fig5.png)

## 2. Related Surveys

### 2.1. Definition of time series data
- Univariate TS : $$X=\left(x_0, x_1, x_2, ..., x_t\right)$$ where $$x_i$$ is  the point at timestamp $$i$$​
- Multivariate TS : $$\mathbf{X}=\left[X_0, X_1, X_2, ..., X_p\right]$$, where $$p$$ is the number of variables
- Multiple multivariate TS : $$\mathcal{X}=\left\{\mathbf{X}_0, \mathbf{X}_1, \mathbf{X}_2, ..., \mathbf{X}_n\right\}$$, where $$n$$ is the number of multivariate TS

### 2.2. Surveys on SSL
- pretext tasks 의 핵심은 pseudo-supervision signals을 만드는 것
- Basic intuition : pull positive samples closer and push negative samples away
  - positive and negative samples : multisensory signals / data augmentation(noise injection, ...) / local-global consistency / temporal consistency
  - pretext task : Context prediction / Instance discrimination / Instance generation
  - model architecture
  - training loss : contrastive loss functions generally include scoring functions (cosine similarity), energy-based margin functions (pair loss and triplet loss), probabilistic NCE-based functions, and mutual information based functions

![사진7](/assets/img/timeseries/SSL4TS/table3.png)

## 3. Generative-based Models
- pretext task : to generate the expected data based on a given view of the data
![사진2](/assets/img/timeseries/SSL4TS/fig2.png)

### 3.1. Autoregressive-based forecasting
- Forecasting : $$\hat{x}_{[t+1: t+K]}=f\left(x_{[1: t]}\right)$$
- Loss : $$\mathcal{L}=\frac{1}{K} \sum_{k=1}^K\left(\hat{x}_{[t+k]}-x_{[t+k]}\right)^2$$​
- RNN-based
  - Adv : Long-term dependencies / Adaptable to varying lengths / Global context information extraction
  - Dis-adv : Vanishing or exploding gradients / Computational efficiency
  - ex : [THOC](https://proceedings.neurips.cc/paper/2020/file/97e401a02082021fd24957f852e0e475-Paper.pdf) : Temporal Self-supervision(TSS), which takes the L-layer dilated RNN with skip-connection structure $$\to$$​ different resolutions at the same time
- CNN-based
  - Adv : Local pattern extraction / Computational efficiency
  - Dis-adv : Long-termdependencies / Information loss
- GNN-based
  - Adv : Adaptability to graph structures / Dynamic relationship capture
  - Dis-adv : Computational and storage complexity 
  - ex : [GDN](https://arxiv.org/pdf/2106.06947.pdf) : the correlation among variables

### 3.2. Autoencoder-based reconstruction
- basic autoencoder (BAE)
  - Encoder $$x \to z$$ , Decoder $$z \to \hat {x}$$  / Loss : $$\mathcal{L}=\|x-\tilde{x}\|_2$$
  - E(), D() 같이 train, D() 제거하고 E()를 feature extractor로 사용
  - ex. [TimeNet](https://arxiv.org/pdf/1706.08838.pdf), [PT-LSTM-SAE](https://www.nature.com/articles/s41598-019-55320-6), [Autowarp](https://arxiv.org/pdf/1810.10107.pdf)
- Denoising autoencoder (DAE)
  - $$x_n=\mathcal{T}(x), \quad Z=E\left(x_n\right), \quad \tilde{x}=D(z)$$, $$\quad \mathcal{T}$$: add noise  / Loss : $$\mathcal{L}=\|x-\tilde{x}\|_2$$
- Mask autoencoder (MAE)
  - Intuition : pre-training할 때에 input의 일부를 mask하고 un-mask part 보고 예측
  - form : $$\begin{gathered}x_m=\mathcal{M}(x), \quad z=E\left(x_m\right), \quad \tilde{x}=D(z),\ \mathcal{L}=\mathcal{M}\left(\|x-\tilde{x}\|_2\right),\end{gathered}$$
  - TS에서는 time-step-wise masking은 interpolation 해버리기 때문에, segment-wise masking or variable-wise masking
  - ex. [TARNet](https://dl.acm.org/doi/pdf/10.1145/3534678.3539329) : 중요한 역할을 하는 data를 선정하고, 해당 데이터를 masking 하여 reconstruction
- Variational autoencoder (VAE)
  - Encoder $$x \to P(z\mid x)$$, instead of explicit representation $$z$$, Decoder는 sampling from $$P(z \mid x)$$​
  - $$P(z \mid x)=E(x), \quad z=\mathcal{S}(P(z \mid x)), \quad \tilde{x}=D(z)$$ / Loss : $$\mathcal{L}=\|x-\tilde{x}\|_2+\operatorname{KL}(\mathcal{N}(\mu, \delta), \mathcal{N}(0, I))$$
  - ex. [InterFusion](https://dl.acm.org/doi/10.1145/3447548.3467075), [mTANs](https://arxiv.org/pdf/2101.10318.pdf), [HetVAE](https://arxiv.org/pdf/2107.11350.pdf)(extract seasonal and trend via VAE) 

### 3.3. Diffusion-based generation
- reverse transition kernel을 NN으로 approximate
- Denoising diffusion probabilistic models [DDPM](https://arxiv.org/pdf/2006.11239.pdf),  
  - $$p_\theta\left(\boldsymbol{x}_{\boldsymbol{t}-\mathbf{1}} \mid \boldsymbol{x}_{\boldsymbol{t}}\right)=$ $\mathcal{N}\left(\boldsymbol{x}_{t-1} ; \mu_\theta\left(\boldsymbol{x}_t, t\right), \sum_\theta\left(\boldsymbol{x}_t, t\right)\right)$$ 일 때,
  - Jensen's inequality에 의해, training loss는 $$\begin{array}{r}\mathbf{K L}\left(q\left(\boldsymbol{x}_1, \boldsymbol{x}_2, ..., \boldsymbol{x}_T\right) \| p_\theta\left(\boldsymbol{x}_0, \boldsymbol{x}_1, ..., \boldsymbol{x}_T\right)\right) \geq \mathbf{E}\left[-\log p_\theta\left(\boldsymbol{x}_0\right)\right]+\text { const. }\end{array}$$
- Score matching diffusion models [score matching](https://arxiv.org/pdf/1907.05600.pdf)
  -  per- turb data with a sequence of Gaussian noise $$\to$$ estimating the score function for all the noisy data

## 4. Contrastive-based Methods
- positive는 가깝게, negative는 멀게 representation하도록 학습 $$\to$$ positive / negative 정하는 룰이 중요함
![사진3](/assets/img/timeseries/SSL4TS/fig3.png)
- **Sampling contrast**
  - 가정 : 시점이 가까울수록 유사도가 높을 것
  - 하지만 실제로 꼭 그런 것은 아니다. contextual information으로 pos / neg 정하기가 쉽지 않다
  - ex. [TNC](https://arxiv.org/pdf/2106.00750.pdf) : augmented Dickey-Fuller (ADF) statistical test 해서 neg samples를 unknown으로 취급, weights 할당, [Supervised contrastive learning](https://arxiv.org/pdf/2004.11362.pdf)
- **Prediction contrast**
  - maximally preserve the mutual information of the context and the target
  - Ex. [Contrastive predictive coding (CPC)](https://arxiv.org/pdf/1807.03748.pdf) : Context와 target의 mutual information을 최대한 유지한 채로 prediction
  - variants : [LNT](https://arxiv.org/pdf/2202.03944.pdf), [TS-TCC](https://arxiv.org/pdf/2106.14112.pdf) [CA-TCC](https://arxiv.org/pdf/2208.06616.pdf) (TS data augmentation techniques)
- **Augmentation contrast**
  - different views of an input sample 생성 (같은 sample의 view끼리는 positive) $$\to$$ similarity [SimCLR](https://arxiv.org/pdf/2002.05709.pdf) 
  - variants : [TS2Vec](https://arxiv.org/pdf/2106.10466.pdf) (week augmentation e.g. jitter-and-scale), [CoST](https://arxiv.org/pdf/2202.01575.pdf), [TF-C](https://arxiv.org/pdf/2206.08496.pdf) (frequency domain), [DCdetector](https://arxiv.org/pdf/2306.10347.pdf), [TimeCLR](https://pdf.sciencedirectassets.com/271505/1-s2.0-S0950705122X00075/1-s2.0-S0950705122002726/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEHAaCXVzLWVhc3QtMSJIMEYCIQDgmFUeLriQDh4DVodXqV0y990PZCUCjyqFZw5tbaaWOQIhAJJXI3FfJlWxRX7ERxHJD52xqRrpOHF7bO5s8CcvR%2BObKrwFCIn%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBRoMMDU5MDAzNTQ2ODY1Igz9LqUqaUEhwALsmIAqkAVKSauBGYOJAgLt97GY2VGTuMQnRA7AgMmTvZNbQR13nb0eSyB3AddrtMNpzfTApqlafitG63sIURfGc04jk0%2BqiLp73hS3BmM6J9f3LNclZKHKiIQ%2BfUjQppBf9%2BSzb2GYgwcFIWgWQCR5PtN2siu0UfPOBUAUFniH5sww3WHYgzisgA4woX%2F%2B1lpEeSZAfoqOLu%2BD70QDpxoC0KgT%2FXhLrNhBehAy%2FZqTdVfSNmO8PnYW%2BbOc6HJ8zuTY5RATpiy9V7EMrdnYFYXvqu%2F1qW2x%2FtdeEZ0RfWCu524fQvnPpB8zVmySXJH4TXT4LA7QJE%2B1QwAHRqUatsaSoMpckzyqhP4LGwWneO%2Fq9RiEEqDkaOCpaL5F%2F%2B5i1tibhhFGI9ACzd814laQtq%2BIcvidp9986C1DHHJjTFHEXHUgMObbcOMXVA8xcpjCf5yFKcLC42BCHss82InfazC%2BJ8X4if%2BIhr7C%2B4MnowAGueEbmt5yQhoYboaD1tk%2FKKIohIhI2hghsk%2Fj%2BwhkWCn5KyLfoONkWJmJW1CXLDORF38jJLFEREaAQr3LRwExugVvijVdQLlWMyzPoCNRSLI5zkotkTprBsrs6iaJrS7hLn3mxOjCh9mZyJI2yV6%2Brr7jzg5XQ6VHiYlrkcfYuw9OFK5jv5OsoGoi4E46toRGV7X2p9jKlrg7T4m61BP5khSxzLJq61nOGlO%2Bx3zUvUT3dMyvkGMkKtaSk1%2FKXT4RovxkHp%2Bmpc3QUR7j6hzf5z0n9IIsv8FzAtzg58kKHg9OBQmHtCehUyLOErVo7P9Qxj5SIP7umI%2F%2Fe9p%2BK%2BGGZKNKv4LyjUqeB7XdlwPp2x2ysLv4d4o%2BIPtvkyjLqxhNu6sOYmb6VjCX1oSwBjqwAfzu66rFmDL30GLaRAVAW1ntG5mkCnwKEF3lFukhkQUOfwCxm7RM9jOJeG4%2Bmi3EJkTk7YzUpDz3XnUhEC9%2BvejsHkC1qETTJrb0bcqMFFW3EaZrZZYvZ4zodutAKA%2BUzMn5Df82EqEjSmeySV18YkkkKDNTM0usR%2FHaNfviRepwNslRryoSwTWiPWMwiV9tIIbZaIFpcs6nZlQB%2BGqMP1tw1rZAozE5PSe1E%2Btz1kLS&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240325T090224Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYQXRPBKFN%2F20240325%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=2f8baa651eec4fdd10cde55f49d1477a95f8710aa9c8758546ef1df59d330c78&hash=4538839e76c3c485eb651626f2c825dd66a6195b3060bbed9553996335a29682&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0950705122002726&tid=spdf-baf2cd37-88cd-4f95-a9ab-f50f1a42eb98&sid=fc89350759b08043e82bbad-52465f639e79gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0f11585559020c5807&rr=869db8c7e9f3a7c3&cc=kr) 
- **Prototype contrast**
  - minimize the distance btw samples and prototype(=virtual sequences, centor, ...)
    but maximize the distance btw prototype(=virtual sequences, centor, ...)
- **Expert knowledge contrast**
  - incorporates expert prior knowledge or information into deep neural networks to guide model training

## 5. Adversarial-based Methods
- pre-text tasks를 GAN으로 푼다. (generator $$\mathcal{G}$$ and a discriminator $$\mathcal{D}$$)
- Learning objective : $$\mathcal{L}=\mathbb{E}_{x \sim \mathcal{P}_{\text {data }}(x)}[\log \mathcal{D}(x)]+\mathbb{E}_{z \sim \mathcal{P}_{\mathbf{z}}(z)}[\log (1-\mathcal{D}(\mathcal{G}(\mathbf{z})))]$$
![사진4](/assets/img/timeseries/SSL4TS/fig4.png)
- **Time series generation and imputation**
  - Complete time series generation : [TimeGAN](https://papers.nips.cc/paper_files/paper/2019/file/c9efe5f26cd17ba6216bbe2a7d26d490-Paper.pdf) (autoregressive GAN), [TTS-GAN](https://arxiv.org/pdf/2202.02691.pdf) (Transformer treating TS as image)
  - time series imputation : pass
- **Auxiliary representation enhancement**
  - pass

## 6. Applications and Datasets
![사진6](/assets/img/timeseries/SSL4TS/table2.png)

## 7. Discussion and Future Directions
### 7.1. **Selection and combination of data augmentation**
- augmentation methods :  jitter, scaling, rotation, permutation, and warping, ...
- permutation + rotation + time warping > single method
### 7.2. **Inductive bias for time series SSL**
- 특히 데이터가 충분하지 않을 수록 합리적인 inductive bias는 필요할 수 있음
### 7.3. **SSL for irregular and sparse time series**=
- Irregular and sparse time series를 interpolation해서 쓰려고 하다보면 undesirable noise가 낄 수도 있으니 그대로 SSL로 활용

##  8. Conclusion
Pass

