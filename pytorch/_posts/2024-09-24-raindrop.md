---
layout: post
related_posts:
  _
title: 
description: >
  [Raindrop github](https://github.com/mims-harvard/Raindrop)
sitemap:
    changefreq: daily
    priority: 1.0
hide_last_modified: true
---

# (Code Review, ICLR 2022) Raindrop

[(Paper) Graph-Guided Network for Irregularly Sampled Multivariate Time Series](https://arxiv.org/abs/2110.05357)

[(Paper Review, ICLR 2022) Raindrop](https://lpppj.github.io/timeseries/2024-02-09-Raindrop)

## 1. Git clone

![사진1](/assets/img/pytorch/raindrop_code/fig1.png)

![사진1](/assets/img/pytorch/raindrop_code/fig2.png)

- 먼저 터미널에 git clone과 requirements를 입력하여 install 한다.
- `python Raindrop.py`로 P19, P12, PAM 데이터셋에 대한 성능을 볼 수 있다.

## 2. Raindrop.py

### 2.1. Data Preparing

![사진1](/assets/img/pytorch/raindrop_code/fig3.png)
![사진1](/assets/img/pytorch/raindrop_code/fig4.png)

- parser를 통해 aurgments를 만들고
- 본 논문에서 제시하는 model은 irregular time series를 다룬다.
  - 그러므로 `missing ratio`, 즉 feature를 masking하는 비율을 미리 결정해준다. (option)
  - 일단은 0(no missing)으로 두고 코드를 이해해보자

![사진1](/assets/img/pytorch/raindrop_code/fig5.png)

- 사전에 정한 `missing ratio`를 사용한다.
- epoch 수와 learning rate도 미리 정한다.

![사진1](/assets/img/pytorch/raindrop_code/fig6.png)

- P19 데이터셋을 사용한다.
  - `d_static`과 `d_inp`는 시간에 따라 변하지 않는(정적) / 변하는(동적) 변수의 개수
  - `static_info`는 `d_static` 변수가 있는지 없는지 (bool)
  - `max_len`은, batch 내 샘플마다 시계열의 길이가 다른데 최대 길이
    - 만약 `max_len`보다 짧다면 그 부분은 다 0으로 기록되어있다.
  - `n_classes`는 샘플에 속하는 class의 개수
- 다른 데이터셋을 사용한다면 위의 변수들은 달라질 수 있다.

- `d_ob`는 각 변수를 몇 차원으로 표현할지를 의미한다.
- 그래서 `d_model`은 동적 변수의 개수인 `d_inp`에 `d_ob`를 곱한 값이 된다.
- `nhid`는 FFN의 dimension인데 `d_model`의 2배를 사용
- `nlayers`는 layer의 개수, `nhead`는 MHA(multi-head attention)에서 heads 개수이고 모두 2개를 사용
- `dropout`은 TransformerEncoderLayer에서 사용하는 dropout ratio
- `aggreg`는 나중에 각 배치마다, 각 시점을 vector로 표현할텐데 그걸 모든 시점에 대해 합칠 때 **평균**을 사용
- `MAX`는 positional encoder에 들어가는 MAX parameter인데
  - 막상 positional encoder 코드를 보면 `MAX`라는 변수를 사용하지 않으니 신경 안써도 된다.

![사진1](/assets/img/pytorch/raindrop_code/fig7.png)

- `n_run`은 데이터셋에 대해 몇 번을 실험해서 기록할지를 의미한다.
- `n_splits`는 데이터가 5등분 되어있어서 5를 사용한다.
- 그리고 본 model을 평가하기 위한 성능 지표를 기록할 arrays를 만들어놓는다.

![사진1](/assets/img/pytorch/raindrop_code/fig8.png)

- 그리고 불러온 데이터셋을 train(0.8) / valid(0.1) / test(0.1)로 나누고 label(y)도 따로 준비한다.
- P19 데이터셋의 경우 train에는 31042개의 샘플이 있다. (샘플은 한 명의 환자 정도로 생각할 수 있다.)
  - 그리고 각 샘플은 `torch.size([# of timesetps,  # of features])`인 tensor이다.

![사진1](/assets/img/pytorch/raindrop_code/fig9.png)

- T는 time steps의 수, F는 (동적) 변수의 개수이고, D는 (정적) 변수의 개수가 된다.
  - 동적 변수는 `Ptrain`의 `arr`에, 정적 변수는 `Ptrain`의 `extended_static`에 따로 준비하고 있다.
- 그리고 normalization을 위해 모든 변수들의 평균과 표준편차를 얻는다.
  - `getStats` 함수에는 사용하는데 특이사항 없으므로 skip

![사진1](/assets/img/pytorch/raindrop_code/fig10.png)

- 각각의 shape은 아래와 같다.
- `Ptrain`의 동적 변수들의 개수가 34개였는데 68이 된 이유는 :
  - 같은 크기의 Mask를 옆에 이어붙였기 때문이다.
  - Mask는 `M = 1*(input_tensor > 0) + 0*(input_tensor <= 0)`이다.
- `Ptrain_time`은 31042개의 텐서인데, 각 tensor는 해당 샘플의 길이를 알려준다.
  - 즉 만약 0번째 샘플의 길이가 40이라면, 0번째 tensor는`[1, 2, ..., 40, 0, 0, ...]`이다.
  - 일단 숫자는 `max_len`개인데 해당 샘플의 길이까지만 index를 기록하고 뒷부분은 zero padding
- `y_train`은 각 샘플의 정답 label이다.

![사진1](/assets/img/pytorch/raindrop_code/fig11.png)

- 이제 `global_structure`를 정의하는데, 각각의 동적 변수가 상호작용하는지를 0, 1로 표현
  - adjacency matrix의 역할을 한다.
- `missing_ratio`가 존재했다면 몇몇 feature를 masking한다.
  - `feature_removal_level`이 `sample`이면 각 샘플(환자)마다 독립적으로 특성을 무작위 제거
  - `feature_removal_level`이 `set`이면 미리 계산된 density scores를 사용하여 제거할 특성을 결정하고 모든 샘플에서 제거

![사진1](/assets/img/pytorch/raindrop_code/fig12.png)

- `Ptrain`의 shape을 `torch.size([# of timesteps,  batch_size,  # of features(w/masking)])`으로,
- `Ptrain_time`의 shape을 `torch.size([# of timesteps, batch_size])`로 setting

![사진1](/assets/img/pytorch/raindrop_code/fig13.png)

- 앞서 소개한 parameters를 한 번 출력해보았다.
- 지금은 masking ratio가 0이다.

![사진1](/assets/img/pytorch/raindrop_code/fig14.png)

- parameters의 descriptions는 위와 같다.

### 2.2. Model setting

![사진1](/assets/img/pytorch/raindrop_code/fig15.png)

- 이제 model, criterion, optimiazer, scheduler를 정의한다.
- model은 2d tensor로 표현된 샘플마다 classification하도록 설계되었으므로 CrossEntropyLoss를 사용
- 아직 input을 model에 넣은 건 아님.
  - input이 model에 들어가면 어떤 과정을 거치는지는 아래 3. `models_rd.py`에서 보도록 한다.

![사진1](/assets/img/pytorch/raindrop_code/fig16.png)

- `idx_0`은 `y`가 0인 samples의 index, `idx_1`은 반대
- label이 1인 샘플의 개수가 적은 unbalancing 문제를 해결하기 위해 3배로 늘림 (왜 **3**배인지는 모름)
- batch_size가 128인데 label이 0과 1인 samples를 절반씩 채울테니
  - n_batches는 개수가 더 적은 label 기준으로 모든 samples를 한 번씩 다 볼 수 있도록 설정했다.
  - 사실 label이 1인 samples를 3배 했으니 label이 1인 샘플을 3번씩 보는 꼴이다.

![사진1](/assets/img/pytorch/raindrop_code/fig17.png)

![사진1](/assets/img/pytorch/raindrop_code/fig18.png)

- 이제 epoch를 시작하는데, label이 0인 샘플과 1인 샘플에서 무작위로 `batch_size/2`개씩 가져온다.
- 사실 label이 1인 samples를 3배 했으니 여기서는 중복된 샘플이 나올 가능성이 있다.
- model에 들어갈 input tensors의 shape을 미리 확인해두자

![사진1](/assets/img/pytorch/raindrop_code/fig19.png)

- 이제 model에 들어가고 통상적인 backpropagation을 거친다.
- model에 들어가면 어떤 일이 일어나는지 알아보자.

## 3. models_rd.py

### 3.1. __init__

- `__init__`이 상당히 많지만 지금 다 알 필요는 없다.
- `forward`에서 사용할 때 다시 올라와서 보면 될 듯

![사진1](/assets/img/pytorch/raindrop_code/fig20.png)

![사진1](/assets/img/pytorch/raindrop_code/fig21.png)

![사진1](/assets/img/pytorch/raindrop_code/fig22.png)

## 3.2. forward

![사진1](/assets/img/pytorch/raindrop_code/fig23.png)

- P19 데이터셋의 경우 input shape은 주황색 주석과 같다.
- src로 들어오는 P의 경우 34개의 변수였는데 같은 크기의 Mask를 옆에 이어붙인 것이니 다시 분리
  - 각각을 missing_mask, src라고 부름
- 그 다음 34개의 변수를 `d_ob`(여기선 4)번 반복해서 src의 representation capacity를 키워주고
  - ReLu를 통과시켜서 non-linearity를 표현할 수 있게 한다.
  - 그 다음 dropout을 거친다.
- 결국 `h`는 src를 확장시키고 learnable weights와 ReLu를 곱해 모델이 학습할 수 있는 형태로 만든 것

![사진1](/assets/img/pytorch/raindrop_code/fig24.png)

- 이제 batch에 있는 각 sample마다 mask를 만든다.
- sample에 값이 있으면 mask에는 False가 되고 값이 없으면 mask가 True가 된다.
- mask의 길이는 60으로 고정이지만 sample마다 길이가 다르기 때문에 어디까지 False이고 언제부터 True인지는 sample마다 다르다.

![사진1](/assets/img/pytorch/raindrop_code/fig25.png)

- 다음으로 `global_structure`를 adjacency matrix로 사용한다.
  - shape은 동적 변수의 개수 `d_inp` x `d_inp`가 되므로 각 동적 변수를 연결 여부를 (0,1)로 표현한다.
  - epoch가 진행되면서 바뀔 수도 있으니 대각성분은 항상 1로 update해준다.
- 그 다음 edge_index와 edge_weights를 미리 구해놓는다.
  - 연결된 nodes의 index와 그 weights를 의미함

- 그 다음 batch에 있는 각 sample마다 (동적) 변수들의 global structure(edge)를 고려한 representation을 저장할 공간 `output`을 미리 만들어놓는다.
  - 각 sample마다 `torch([# of time steps,  d_inp x d_ob])` shape의 tensor가 들어갈 예정이다.

![사진1](/assets/img/pytorch/raindrop_code/fig26.png)

- 이제 아까 만든 `h`를 `x`로 받아서 (`x=h`) 하나의 sample에 대한 `h`를 `stepdata` 가져온다
- `p_t`는 각 timestep을 `d_pe = 16`차원 vector로 embedding한 것이다. (init 참고)
- 이제 `stepdata`를 `torch([# of features,  (# of time steps)x(d_ob)])`로 reshape한다.
  - 왜냐하면 feature끼리 attention을 수행하기 때문에 각 feature를 하나의 vector로 만들 필요가 있기 때문
- 이제 각 feature를 vector로 만든 걸 `ob_propagation`으로 정의된 attention layer에 넣는다.
  - 그러면 같은 shape `torch([# of features,  (# of time steps)x(d_ob)])` tensor가 return되지만
  - 해당 sample의 각각의 features를 Observation Propagation을 거쳐 representation한 결과이다.
  - `Ob_propagation.py`에 있고, 코드를 따로 첨부하지는 않겠으나 아래와 같은 과정을 거친다.
    - 1) Message Passing: node 간에 정보를 전달하는 mechanism 구현
    - 2) Attention Mechanism: 각 node가 이웃 node로부터 받는 메시지의 중요도를 학습
    - 3) Egde weights: graph의 edge에 weight를 적용하여 정보 전달의 강도를 조절
    - 4) Edge prune: 중요도가 낮은 edge를 제거하여 computation efficiency 높임
    - 5) Feature Transform: linear Transform과 activation ftn으로 node의 feature를 변환
    - 6) Aggregation: 이웃 node로부터 받은 메시지를 합침

![사진1](/assets/img/pytorch/raindrop_code/fig27.png)

- `ob_propagation-layer`를 한 번 더 통과시키고 shape을 맞춰서 `output`의 sample index 자리에 넣는다.
  - 그리고 alpha_all에는 그 attention weights를 넣는다.
    - 34개의 features끼리의 attention이니 34$$\times$$34$$=$$1156개의 숫자가 된다.
- 모든 samples에 대해서 완료하여 `output`이 완성되면 distance를 구한다.

![사진1](/assets/img/pytorch/raindrop_code/fig28.png)

- 다음으로 time embedding을 concat한다.
- 이러면 shape이 `torch.size([60, 128, 152])`가 되는데, 각 sample마다(128), 하나의 시점을 152차원 vector로 표현한 것이다.
  - 이 152는 (동적) 변수 34개를 34$$\times$$4 = 136차원으로 표현하고, time embedding 16차원을 붙인 것

![사진1](/assets/img/pytorch/raindrop_code/fig29.png)

- 이걸 transformer encoder에 통과시키고

![사진1](/assets/img/pytorch/raindrop_code/fig30.png)

- aggregate 하는데, 이 때 모든 시점에 대해 평균을 내준다. (`aggreg == mean`)
- 그러면 각 sample은 모든 시점과 모든 변수를 통합하여 152차원 벡터로 표현된 결과가 나온다.

![사진1](/assets/img/pytorch/raindrop_code/fig31.png)

- 마지막으로 (정적) 변수를 embedding한 emb를 붙여서 2-layer MLP에 넣으면
- 각 sample에 대한 classification이 완료된다.

![사진1](/assets/img/pytorch/raindrop_code/fig32.png)

- Training에 따른 validation set acccuracy가 출력된다.

![사진1](/assets/img/pytorch/raindrop_code/fig33.png)

- 그리고 classification report가 출력된다.

끝 !

- 참고로 나의 경우에는 `from torch_scatter import gather_csr, scatter, segment_csr`가 안되어서 아래와 같이 주석 처리하고
  - pytorch를 보고 함수를 직접 작성하여 사용하였다.
  - [pytorch_scatter 참고](https://github.com/rusty1s/pytorch_scatter/blob/master/torch_scatter/scatter.py)

~~~python
# from torch_scatter import gather_csr, scatter, segment_csr
from typing import Optional, Tuple
def broadcast(src: torch.Tensor, other: torch.Tensor, dim: int):
    if dim < 0:
        dim = other.dim() + dim
    if src.dim() == 1:
        for _ in range(0, dim):
            src = src.unsqueeze(0)
    for _ in range(src.dim(), other.dim()):
        src = src.unsqueeze(-1)
    src = src.expand(other.size())
    return src

def scatter_sum(src: torch.Tensor, index: torch.Tensor, dim: int = -1,
                out: Optional[torch.Tensor] = None,
                dim_size: Optional[int] = None) -> torch.Tensor:
    index = broadcast(index, src, dim)
    if out is None:
        size = list(src.size())
        if dim_size is not None:
            size[dim] = dim_size
        elif index.numel() == 0:
            size[dim] = 0
        else:
            size[dim] = int(index.max()) + 1
        out = torch.zeros(size, dtype=src.dtype, device=src.device)
        return out.scatter_add_(dim, index, src)
    else:
        return out.scatter_add_(dim, index, src)


def scatter_add(src: torch.Tensor, index: torch.Tensor, dim: int = -1,
                out: Optional[torch.Tensor] = None,
                dim_size: Optional[int] = None) -> torch.Tensor:
    return scatter_sum(src, index, dim, out, dim_size)


def scatter_mul(src: torch.Tensor, index: torch.Tensor, dim: int = -1,
                out: Optional[torch.Tensor] = None,
                dim_size: Optional[int] = None) -> torch.Tensor:
    return torch.ops.torch_scatter.scatter_mul(src, index, dim, out, dim_size)


def scatter_mean(src: torch.Tensor, index: torch.Tensor, dim: int = -1,
                 out: Optional[torch.Tensor] = None,
                 dim_size: Optional[int] = None) -> torch.Tensor:
    out = scatter_sum(src, index, dim, out, dim_size)
    dim_size = out.size(dim)

    index_dim = dim
    if index_dim < 0:
        index_dim = index_dim + src.dim()
    if index.dim() <= index_dim:
        index_dim = index.dim() - 1

    ones = torch.ones(index.size(), dtype=src.dtype, device=src.device)
    count = scatter_sum(ones, index, index_dim, None, dim_size)
    count[count < 1] = 1
    count = broadcast(count, out, dim)
    if out.is_floating_point():
        out.true_divide_(count)
    else:
        out.div_(count, rounding_mode='floor')
    return out


def scatter_min(
        src: torch.Tensor, index: torch.Tensor, dim: int = -1,
        out: Optional[torch.Tensor] = None,
        dim_size: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]:
    return torch.ops.torch_scatter.scatter_min(src, index, dim, out, dim_size)


def scatter_max(
        src: torch.Tensor, index: torch.Tensor, dim: int = -1,
        out: Optional[torch.Tensor] = None,
        dim_size: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]:
    return torch.ops.torch_scatter.scatter_max(src, index, dim, out, dim_size)


def scatter(src: torch.Tensor, index: torch.Tensor, dim: int = -1,
            out: Optional[torch.Tensor] = None, dim_size: Optional[int] = None,
            reduce: str = "sum") -> torch.Tensor:
    r"""
    |

    .. image:: https://raw.githubusercontent.com/rusty1s/pytorch_scatter/
            master/docs/source/_figures/add.svg?sanitize=true
        :align: center
        :width: 400px

    |

    Reduces all values from the :attr:`src` tensor into :attr:`out` at the
    indices specified in the :attr:`index` tensor along a given axis
    :attr:`dim`.
    For each value in :attr:`src`, its output index is specified by its index
    in :attr:`src` for dimensions outside of :attr:`dim` and by the
    corresponding value in :attr:`index` for dimension :attr:`dim`.
    The applied reduction is defined via the :attr:`reduce` argument.

    Formally, if :attr:`src` and :attr:`index` are :math:`n`-dimensional
    tensors with size :math:`(x_0, ..., x_{i-1}, x_i, x_{i+1}, ..., x_{n-1})`
    and :attr:`dim` = `i`, then :attr:`out` must be an :math:`n`-dimensional
    tensor with size :math:`(x_0, ..., x_{i-1}, y, x_{i+1}, ..., x_{n-1})`.
    Moreover, the values of :attr:`index` must be between :math:`0` and
    :math:`y - 1`, although no specific ordering of indices is required.
    The :attr:`index` tensor supports broadcasting in case its dimensions do
    not match with :attr:`src`.

    For one-dimensional tensors with :obj:`reduce="sum"`, the operation
    computes

    .. math::
        \mathrm{out}_i = \mathrm{out}_i + \sum_j~\mathrm{src}_j

    where :math:`\sum_j` is over :math:`j` such that
    :math:`\mathrm{index}_j = i`.

    .. note::

        This operation is implemented via atomic operations on the GPU and is
        therefore **non-deterministic** since the order of parallel operations
        to the same value is undetermined.
        For floating-point variables, this results in a source of variance in
        the result.

    :param src: The source tensor.
    :param index: The indices of elements to scatter.
    :param dim: The axis along which to index. (default: :obj:`-1`)
    :param out: The destination tensor.
    :param dim_size: If :attr:`out` is not given, automatically create output
        with size :attr:`dim_size` at dimension :attr:`dim`.
        If :attr:`dim_size` is not given, a minimal sized output tensor
        according to :obj:`index.max() + 1` is returned.
    :param reduce: The reduce operation (:obj:`"sum"`, :obj:`"mul"`,
        :obj:`"mean"`, :obj:`"min"` or :obj:`"max"`). (default: :obj:`"sum"`)

    :rtype: :class:`Tensor`

    .. code-block:: python

        from torch_scatter import scatter

        src = torch.randn(10, 6, 64)
        index = torch.tensor([0, 1, 0, 1, 2, 1])

        # Broadcasting in the first and last dim.
        out = scatter(src, index, dim=1, reduce="sum")

        print(out.size())

    .. code-block::

        torch.Size([10, 3, 64])
    """
    if reduce == 'sum' or reduce == 'add':
        return scatter_sum(src, index, dim, out, dim_size)
    if reduce == 'mul':
        return scatter_mul(src, index, dim, out, dim_size)
    elif reduce == 'mean':
        return scatter_mean(src, index, dim, out, dim_size)
    elif reduce == 'min':
        return scatter_min(src, index, dim, out, dim_size)[0]
    elif reduce == 'max':
        return scatter_max(src, index, dim, out, dim_size)[0]
    else:
        raise ValueError

~~~