<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-03-19T13:04:31+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">LpppJ</title><subtitle>This is blog about machine learning, deep learning, artificial intelligence.
</subtitle><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><entry><title type="html">(Survey paper) Time Series Forecasting With Deep Learning A Survey (Philos Trans R Soc A. 2020)</title><link href="http://localhost:4000/timeseries/2024-03-19-TSwDLsurvey/" rel="alternate" type="text/html" title="(Survey paper) Time Series Forecasting With Deep Learning A Survey (Philos Trans R Soc A. 2020)" /><published>2024-03-19T00:00:00+09:00</published><updated>2024-03-19T13:04:28+09:00</updated><id>http://localhost:4000/timeseries/TSwDLsurvey</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-03-19-TSwDLsurvey/"><![CDATA[<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>Time series forecasting
    <ul>
      <li>traditional methods : parametric models informed by domain expertise (ex. autoregressive(AR))</li>
      <li>machine learning : learn temporal dynamics in a puerly data-driven manner</li>
      <li>deep learning : learn complex data representation
        <ul>
          <li>CNN, RNN, Attention-based mechanism</li>
        </ul>
      </li>
      <li>hybrid model : Quantitative TS model + deep learning model</li>
    </ul>
  </li>
  <li>Time series forecasting의 application
    <ul>
      <li>interpretability and counterfactual prediction</li>
    </ul>
  </li>
</ul>

<h2 id="2-deep-learning-architectures-for-tsf">2. Deep Learning Architectures for TSF</h2>
<ul>
  <li>One-step-ahead forecasting : \(\hat{y}_{i, t+1}=f\left(y_{i, t-k: t}, \boldsymbol{x}_{i, t-k: t}, \boldsymbol{s}_i\right)\)
    <ul>
      <li>\(\hat{y}_{i, t+1}\) : model forecast</li>
      <li>\(y_{i, t-k: t}=\left\{y_{i, t-k}, \ldots, y_{i, t}\right\}, \boldsymbol{x}_{i, t-k: t}=\left\{\boldsymbol{x}_{i, t-k}, \ldots, \boldsymbol{x}_{i, t}\right\}\) : observation over look-back window</li>
      <li>\(f(\cdot)\) : the prediction function learntby the model
        <h3 id="2a-basic-building-blocks">2.(a) Basic building blocks</h3>
      </li>
    </ul>
  </li>
  <li>Encoder : \(\boldsymbol{z}_t=g_{\mathrm{enc}}\left(y_{t-k: t}, \boldsymbol{x}_{t-k: t}, \boldsymbol{s}\right)\)</li>
  <li>Decoder : \(f\left(y_{t-k: t}, \boldsymbol{x}_{t-k: t}, \boldsymbol{s}\right)=g_{\mathrm{dec}}\left(\boldsymbol{z}_t\right)\)
    <ul>
      <li>Encoder에서 observations를 latent vector로 representation</li>
      <li>(1) Convolution Neural Networks : \(\begin{aligned} \boldsymbol{h}_t^{l+1} &amp; =A((\boldsymbol{W} * \boldsymbol{h})(l, t)) \\ (\boldsymbol{W} * \boldsymbol{h})(l, t) &amp; =\sum_{\tau=0}^k \boldsymbol{W}(l, \tau) \boldsymbol{h}_{t-\tau}^l \end{aligned}\)
        <ul>
          <li>Convolution과 pooling을 반복하는 구조. TS에서는 과거의 값만 보도록 설계</li>
          <li>\(\boldsymbol{h}_t^l \in \mathbb{R}^{\mathcal{H}_{i n}}\) : intermediate state at layer \(l\) at time \(t\)</li>
          <li>
            <p>\(*\) : convolution operator</p>
          </li>
          <li>\(\boldsymbol{W}(l, \tau) \in$ $\mathbb{R}^{\mathcal{H}_{\text {out }} \times \mathcal{H}_{\text {in }}}\) : fixed filter weight at layer \(l\)</li>
          <li>\(A(.)\) : activation function</li>
        </ul>
      </li>
      <li>Dilated Convolution : \((\boldsymbol{W} * \boldsymbol{h})\left(l, t, d_l\right)=\sum_{\tau=0}^{\left\lfloor k / d_l\right\rfloor} \boldsymbol{W}(l, \tau) \boldsymbol{h}_{t-d_l \tau}^l\)
        <ul>
          <li>\(d_l\) : layer-specific dilation rate</li>
          <li>(WaveNet) \(d_l = 2^l\) at layer \(l\) (fig1.(a))
<img src="/assets/img/timeseries/TSwDLsurvey/fig1.png" alt="사진1" /></li>
        </ul>
      </li>
      <li>(2) Recurrent Neural Networks
        <ul>
          <li>Memory state를 통해 과거 정보를 기억하는 sequential data에 적합한 구조</li>
          <li>
            <p>Gradient vanishing으로 인한 long-range dependency \(\to\) LSTM</p>
          </li>
          <li>
            <p>Memory update funciton : \(\boldsymbol{z}_t=\nu\left(\boldsymbol{z}_{t-1}, y_t, \boldsymbol{x}_t, \boldsymbol{s}\right)\)</p>
          </li>
          <li>Network : \(\begin{aligned} y_{t+1} &amp; =\gamma_y\left(\boldsymbol{W}_y \boldsymbol{z}_t+\boldsymbol{b}_y\right) \\ \boldsymbol{z}_t &amp; =\gamma_z\left(\boldsymbol{W}_{z_1} \boldsymbol{z}_{t-1}+\boldsymbol{W}_{z_2} y_t+\boldsymbol{W}_{z_3} \boldsymbol{x}_t+\boldsymbol{W}_{z_4} \boldsymbol{s}+\boldsymbol{b}_z\right) \end{aligned}\)
            <ul>
              <li>\(W_{.}, \boldsymbol{b}\) : the linear weights and bias</li>
              <li>\(\gamma_y(.), \gamma_z(.)\) : network activation functions</li>
            </ul>
          </li>
          <li>Long Short Term Memory(LSTM)
<img src="/assets/img/timeseries/TSwDLsurvey/fig2.png" alt="사진2" /></li>
        </ul>
      </li>
      <li>(3) Attention mechanisms
        <ul>
          <li>form : \(\boldsymbol{h}_t=\sum_{\tau=0}^k \alpha\left(\boldsymbol{\kappa}_t, \boldsymbol{q}_\tau\right) \boldsymbol{v}_{t-\tau}\)
            <ul>
              <li>key \(\boldsymbol{\kappa}_t\), query \(\boldsymbol{q}_\tau\) and value \(\boldsymbol{v}_{t-\tau}\) are intermediate features produced at different time steps by lower levels of the network</li>
              <li>\(\alpha\left(\boldsymbol{\kappa}_t, \boldsymbol{q}_\tau\right) \in[0,1]\) is the attention weight for \(t-\tau\) generated at time \(t\)</li>
              <li>\(\boldsymbol{h}_t\) is the context vector output of the attention layer
                <h3 id="2b-multi-horizon-forecasting-models">2.(b) Multi-horizon Forecasting Models</h3>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>단순히 다음 한 시점에 대한 예측이 아닌 미래 여러 시점에 대한 예측</li>
  <li>(1) Iterative Methods : Autoregressive forecasting. 각 time step에서의 작은 오차가 누적된다는 단점이 있다.</li>
  <li>(2) Direct Methods : Encoder의 정보를 활용해서 한 번에 target time steps를 예측</li>
</ul>

<h2 id="3-incorporating-domain-knowledge-with-hybrid-models">3. Incorporating Domain Knowledge with Hybrid Models</h2>
<ul>
  <li>Machine learning의 underperformance의 이유는 1) flexibility로 인한 overfitting, 2) pre-processed input에 대한 sensitivity</li>
  <li>Hybrid models
    <ul>
      <li>combine well-studied quantitative time series models together with deep learning</li>
      <li>use domain knowledge \(\to\) hypothesis space를 줄여준다</li>
      <li>(a) Non-probabilistic Hybrid models : forecasting equations를 modify</li>
      <li>(b) Probabilistic Hybrid models : predictive distribution으로 parameters 생성</li>
    </ul>
  </li>
</ul>

<h2 id="4-facilitating-decision-support-using-deep-neural-networks">4. Facilitating Decision Support Using Deep Neural Networks</h2>
<ul>
  <li>연구하는 입장에서는 model의 성능(MSE, Accuracy, …)가 중요하지만, user는 future action에 대한 guide의 지표</li>
  <li>그러므로 Local Interpretable Model-Agnostic Explanations (LIME), Shapley additive explanations (SHAP)과 같은 post-hoc 분석, Attention weights를 통한 inherent interpretability를 이해할 필요가 있다.</li>
  <li>그러면 counterfactual forecast(determining what would have happened if a different set of circumstances had occurred) 가능</li>
</ul>

<h2 id="5-conclusions-and-future-directions">5. Conclusions and Future Directions</h2>
<ul>
  <li>Survey the main architectures used for TS forecasting</li>
  <li>Hybrid DL models : combine statistical and deep learning components</li>
  <li>Limitation : irregular TS나 hierarchical structure에 대한 고민은 하기 이전</li>
</ul>

<h2 id="추가">추가</h2>
<ul>
  <li>2020년에 발표된 survey 논문이지만 최근 Long-term Time Series Forecasting(LTSF)에 활용되는 모델에 대한 내용을 잘 정리한 논문이다.</li>
  <li>본 논문 이후 현재까지 최신 연구들을 이해한 상태로 읽는다면 최신 연구들의 motivation을 이해하는 데에 도움이 되는 논문이다.</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[Philos Trans R Soc A. 2020](https://arxiv.org/pdf/2004.13408.pdf)]]></summary></entry><entry><title type="html">(SoftCLT) Soft Contrastive Learning for Time Series (ICLR 2024)</title><link href="http://localhost:4000/timeseries/2024-03-13-softCLT/" rel="alternate" type="text/html" title="(SoftCLT) Soft Contrastive Learning for Time Series (ICLR 2024)" /><published>2024-03-13T00:00:00+09:00</published><updated>2024-03-18T20:38:56+09:00</updated><id>http://localhost:4000/timeseries/softCLT</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-03-13-softCLT/"><![CDATA[<h2 id="abstract">Abstract</h2>
<ul>
  <li>TS instance만으로 contrasting하거나, 하나의 TS의 adjacent timestamps만으로 contrasting하면 TS의 inherent correlation을 제대로 반영하지 못한다.</li>
  <li><strong>SoftCLT</strong> : instance-wise &amp; temporal Contrastive loss를 사용하여, 0 또는 1이 아닌 0 ~ 1 사이의 값으로 assign
    <ul>
      <li>Instance-wise contrastive loss : Data space에서 두 시계열의 distance</li>
      <li>Temporal contrastive loss : 서로 다른 시점에 대한 loss</li>
    </ul>
  </li>
</ul>

<h2 id="1-introduciton">1. Introduciton</h2>
<ul>
  <li>Self-supervised learning - Contrastive learning에서는 두 instance의 유사도로 pair를 설정하기보다는, 각 데이터에 대해 2개의 view를 augmentation하고 둘을 positive pair로 설정한다. (다른 데이터에서 augmentation된 view와는 negative)</li>
  <li>TS의 inherent correlations는 유사한 instance 뿐만 아니라, 인접한 timestamps에도 있다.</li>
  <li>설령 같은 data에서 augmentation 되었거나, 같은 timestamp의 value에만 positive(1)로 설정하더라도, 다른 data에서 augmentation 된 다른 timestamp의 value에는 다 똑같의 negative(0)으로 설정하는 것은 optimal하지 않다.</li>
  <li><a href="https://arxiv.org/pdf/1807.03748.pdf">InfoNCE</a>의 loss처럼 positive pair 뿐만 아니라 negative pair에 대해서도 weight를 고려하는 Soft Contrastive Learning for TS를 제안
<img src="/assets/img/timeseries/softclt/table1.png" alt="사진1" /></li>
</ul>

<h2 id="2-related-work">2. Related Work</h2>
<ul>
  <li>Self-supervised learning : 많은 양의 unlabeled data를 활용하는 pretext task를 수행하는 모델을 훈련시키고, 해당 모델을 downstream task의 앞쪽에 가져와서 사용한다. pretext task로는 <code class="language-plaintext highlighter-rouge">next token prediction</code>, <code class="language-plaintext highlighter-rouge">masked token prediction</code>, <code class="language-plaintext highlighter-rouge">jigsaw puzzles</code>, <code class="language-plaintext highlighter-rouge">rotation prediction</code> 등</li>
  <li>Contrastive learning in TS
    <ul>
      <li><a href="https://arxiv.org/pdf/1901.10738.pdf">T-Loss</a> : TS에서 subseries 샘플링, subseries가 속한 TS와는 positive 다른 TS와는 negative</li>
      <li><a href="https://arxiv.org/pdf/2011.13548.pdf">Self-Time</a> : augmented sample로 inter-sample relation 학습, temporal distance로 label을 만들고 classification 해서 intra-temporal relation 학습</li>
      <li><a href="https://arxiv.org/pdf/2106.00750.pdf">TNC</a> : 정규분포 window로 정의한 temporal neighborhood를 positive로 설정</li>
      <li><a href="https://arxiv.org/pdf/2106.14112.pdf">TS-TCC</a> : augmentations가 서로의 미래 시점을 예측하도록 해서 temporal contrastive loss 설정</li>
      <li><a href="https://arxiv.org/pdf/2203.09270.pdf">Mixing-up</a> : 2개의 TS를 섞어서 새로운 TS를 만드는데 mixing weights를 predict</li>
      <li><a href="https://arxiv.org/pdf/2202.01575.pdf">CoST</a> : time, frequency domain의 contrastive losses를 사용하여 representation learning</li>
      <li><a href="https://pdf.sciencedirectassets.com/271505/1-s2.0-S0950705122X00075/1-s2.0-S0950705122002726/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEMr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCDSwasc4kb8LU0bgnJMwyHRmJ5Xp0qOkMGkgGRC101hgIgQu4zuleiKDecSs%2FYiwU6McTbx88zb7ZGNMt6fPGxxoAqvAUI0v%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDF3vdKai06uU77VSpSqQBVBf8gEuvX4RtLZKv9hE3KxXK6cBABJ3MlBBkOHOQG9wKZz7o6d1XmLn2FZSjY4%2FX7pPyQcDRmkq2n%2FJq8%2Fsui0EeAASo4iyS840z2aCXativJcKRglZNYHjwhkBAax3A8xvkoahV70%2BnaX2GHQ5TWPuaUEwQkfUD1Y%2BKJW17Llm6SzL9NFiUMu9oRVuGLNfzeDz8H916pyvPQXFS5ltLq8PmDSlDFSwpmuvjRZvcGJVQCRYJ9QAqN4pjSkBwmRJtZ1zxeYYLfQU88%2FhHpCuqKY%2Fo5PlZqitF%2Fi5tN9wcjv%2BOaUu0e3H8K8qknd2hQhfYZ3mcE319ttggfYVT4PxT6jQv2hH%2BtWO%2BQVZ32moiyr2q2dfvqndSZ%2BcslmaJMEEGPfVbkcqz6OuRXKg9c6wHw%2BzGjJ0qF8lctSoDbLhT5IOZWG%2FmNF%2BMVvU5Wgorfa2swiBav99Hgn3vrf74u8mLsY5T0vx4NEyG%2BNVyPbgKqGOHsQAejW06Vq4ik5UIzPpsQ5HV4XPKK%2Fqymlem1XN6PxFHQeaf3vs0y8kVwp0rvnrfnnQ4LSrKfZc%2FNdpLU%2FXHGx%2BkUvIAHtVRX4a%2BC3sP8xSXKWTctA458XV7b5O7K5sXlyS36%2F3xnTrjC0NcJv80e3dYPRDhg3knQfYgDe2geRGQuU2COYu%2FKksZiGgBXhSAln%2Bud9LWeLVphgzjSipja81DInKiCBNOHOlulkaoOh0WcdIOFQeAQ2q6v4DeoIE1D8tTL5JNgWDLUk8sxQGq9zspYADXCEhc9Ke4hgL%2FuFvRA6Q12rCsxcWroPVYAf2el010OB%2BHSiqaCHw6xiykfcfjw7oO7bINDuWwMASTZbTgTVETF0hx1VpaYUnUbObMOCH4K8GOrEBiMpaUIWZ9pgzWe8VL74b8Keg8P4qJal5QND0KgcUzoVtZv4JMAmxEuey5Xggo3VjcjrCYsQ3sGOrJ9OJ570LbYowhBvMl7GSojd2kqdTrDSXd400eFg4uwE4Vb35B7htjgxzcxpZJeKmMPHzoEJdnMzI61T%2Fkl8%2FoIh3I9dws%2BUKd1pmrot0rGKx7EM68SBELBX2rcQ1SfmvbLKJAKBimMCFZrVhl4BAeMfpNyKSnkQM&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20240318T093805Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTYRLOY57VC%2F20240318%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=0e72e500b607b8e5538d7a3d24ad28c78f5bc82c4b10c8f43305eb800f767c1b&amp;hash=4ee078d9d743db9b7aed88f3efc12b11dbe7e497747d269063317fe1b35fad70&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S0950705122002726&amp;tid=spdf-1cc819cf-9b45-4e50-834c-160b0fdd0a1e&amp;sid=cc5998cf8485c74f0b497fc9e83d21092089gxrqa&amp;type=client&amp;tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&amp;ua=05125c535357540259&amp;rr=86643f6fd90f3079&amp;cc=kr">TimeCLR</a> : phase-shift and amplitude change augmentation based on DTW</li>
    </ul>
  </li>
  <li>Soft contrastive learning
    <ul>
      <li><a href="https://arxiv.org/pdf/2104.14548.pdf">NNCLR</a> : 각 view마다 feature space에서 k-neighbors를 찾아서 추가적인 positive pair를 고려</li>
      <li>non-TS 도메인에서는 soft assignment를 계산할 때 embedding space에서 했지만, TS 도메인에서는 data space에서 계산한다.</li>
    </ul>
  </li>
  <li>Masked modeling in TS
    <ul>
      <li><a href="https://arxiv.org/pdf/2010.02803.pdf">TST</a> : masked modeling paradigm을 TS에 도입</li>
      <li><a href="https://arxiv.org/pdf/2211.14730.pdf">PatchTST</a> :  masked subseries-level patche를 예측해서 local semantic information을 효율적으로 계산</li>
      <li><a href="https://arxiv.org/pdf/2302.00861.pdf">SimMTM</a> : 여러 개의 masked TS로부터 reconstruction</li>
    </ul>
  </li>
</ul>

<h2 id="3-methodology">3. Methodology</h2>
<ul>
  <li>instance-wise contrastive loss : inter-sample relationship 학습. Distance btw TS on data space</li>
  <li>temporal contrastive loss : intra-temporal relationship 학습. 하나의 TS에서 서로 다른 timestamps의 차이
<img src="/assets/img/timeseries/softclt/fig1.png" alt="사진2" />
    <h3 id="31-problem-definition">3.1. Problem Definition</h3>
  </li>
  <li>하나의 batch에는 N개의 TS : \(\mathcal{X}=\left\{x_1, \ldots, x_N\right\}\)가 있고
    <ul>
      <li>\(f_\theta = x_i \in \mathbb{R}^{T \times D} \to r_i=\left[r_{i, 1}, \ldots, r_{i, T}\right]^{\top} \in \mathbb{R}^{T \times M}\)를 학습</li>
      <li>\(D\)는 input feature dim, \(M\)은 embedded feature dim
        <h3 id="32-soft-instance-wise-contrastive-learning">3.2. Soft Instance-wise Contrastive learning</h3>
      </li>
    </ul>
  </li>
  <li>Vision에서는 pixel-by-pixel distance가 similarity와 관련이 없기 때문에 embedding space에서 similar instance를 학습하지만, TS에서는 data space에서의 거리가 similarity가 된다.</li>
  <li>soft assignment for a pair of data indice \((i, i')\) : \(w_I\left(i, i^{\prime}\right)=2 \alpha \cdot \sigma\left(-\tau_I \cdot D\left(x_i, x_{i^{\prime}}\right)\right)\)
    <ul>
      <li>\(D(\cdot, \cdot)\) : min-max normalized distance metric</li>
      <li>\(\tau_I\) : hyperparameter controlling the sharpness</li>
      <li>\(\alpha\) : the upper bound in the range of [0, 1]. 완전 똑같은 TS의 assignment</li>
      <li>augmented view끼리가 아니라 original TS끼리 계산하는 것</li>
    </ul>
  </li>
  <li>Contrasive loss는 cross-entropy loss로 해석될 수 있으므로(<a href="https://arxiv.org/pdf/2010.08887.pdf">i-Mix</a>), softmax probability of the relative similarity는 \(p_I\left(\left(i, i^{\prime}\right), t\right)=\frac{\exp \left(r_{i, t} \circ r_{i^{\prime}, t}\right)}{\sum_{j=1, j \neq i}^{2 N} \exp \left(r_{i, t} \circ r_{j, t}\right)}\)</li>
  <li>Soft instance-wise contrastive loss for \(x_i\), at \(t\)는 \(\ell_I^{(i, t)}=-\log p_I((i, i+N), t)-\sum_{j=1, j \neq\{i, i+N\}}^{2 N} w_I(i, j \bmod N) \cdot \log p_I((i, j), t)\)
    <ul>
      <li>첫째 term은 positive pair에 대한 loss, 둘째 term은 나머지에 대한 loss인데 \(w_I\left(i, i^{\prime}\right)\)로 weighted.</li>
      <li>\(\forall w_I\left(i, i^{\prime}\right)=0\)이면 hard instance-wise contrastive loss이므로 일반화 버전이다.
        <h3 id="33-soft-temporal-contrastive-learning">3.3. Soft Temporal Contrastive learning</h3>
      </li>
    </ul>
  </li>
  <li>soft assignment for a pair of timestamps \((t, t')\) : \(w_T\left(t, t^{\prime}\right)=2 \cdot \sigma\left(-\tau_T \cdot\mid t-t^{\prime}\mid\right)\)
    <ul>
      <li>\(\tau_I\) : hyperparameter controlling the sharpness</li>
    </ul>
  </li>
  <li>: 인접한 timestamp의 values는 비슷할 것이라는 직관</li>
  <li><strong>Hierarchical loss</strong> : <a href="https://arxiv.org/pdf/2106.10466.pdf">TS2Vec</a>의 방식처럼 maxpooling을 해서 loss 계산
<img src="/assets/img/timeseries/softclt/fig2.png" alt="사진3" /></li>
  <li>Softmax probability of the relative similarity는 \(p_T\left(i,\left(t, t^{\prime}\right)\right)=\frac{\exp \left(r_{i, t} \circ r_{i, t^{\prime}}\right)}{\sum_{s=1, s \neq t}^{2 T} \exp \left(r_{i, t} \circ r_{i, s}\right)}\),</li>
  <li>Soft temporal contrastive loss for \(x_i\) at \(t\)는 \(\ell_T^{(i, t)}=-\log p_T(i,(t, t+T))-\sum_{s=1, s \neq\{t, t+T\}}^{2 T} w_T(t, s \bmod T) \cdot \log p_T(i,(t, s))\)
    <ul>
      <li>마찬가지로 \(\forall w_T\left(t, t^{\prime}\right)=0\)이면 hard temporal contrastive loss이므로 일반화 버전이다.</li>
    </ul>
  </li>
  <li>본 논문에서 제시하는 SoftCLT의 Final loss : \(\mathcal{L}=\frac{1}{4 N T} \sum_{i=1}^{2 N} \sum_{t=1}^{2 T}\left(\lambda \cdot \ell_I^{(i, t)}+(1-\lambda) \cdot \ell_T^{(i, t)}\right)\)
    <ul>
      <li>\(\lambda\) : hyperparameter controlling the contribution of each loss</li>
    </ul>
  </li>
</ul>

<h2 id="4-experiments">4. Experiments</h2>
<ul>
  <li>(1) Classification with UTS, MTS (2) Semi-supervised classification (3) Transfer learning in in-domain and cross-domain (4) Anomaly detection
    <h3 id="41-classification">4.1. Classification</h3>
    <p><img src="/assets/img/timeseries/softclt/fig23.png" alt="사진4" /></p>
    <h3 id="42-semi-supervised-classification">4.2. Semi-supervised classification</h3>
    <p><img src="/assets/img/timeseries/softclt/table3.png" alt="사진5" /></p>
    <h3 id="43-transfer-learning">4.3. Transfer learning</h3>
    <p><img src="/assets/img/timeseries/softclt/table4.png" alt="사진6" /></p>
    <h3 id="44-anomaly-detection">4.4. Anomaly detection</h3>
    <p><img src="/assets/img/timeseries/softclt/table5.png" alt="사진7" /></p>
    <h3 id="45-ablation-study">4.5. Ablation study</h3>
    <p><img src="/assets/img/timeseries/softclt/table6.png" alt="사진8" /></p>
    <ul>
      <li>(a) : soft assignment를 instance-wise와 temporal에 모두 적용했을 때 성능이 가장 좋다.</li>
      <li>(b) : \(W_T\)를 계산하는 방법들에 따른 비교. sigmoid를 사용하는 근거가 된다.</li>
      <li>(c) : \(\alpha=0.5\) 정도로 해서 같은 TS의 similarity of the pairs를 적절히 크게 할 때 성능이 좋다.</li>
      <li>(d) : Distance function에 따른 성능 비교. DTW와 TAM의 성능이 같지만 더 일반적인 DTW 사용했다.
        <h3 id="46-analysis">4.6. Analysis</h3>
      </li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Comparison with soft CL methods in computer vision</code> : 앞서 언급했듯이 embedding space에서 similarity를 계산하는 vision domain과 다르게, TS는 data space에서 계산하면 성능이 더 좋다.</li>
  <li><code class="language-plaintext highlighter-rouge">Robustness to seasonality</code> : Seasonality in TS는 extract하기 어렵지도 않고 고려 안해도 성능이 좋아서 직접적으로 고려하지 않았다.</li>
  <li><code class="language-plaintext highlighter-rouge">Instance-wise relationships</code> : layer가 깊어짐에 따라 SoftCLT가 Hard CL보다 TS instance 사이의 관계를 잘 보존한다.</li>
  <li><code class="language-plaintext highlighter-rouge">Temporal relationships</code> : 시간(training epoch)에 따라서도 t-SNE를 비교했을 때, Hard CL은 진한 색(large tarining epoch)을 잘 구분하지 못하는데, large training epoch에는 fine-grained relationship이 학습된다. 즉 Hard CL은 coarse-grained relationship은 잘 학습하지만 SoftCLT는 fine-grained relationship도 잘 학습한다.</li>
</ul>

<h2 id="5-conclusion">5. Conclusion</h2>
<ul>
  <li>SoftCLT : soft assignments based on the instance-wise and temporal relationships on the data space</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[ICLR 2024](https://arxiv.org/abs/2312.16424)]]></summary></entry><entry><title type="html">(TS2Vec) Towards Universal Representation of Time Series (AAAI 2022)</title><link href="http://localhost:4000/timeseries/2024-03-12-ts2vec/" rel="alternate" type="text/html" title="(TS2Vec) Towards Universal Representation of Time Series (AAAI 2022)" /><published>2024-03-12T00:00:00+09:00</published><updated>2024-03-12T20:29:48+09:00</updated><id>http://localhost:4000/timeseries/ts2vec</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-03-12-ts2vec/"><![CDATA[<h2 id="abstract">Abstract</h2>
<ul>
  <li>본 논문에서 풀고자 하는 문제는 unsupervised TS representation(TS \(\to\) vector)</li>
  <li>TS를 arbitrary semantic level에서 representation하는 방법을 학습하는 framework</li>
  <li>augmented context views를 hierarchical하게 contrastive learning한다.</li>
  <li>(선행연구(<a href="https://arxiv.org/abs/2106.00750">TNC</a>, <a href="https://arxiv.org/abs/1901.10738">T-Loss</a>)를 읽기 전이라면 abstract에서 등장하는 단어들의 의미가 와닿지 않을 수 있다.)</li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>이미 instance-level representation을 학습하는 연구들도 있었고(<a href="https://arxiv.org/abs/2106.00750">TNC</a>, <a href="https://arxiv.org/abs/1901.10738">T-Loss</a>),</li>
  <li>contrastive loss를 사용해서 TS의 구조를 학습하는 연구들도 있었다.(<a href="https://arxiv.org/abs/2106.14112">TS-TCC</a>, <a href="https://arxiv.org/abs/1901.10738">T-Loss</a>)</li>
  <li>하지만 지금까지의 방법들의 한계는 아래 3가지로 정리할 수 있다.</li>
  <li>첫째, instance-level representation은 fine-grained representation(e.g. forecasting, anomaly detection)에 적합하지 않다.
    <ul>
      <li>왜냐하면 specific한 timestamp, sub-series를 타겟으로 inference해야 하는데, coarse-grained representation으로는 충분하지 않다.</li>
    </ul>
  </li>
  <li>둘째, 다양한 granularities에서의 multi-scale contextual information을 파악하기 어렵다.
    <ul>
      <li>granularity가 높을수록 더 자세한 정보를 포함 (일별 &lt; 시간별 &lt; 분별 &lt; 초별 …)</li>
      <li>multi-scale information은 다양한 granularities에서 나타나는 정보. Scale에 따라 달라질 수는 있지만, representation의 generalization capability를 향상시킨다는 점에서 TS task에서 필수적인 정보이다.</li>
    </ul>
  </li>
  <li>셋째, CV, NLP에서의 unsupervised representation은 강한 inductive bias가 있는데, TS는 그렇지 않다.
    <ul>
      <li>transformation-invariant : 강아지 사진은 거꾸로 뒤집어도 강아지 사진이지만, TS는 거꾸로 뒤집으면 아예 다른 데이터가 된다.</li>
      <li>cropping-invariant : 사진이나 문장은 일부분을 잘라도 본질적인 정보가 바뀌지 않는 경우가 많아 augmentation 방법으로 쓰이지만, TS는 일부분을 자르면 패턴이나 분포 자체가 달라지게 된다.</li>
    </ul>
  </li>
  <li>본 논문에서 제시하는 TS2Vec은 universal contrastive learning framework를 제안
    <ul>
      <li>maxpooling으로 다양한 granularity의 overall representation을 얻고</li>
      <li>instance-wise and temporal dim에서의 hierarchically contrastive learning을 통해</li>
      <li>all-semantic level에서의 representation을 얻는다.</li>
    </ul>
  </li>
</ul>

<h2 id="2-method">2. Method</h2>

<h3 id="21-problem-definition">2.1. Problem Definition</h3>
<ul>
  <li>N개의 시계열 \(\mathcal{X}=\left\{x_1, x_2, \cdots, x_N\right\}\)에 대해서 nonlinear embedding function \(f_\theta : x_i \in \mathbb{R}^{T \times F} \to r_i=\left\{r_{i, 1}, r_{i, 2}, \cdots, r_{i, T}\right\} \in \mathbb{R}^{T \times K}\)를 학습한다.</li>
</ul>

<h3 id="22-model-architecture">2.2. Model Architecture</h3>
<p><img src="/assets/img/timeseries/ts2vec/fig1.png" alt="사진1" /></p>
<ul>
  <li><strong>sub-series</strong> : input TS \(x_i\)에서 2개의 sub-series를 랜덤하게 sampling한다.
    <ul>
      <li>겹치는 부분이 있도록 (겹치는 부분의 contextual representation이 consistent하도록 할거니까)</li>
    </ul>
  </li>
  <li><strong>Encoder</strong> \(f_\theta\)는 3개의 modules로 구성
    <ul>
      <li><strong>projection layer</strong> : t시점의 input을 high-dim latent vector로 mapping하는 FC layer. \(x_{i,t} \to z_{i,t}\)</li>
      <li><strong>timestamp masking module</strong> : latent vectors의 random한 timestamps를 masking(=0)해서 augmented context view를 생성</li>
      <li><strong>dilated CNN module</strong> : 각 timestamp의 contextual representation을 extract. 이 때 1d dilated conv layer를 사용하는데, dilation parameter를 다양하게 해서(\(2^l\) for \(l\)-th block) larger receptive field</li>
    </ul>
  </li>
</ul>

<h3 id="23-contextual-consistency">2.3. Contextual Consistency</h3>
<ul>
  <li>Contrastive learning을 위한 positive pair를 만드는 전략들을 소개한다.
<img src="/assets/img/timeseries/ts2vec/fig2.jpeg" alt="사진2" /></li>
  <li><strong>Subseries consistency</strong> : 서로 sub-series 관계인 segments를 positive pair로 설정하고 representation을 가깝게 학습</li>
  <li><strong>Temporal consistency</strong> : 인접한 시점의 segments를 positive pair로 설정</li>
  <li><strong>Transformation consistency</strong> : scaling, permutation과 같은 transformation에 invariant한 representation을 학습
<img src="/assets/img/timeseries/ts2vec/fig3.jpeg" alt="사진3" /></li>
  <li>하지만 fig3을 보면 위와 같은 전략들이 시계열 데이터에는 적절하지 않다. sub-series라고 해서, 인접한 시점이라고 해서 패턴이 같은 것은 아니다.</li>
  <li><strong>Contextual consistency</strong> : 본 논문에서 제시하는 방법으로, 동일한 timestamp에 대해 random masking이나 random cropping으로 생성한 contexts를 positive pair로 설정한다.
    <ul>
      <li><strong>Timestamp masking</strong> : 각 timestamp에 대해 latent vector \(z_i = \{z_{i,t\}\}\)를 \(p=0.5\) bernoulli masking</li>
      <li><strong>Random cropping</strong> : input \(x_i \in \mathbb R^{T \times F}\)에 대해 \(0 &lt; a_1 \le a_2 \le b_1 \le b_2 \le T\)를 만족하는 segments \([a_1, b_1], [a_2, b_2]\)를 random하게 만들고, 각 segment에 대해 overlapping segment인 \([a_2, b_1]\)의 contextual representation이 consistent해지도록 학습한다.</li>
      <li>Masking과 random cropping은 시계열의 magnitude를 바꾸지도 않으면서, 각 timestamp에 대해 복원하도록 학습시키기 때문에 robust한 representation learning 방식이다.</li>
    </ul>
  </li>
</ul>

<h3 id="24-hierarchical-contrasting">2.4. Hierarchical Contrasting</h3>
<ul>
  <li><strong>Hierarchical contraastive loss</strong> : 본 논문에서 제시하는 학습 방식으로, 다양한 scales에서의 representation을 학습하기 위한 loss이다. (scales가 다양하기 때문에 max-pooling을 사용한다.)
    <ul>
      <li>instance-wise &amp; temporal contrastive losses 모두 leverage하는데, 이걸 모든 granularity levels에 대해서 hierarchical하게 적용한다.</li>
    </ul>
  </li>
  <li><strong>Temporal Contrastive Loss</strong>
    <ul>
      <li>\(\ell_{t e m p}^{(i, t)}=-\log \frac{\exp \left(r_{i, t} \cdot r_{i, t}^{\prime}\right)}{\sum_{t^{\prime} \in \Omega}\left(\exp \left(r_{i, t} \cdot r_{i, t^{\prime}}^{\prime}\right)+\mathbb{1}_{\left[t \neq t^{\prime}\right]} \exp \left(r_{i, t} \cdot r_{i, t^{\prime}}\right)\right)}, \quad \Omega \text{ is the set of timestamps}\)이다.</li>
      <li>동일한 input \(x_i\)에 대해서, timestamp가 같으면 positive이고 다르면 negative이다.
<img src="/assets/img/timeseries/ts2vec/myfig1.jpeg" alt="사진5" /></li>
      <li>위 그림에서 빨강색이 분모에 포함되는 timestamps이고, 파랑색이 분자에 해당하는 timestamp이다. 같은 input에 대해 서로 다른 augmentation의 같은 timestamp가 가깝게 representation되도록 학습한다는 의미이다.</li>
    </ul>
  </li>
  <li><strong>Instance-wise Contrastive Loss</strong>
    <ul>
      <li>\(\ell_{i n s t}^{(i, t)}=-\log \frac{\exp \left(r_{i, t} \cdot r_{i, t}^{\prime}\right)}{\sum_{j=1}^B\left(\exp \left(r_{i, t} \cdot r_{j, t}^{\prime}\right)+\mathbb{1}_{[i \neq j]} \exp \left(r_{i, t} \cdot r_{j, t}\right)\right)}, \quad B \text{ is the batch size}\)이다.</li>
      <li>한 시점 t와 모든 instance(input)에 대해 같은 instance이면 positive이고 다른 instance이면 negative이다.
<img src="/assets/img/timeseries/ts2vec/myfig2.jpeg" alt="사진6" /></li>
      <li>역시 빨강색이 분모에 포함되는 instance이고, 파랑색이 분자에 해당하는 instance이다. 한 timestamp에 대해 같은 instance의 augmentation가 가깝게 representation되도록 학습한다는 의미이다.</li>
    </ul>
  </li>
  <li>두 losses는 complementary하다. (예를 들어 다수의 전기 사용량 시계열 데이터라면, instance contrast는 user-specifc 정보를, temporal contrast는 시간에 따른 dynamic trends를 학습한다.)</li>
  <li>The overall loss : \(\mathcal{L}_{\text {dual }}=\frac{1}{N T} \sum_i \sum_t\left(\ell_{\text {temp }}^{(i, t)}+\ell_{\text {inst }}^{(i, t)}\right)\)</li>
</ul>

<h2 id="3-experiments">3. Experiments</h2>
<p><img src="/assets/img/timeseries/ts2vec/table2.jpeg" alt="사진7" />
<img src="/assets/img/timeseries/ts2vec/fig5.png" alt="사진8" /></p>
<ul>
  <li>Informer는 trends는 학습했지만 주기적 패턴을 학습하지 못했고, TCN은 반대로 주기적 패턴은 학습했지만 trends는 학습하지 못했다. (coarse-grained vs fine-grained 둘 다 잘 학습하기 어려움)</li>
</ul>

<h2 id="4-analysis">4. Analysis</h2>
<p><img src="/assets/img/timeseries/ts2vec/table5.png" alt="사진9" /></p>
<ul>
  <li>Ablation study를 통해 components를 justify하였다.
<img src="/assets/img/timeseries/ts2vec/fig7.png" alt="사진10" /></li>
  <li>Heatmap을 통해 급작스러운 spike에 대해서도 적절하게 representation할 수 있음을 확인하였다.</li>
</ul>

<h2 id="5-conclusion">5. Conclusion</h2>
<ul>
  <li>TS2Vec : universial representation learning framework
    <ul>
      <li>hierarchical contrasting을 통해 scale-invariant representation을 학습하였고,</li>
      <li>instance-wise contrasting과 temporal contrasting으로 loss를 설정하였다.</li>
    </ul>
  </li>
  <li>Ablation study를 통해 모델의 components가 모두 필요함을 보여주었다.</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[AAAI 2022](https://arxiv.org/abs/2106.10466)]]></summary></entry><entry><title type="html">(SimMTM) A Simple Pre-Training Framework for Masked Time-Series Modeling (NeurIPS 2023)</title><link href="http://localhost:4000/timeseries/2024-03-06-SimMTM/" rel="alternate" type="text/html" title="(SimMTM) A Simple Pre-Training Framework for Masked Time-Series Modeling (NeurIPS 2023)" /><published>2024-03-06T00:00:00+09:00</published><updated>2024-03-07T15:14:12+09:00</updated><id>http://localhost:4000/timeseries/SimMTM</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-03-06-SimMTM/"><![CDATA[<h2 id="abstract">Abstract</h2>
<ul>
  <li>Labeling 비용을 줄이고 다양한 downstream tasks의 성능을 위해 self-supervised pre-training 방식이 사용된다.
    <ul>
      <li>Contrastive learning : positive and negative pairs를 통해 representation space 최적화</li>
      <li>Masked modeling : unmasked part를 보고 masked content를 reconstruct</li>
    </ul>
  </li>
  <li>하지만 시계열에서는 randomly masking하면 temporal variations(trend, periodicity, peak valley …)가 망가져서 reconstruction task가 너무 어려워진다.</li>
  <li>그래서 본 논문에서 제시하는 SimMTM은 한 개가 아니라 여러 개의 masked series를 assembling해서 reconstruction한다.</li>
</ul>

<h2 id="1-intnroduction">1. Intnroduction</h2>
<ul>
  <li>Self-supervised pre-training(SSL) : 대량의 unlabeled 데이터로 pretext knowledge를 학습하고, 다양한 downstream task에 맞게 개선 (Linear probing / Fine tuning)</li>
  <li>pre-training 방법 중 하나인 Masked modeling을 시계열에 적용
    <ul>
      <li>Masked modeling : 데이터의 일부를 masking하고 unmasked part를 보고 masked part를 reconstruct하는 방식을 학습</li>
    </ul>
  </li>
  <li>이미지나 자연어는 불필요한 정보도 많이 있지만(이미지의 빈 공간, 수식어 등), 시계열에는 temporal variations(trend, periodicity, peak vally…)가 있어서 단순하게 일부를 masking하면 시계열의 본질적인 부분이 변형되거나 망가질 수 있다.</li>
  <li>그래서 multiple masking series로 original data를 reconstruction하면 개별 maksing series에서는 temporal variations가 변형될 수 있지만 각 maksing series는 서로서로 complement하기 때문에 multiple masking series를 봤을 때에는 본질적인 부분이 사라지지 않는다.
<img src="/assets/img/timeseries/SimMTM/fig1.jpeg" alt="사진1" /></li>
  <li>요약하자면 SimMTM은 neighborhood aggregation design for reconstruction이라고 할 수 있고,
    <ul>
      <li>풀어서 설명하자면 SimMTM은 masked part를 reconstruct하기 위해서 series-wise representation의 simailarity가 높은 point-wise representations을 aggregate한다고 할 수 있다.</li>
    </ul>

    <h2 id="2-related-work">2. Related Work</h2>
    <h3 id="21-self-supervised-pre-training">2.1. Self-supervised Pre-training</h3>
    <ul>
      <li>Self-supervised Pre-training(SSL)
        <ul>
          <li>Contrastive leaning : positive pairs는 가깝게, negative pairs는 멀게 representation하도록 학습</li>
          <li>Masked modeling
            <ul>
              <li>TST : learns to predict removed time points based on the remaining time points</li>
              <li>PatchTST : predict masked subseries-level patches to capture the local semantic information</li>
              <li>Ti-MAE : mask modeling as an auxiliary task to boost the forecasting and classification performances</li>
            </ul>
          </li>
          <li>하지만 directly masking time series 방식은 본질적인 temporal variations를 망가지게 할 수 있으니, multiple randomly masked series로 recunstruct한다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="3-simmtm">3. SimMTM</h2>
<ul>
  <li>모델은 크게 2개의 단계로 구성
    <ul>
      <li>multiple time series의 series-wise representation space에서의 similarities를 학습</li>
      <li>학습된 similarities를 바탕으로 point-wise representations를 aggregate</li>
    </ul>
  </li>
</ul>

<h3 id="31-overall-architecture">3.1. Overall Architecture</h3>
<ul>
  <li>모델은 4개의 modules로 구성
    <ul>
      <li>Masking</li>
      <li>Representation learning</li>
      <li>Series-wise similarity learning</li>
      <li>Point-wise aggregation
<img src="/assets/img/timeseries/SimMTM/fig2.png" alt="사진2" /></li>
    </ul>
  </li>
  <li><strong>Masking</strong>
    <ul>
      <li>\(\left\{\mathbf{x}_i\right\}_{i=1}^N\) : a mini-batch of \(N\) time series samples, <br />
where \(\mathbf{x}_i \in \mathbb{R}^{L \times C}\) contains \(L\) time points and \(C\) observed variates</li>
      <li>\(\left\{\overline{\mathbf{x}}_i^j\right\}_{j=1}^M=\operatorname{Mask}_{r}\left(\mathbf{x}_i\right)\) <br />
where \(r \in[0,1]\) denotes the masked portion,
\(M\) is a hyperparameter for the number of masked time series</li>
      <li>
        <p>\(\overline{\mathbf{x}}_i^j \in \mathbb{R}^{L \times C}\) : the \(j\)-th masked time series of \(\mathbf{x}_i\)</p>
      </li>
      <li>All the \((N(M+1))\) input series in a set as \(\mathcal{X}=\bigcup_{i=1}^N\left(\left\{\mathbf{x}_i\right\} \cup\left\{\overline{\mathbf{x}}_i^j\right\}_{j=1}^M\right)\).
        <ul>
          <li>\(N\)은 mini-batch에 있는 시계열 데이터 sample의 개수,</li>
          <li>\(M\)은 multiple masked time series의 개수</li>
          <li>\(1\)은 masking 하지 않은 원본 시계열을 의미한다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Representation learning</strong>
    <ul>
      <li>Encoder : Transformer and ResNet (to obtain the point-wise representations \(\mathcal{Z}\))
        <ul>
          <li>\(\mathcal{Z}=\bigcup_{i=1}^N\left(\left\{\mathbf{z}_i\right\} \cup\left\{\overline{\mathbf{z}}_i^j\right\}_{j=1}^M\right)=\operatorname{Enocder}(\mathcal{X})\) <br />
where \(\mathbf{z}_i, \overline{\mathbf{z}}_i^j \in \mathbb{R}^{L \times d_{\text {model }}}\)</li>
          <li>Detail : input 시계열마다 separately하게 통과 : \(\bigcup_{i=1}^N\left(\operatorname{Encoder}\left(\mathbf{x}_i\right) \cup\left\{\text { Encoder }\left(\overline{\mathbf{x}}_i^j\right)\right\}_{j=1}^M\right)\)</li>
        </ul>
      </li>
      <li>Projector : MLP layer along the temporal dim (to obtain the series-wise representations \(\mathcal{S}\))
        <ul>
          <li>\(\mathcal{S}=\bigcup_{i=1}^N\left(\left\{\mathbf{s}_i\right\} \cup\left\{\overline{\mathbf{s}}_i^j\right\}_{j=1}^M\right)=\operatorname{Projector}(\mathcal{Z})\) <br />
where \(\mathbf{s}_i, \overline{\mathbf{s}}_i^j \in \mathbb{R}^{1 \times d_{\text {model }}}\)</li>
        </ul>
      </li>
      <li>Note : \(\mathbf{z}_i, \overline{\mathbf{z}}_i^j \in \mathbb{R}^{L \times d_{\text {model }}}, \mathbf{s}_i, \overline{\mathbf{s}}_i^j \in \mathbb{R}^{1 \times d_{\text {model }}}\)
<img src="/assets/img/timeseries/SimMTM/myfig1.jpeg" alt="사진3" /></li>
    </ul>
  </li>
  <li><strong>Series-wise similarity learning</strong>
    <ul>
      <li>Multiple masked time series를 단순하게 averaging하면 over-smoothing problem이 있기 때문에, similarities among series-wise representation로 weighted aggregation한다.</li>
      <li>
\[\mathbf{R}=\operatorname{Sim}(\mathcal{S}) \in \mathbb{R}^{D \times D}, D=N(M+1), \quad \mathbf{R}_{\mathbf{u}, \mathbf{v}}=\frac{\mathbf{u v}^{\top}}{\|\mathbf{u}\|\|\mathbf{v}\|}, \mathbf{u}, \mathbf{v} \in \mathcal{S}\]
        <ul>
          <li>\(\mathbf{R}=\operatorname{Sim}(\mathcal{S}) \in \mathbb{R}^{D \times D}\)은 \(N(M+1)\)개의 input 각각에 대해 series-wise representation space에서의 similarities가 된다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Point-wise aggregation</strong>
    <ul>
      <li>The aggregation process는 다음과 같다 : \(\widehat{\mathbf{z}}_i=\sum_{\mathbf{s}^{\prime} \in \mathcal{S} \backslash\left\{\mathbf{s}_i\right\}} \frac{\exp \left(\mathbf{R}_{\mathbf{s}_i, \mathbf{s}^{\prime}} / \tau\right)}{\sum_{\mathbf{s}^{\prime \prime} \in \mathcal{S} \backslash\left\{\mathbf{s}_i\right\}} \exp \left(\mathbf{R}_{\mathbf{s}_i, \mathbf{s}^{\prime \prime}} / \tau\right)} \mathbf{z}^{\prime}\)
        <ul>
          <li>where \(\mathbf{z}^{\prime}=\text { Projector }\left(\mathbf{s}^{\prime}\right)\), \(\tau\) denotes the temperature hyperparameter of softmax normalization for series-wise similarities</li>
          <li>의미적으로는 \(\mathbf{x}_i\)를 reconstruction하기 위해서 \(\mathbf{x}_i\)에 대한 M개의 masked series \(\left\{\overline{\mathbf{x}}_i^j\right\}_{j=1}^M\) 뿐만 아니라, similarities가 높은 다른 series(samples)도 참고하겠다는 것으로, 시계열의 structure를 더 잘 학습하도록 의도했다.</li>
        </ul>
      </li>
      <li>그리고 마지막으로 Decoder를 통과시키면 reconstruction 값을 얻는다 : \(\left\{\widehat{\mathbf{x}}_i\right\}_{i=1}^N=\operatorname{Decoder}\left(\left\{\widehat{\mathbf{z}}_i\right\}_{i=1}^N\right)\)
        <ul>
          <li>\(\operatorname{Decoder}\)는 simple MLP layer (along the channel dim)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="32-self-supervised-pre-training">3.2. Self-supervised Pre-training</h3>
<ul>
  <li>SimMTM의 reconstruction loss는 \(\mathcal{L}_{\text {reconstruction }}=\sum_{i=1}^N\left\|\mathbf{x}_i-\widehat{\mathbf{x}}_i\right\|_2^2\)이다.</li>
  <li>The series-wise representation space에 constraints가 없으면 trivial aggregation이 발생할 수 있기 때문에, 한 series에 대한 multiple masked series끼리는 positive pair, 서로 다른 series에 대해서는 negative pair로 가정하고 (neighborhood assumption) contrastive하게 학습할 수 있도록 loss를 추가해주었다. : \(\mathcal{L}_{\text {constraint }}=-\sum_{\mathbf{s} \in \mathcal{S}}\left(\sum_{\mathbf{s}^{\prime} \in \mathcal{S}^{+}} \log \frac{\exp \left(\mathbf{R}_{\mathbf{s}, \mathbf{s}^{\prime}} / \tau\right)}{\sum_{\mathbf{s}^{\prime \prime} \in \mathcal{S} \backslash\{\mathbf{s}\}} \exp \left(\mathbf{R}_{\mathbf{s}, \mathbf{s}^{\prime \prime}} / \tau\right)}\right)\)</li>
  <li>SimMTM의 overall optimization loss는 다음과 같다 : \(\min _{\Theta} \mathcal{L}_{\text {reconstruction }}+\lambda \mathcal{L}_{\text {constraint }}\)
    <ul>
      <li>\(\mathcal{L}_{\text {constraint }}\)이 trivial aggregation이 발생하는 것에 대한 regularization 역할을 한다.</li>
    </ul>
  </li>
</ul>

<h2 id="4-experiments">4. Experiments</h2>
<p><img src="/assets/img/timeseries/SimMTM/table1.jpeg" alt="사진4" /></p>
<ul>
  <li>Low-level downstream task인 forecasting, high-level downstream task인 classification을 수행하였다.</li>
  <li>비교한 SOTA 모델들
    <ul>
      <li>contrastive learning methd : TF-C, CoST, TS2Vec, LaST</li>
      <li>masked modeling method : <strong>Ti-MAE</strong>, TST, TF-C
<img src="/assets/img/timeseries/SimMTM/fig3.png" alt="사진5" /></li>
      <li>(x-axis) 왼쪽에 있을수록 MSE가 낮고, (y-axis) 위쪽에 있을수록 Accuracy가 높다.</li>
    </ul>
  </li>
  <li><img src="/assets/img/timeseries/SimMTM/table2.png" alt="사진6" /></li>
  <li><img src="/assets/img/timeseries/SimMTM/table3.png" alt="사진7" /></li>
  <li><img src="/assets/img/timeseries/SimMTM/table4.png" alt="사진8" />
    <ul>
      <li>SimMTM은 학습 데이터와 테스트 데이터가 다른 cross-domain setting에서도 forecasting과 classification 모두 다른 모델보다 뛰어나기 때문에 좋은 baseline 모델이라 할 수 있다.</li>
    </ul>
  </li>
  <li><img src="/assets/img/timeseries/SimMTM/fig4.png" alt="사진9" />
    <ul>
      <li>\(\min _{\Theta} \mathcal{L}_{\text {reconstruction }}+\lambda \mathcal{L}_{\text {constraint }}\) 두 항 모두 loss term에 있을 때에 성능이 더 좋았다.</li>
    </ul>
  </li>
  <li><img src="/assets/img/timeseries/SimMTM/fig5.png" alt="사진10" />
    <ul>
      <li>(left) SimMTM은 학습의 effectiveness가 다른 모델보다 높다. 즉 적은 데이터만으로도 valuable knowledge를 잘 파악한다.</li>
      <li>(right) SimMTM에서 masked ratio가 높을수록 많은 multiple masked series를 만들 때 성능이 높다는 직관과 부합하는 결과이다.</li>
    </ul>
  </li>
</ul>

<h2 id="5-conclusion">5. Conclusion</h2>
<ul>
  <li>SimMTM은 new masked modeling 방법을 제시
    <ul>
      <li>reconstructs the original series from its multiple neighbor masked series</li>
      <li>aggregates the point-wise representations based on the series-wise similarities</li>
    </ul>
  </li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[NeurIPS 2023](https://arxiv.org/abs/2302.00861)]]></summary></entry><entry><title type="html">MCMC with Implementation (2) : Gibbs Sampling</title><link href="http://localhost:4000/stat/2024-03-06-gibbs/" rel="alternate" type="text/html" title="MCMC with Implementation (2) : Gibbs Sampling" /><published>2024-03-06T00:00:00+09:00</published><updated>2024-03-06T19:08:49+09:00</updated><id>http://localhost:4000/stat/gibbs</id><content type="html" xml:base="http://localhost:4000/stat/2024-03-06-gibbs/"><![CDATA[<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>만약 sampling하고자 하는 parameter의 full conditional distribution을 알 수 있다면 Gibbs sampler를 사용할 수 있다.</li>
  <li>Gibbs sampler는 MH-algorithm의 special case라고 할 수 있다.
    <ul>
      <li>Acceptance rate = 1이 되어 accept/reject 과정이 없다.</li>
    </ul>
  </li>
  <li><strong>Full conditional distribution</strong> : 만약 model parameters가 \(\mathbf{\theta}=\left(\theta_1, \cdots, \theta_k\right)\)이라면, full conditional distribution은 \(\pi\left(\theta_i \mid \theta_1, \cdots, \theta_{i-1}, \theta_{i+1}, \cdots, \theta_k, \mathbf{X}\right)\)이다. 즉 다른 parameters는 모두 given일 때 관심있는 parameter의 분포를 의미한다.</li>
  <li>정확히는 full conditional distribution이 모두 closed-form이어야 한다. 즉 k개의 conditional distributions가 standard한 분포(Normal, Gamma, …)를 따른다.</li>
  <li>그러므로 Gibss sampling 방식은 k개의 parameters로 이루어지는 확률변수 \(\mathbf{\theta}\)를 sampling을 할 때 k개 parameters를 한 번에 sampling하는 것이 아니라, 하나씩 sampling한 다음 k개를 모아서 하나의 sample로 만든다.
    <ul>
      <li>
        <ol>
          <li>Choose starting values \(\mathbf{\theta}=\left(\theta_1^{(1)}, \cdots, \theta_k^{(1)}\right)\)</li>
        </ol>
      </li>
      <li>
        <ol>
          <li>For \(i=2, \cdots, T\) sample <br />
\(\begin{aligned}
&amp; \theta_1^{(i)} \mid \theta_2^{(i-1)}, \cdots, \theta_k^{(i-1)}, \mathbf{X} \\
&amp; \theta_2^{(i)} \mid \theta_1^{(i)}, \theta_3^{(i-1)}, \cdots, \theta_k^{(i-1)}, \mathbf{X} \\
&amp; \theta_k^{(i)} \mid \theta_1^{(i)}, \cdots, \theta_{k-1}^{(i)}, \mathbf{X}
\end{aligned}\)</li>
        </ol>
      </li>
    </ul>
  </li>
  <li>주의할 점은 \(\theta_2^{(i)}\)를 sampling할 때에는 아직 sampling하지 않은 \(\theta_3^{(i)}\)부터 \(\theta_k^{(i)}\)까지는 이전 시점의 값을 사용하지만, 이미 sampling을 한 \(\theta_1^{(i)}\)은 sampling한 값을 사용한다는 점이다.</li>
</ul>

<h2 id="2-full-conditional-distribution-for-gibb-sampler">2. Full conditional distribution for Gibb Sampler</h2>
<ul>
  <li>다음과 같은 간단한 Bayse rule을 보자. \(P(A \mid B)=\frac{P(A, B)}{P(B)}=\frac{P(A, B)}{P(A)} \times \frac{P(A)}{P(B)}=P(B \mid A) \times \frac{P(A)}{P(B)}\)
    <ul>
      <li>A를 sampling할 parameters, B를 주어진 데이터라고 하면 \(P(B \mid A)\)는 likelihood이고, \(P(A)\)는 prior가 된다. 그리고 \(P(B)\)는 주어진 상수가 되어 고려하지 않아도 된다. 왜냐하면 결국 A가 바뀔 때 posterior \(P(A \mid B)\)의 대소관계가 궁금하기 때문이다.</li>
      <li>그러므로 \(\text{posterior} \propto \text{likelihood} \times \text{prior}\) 관계가 성립한다.</li>
    </ul>
  </li>
</ul>

<h2 id="3-r-implementation-of-gibb-sampler">3. R Implementation of Gibb Sampler</h2>

<h3 id="31-ex1--bayesian-linear-regression">3.1. Ex.1 : Bayesian Linear Regression</h3>
<p>\(\begin{gathered}
Y_i=\beta_0+\beta_1 X_{1, i}+\beta_2 X_{2, i}+\beta_3 X_{1, i} X_{2, i}+\epsilon_i  \\
\text{where } \epsilon_i \sim N\left(0, \sigma^2\right) \text{independently for } i=1, \cdots, 300,000 \\
\text{We will use independent priors as} \\
\beta_j \sim N(0,10) \text { for } j=0,1,2,3 \\
\sigma^2 \sim \operatorname{IG}(0.01,0.01)
\end{gathered}\)</p>
<ul>
  <li>위 모형에서 임의의 parameters로 데이터를 생성하고, Gibbs sampler가 생성한 parameters samples와 임의로 정한 parameters를 비교한다.</li>
  <li><strong>Simulation the dataset</strong>
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># the size of dataset</span><span class="w">
</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">300000</span><span class="w">

</span><span class="c1"># Simulating (X_1,1, ..., X_1,n) and (X_2,1, ..., X_2,n) ~ N(0,1)</span><span class="w">
</span><span class="n">X</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mvrnorm</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">mu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w"> </span><span class="n">Sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="m">2</span><span class="p">))</span><span class="w">
  
</span><span class="c1"># Setting the true parameters (beta)</span><span class="w">
</span><span class="n">beta.true</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">-1</span><span class="p">)</span><span class="w">

</span><span class="c1"># Simulating (Y_1, ..., Y_n) using the design matrix for above model</span><span class="w">
</span><span class="n">X_design</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cbind</span><span class="p">(</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="p">[,</span><span class="m">1</span><span class="p">]</span><span class="o">*</span><span class="n">X</span><span class="p">[,</span><span class="m">2</span><span class="p">]</span><span class="w"> </span><span class="p">)</span><span class="w">
</span><span class="n">Y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">X_design</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">beta.true</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><strong>Calculation the full conditional distribution</strong>
    <ul>
      <li>For \(\beta\), the kernel of posterior for Gibbs sampler is following :
\(\begin{aligned}
&amp; P\left(\beta \mid Y, X, \sigma^2\right) \propto L\left(Y, X \mid \beta, \sigma^2\right) P(\beta) \\
&amp; \propto\left(\frac{1}{\sqrt{2 \pi}}\right)^n\left(\frac{1}{\operatorname{det}\left(\sigma^2 I\right)}\right)^{\frac{1}{2}} \exp \left(-\frac{(Y-X \beta)^{\top}(Y-X \beta)}{2 \sigma^2}\right)\left(\frac{1}{\sqrt{2 \pi}}\right)^p\left(\frac{1}{\operatorname{det}(10 I)}\right)^{\frac{1}{2}} \exp \left(-\frac{\beta^{\top} \beta}{20}\right) \\
&amp; \propto \exp \left(-\frac{(Y-X \beta)^{\top}(Y-X \beta)}{2 \sigma^2}-\frac{\beta^{\top} \beta}{20}\right) \\
&amp; =\exp \left(-\frac{1}{2 \sigma^2} Y^{\top} Y+\frac{1}{2 \sigma^2} Y^{\top} X \beta+\frac{1}{2 \sigma^2} \beta^{\top} X Y-\frac{\beta^{\top} X^{\top} X \beta}{2 \sigma^2}-\frac{\beta^{\top} \beta}{20}\right) \\
&amp; =\exp \left(-\frac{1}{2}\left(\beta^{\top}\left(\frac{X^{\top} X}{\sigma^2}+\frac{I}{10}\right) \beta-\beta^{\top}\left(\frac{X^{\top} Y}{\sigma^2}\right)-\left(\frac{Y^{\top} X}{\sigma^2}\right) \beta+\frac{Y^{\top} Y}{6^2}\right)\right) \\
&amp; \therefore V_\beta=\left[\frac{X^{\top} X}{\sigma^2}+\frac{I}{10}\right]^{-1}, \quad m_\beta=V_\beta \frac{X^{\top} Y}{\sigma^2} \\
&amp; \beta \sim N\left(m_\beta, V_\beta\right) \\
\end{aligned}\)</li>
    </ul>
  </li>
  <li>For \(\sigma^2\), the kernel of posterior for Gibbs sampler is following :
\(\begin{aligned}
P\left(\sigma^2 \mid, \beta\right) &amp; \propto L\left(Y, X \mid \beta, \sigma^2\right) P\left(\sigma^2\right) \\
&amp; \propto\left(\frac{1}{\sigma \sqrt{2 \pi}}\right)^n \exp \left(-\frac{(Y-X \beta)^{\top}(Y-X \beta)}{2 \sigma^2}\right) \frac{\beta^\alpha}{\Gamma(\alpha)}\left(\frac{1}{\sigma^2}\right)^{\alpha+1} \exp \left(-\frac{\beta}{\sigma^2}\right) \\
&amp; \propto\left(\frac{1}{\sigma^2}\right)^{\frac{n}{2}+\alpha+1} \exp \left(-\frac{\beta+\frac{1}{2}(Y-X \beta)^{\top}(Y-X \beta)}{\sigma^2}\right) \\
&amp; \\
&amp; \therefore \alpha_{\sigma^2}=\frac{n}{2}+\alpha, \quad \beta_{\sigma^2}=\beta+\frac{1}{2}(Y-X \beta)^{\top}(Y-X \beta) \\
&amp; \sigma^2 \sim I G\left(\alpha_{\sigma^2}, \beta_{\sigma^2}\right)
\end{aligned}\)
    <ul>
      <li>위 결과를 바탕으로 sampling하는 R 코드를 작성한다.</li>
    </ul>

    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># the number of variates</span><span class="w">
</span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ncol</span><span class="p">(</span><span class="n">X_design</span><span class="p">)</span><span class="w">

</span><span class="c1"># The prior parameters</span><span class="w">
</span><span class="n">m.beta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0</span><span class="p">;</span><span class="w"> </span><span class="n">v.beta</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="n">a.s2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.01</span><span class="p">;</span><span class="w"> </span><span class="n">b.s2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">0.01</span><span class="w">
  
</span><span class="c1"># 각각의 parameters를 1000개씩 sampling한다.</span><span class="w">
</span><span class="n">B</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="w">

</span><span class="c1"># sample space with initialization for each parameters</span><span class="w">
</span><span class="n">beta.samps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">B</span><span class="p">)</span><span class="w">
</span><span class="n">s2.samps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">nrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">B</span><span class="p">)</span><span class="w">
</span><span class="n">beta.samps</span><span class="p">[,</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="n">p</span><span class="p">)</span><span class="w">
</span><span class="n">s2.samps</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1</span><span class="w">

</span><span class="c1"># Gibbs sampler</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">2</span><span class="o">:</span><span class="n">B</span><span class="p">){</span><span class="w">
    
  </span><span class="c1">## beta[i] | s2[i-1]</span><span class="w">
  </span><span class="n">V</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">solve</span><span class="p">(</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">X_design</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">X_design</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">s2.samps</span><span class="p">[</span><span class="n">i</span><span class="m">-1</span><span class="p">]</span><span class="o">+</span><span class="w"> </span><span class="n">diag</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">v.beta</span><span class="w"> </span><span class="p">)</span><span class="w">
  </span><span class="n">m</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">V</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">X_design</span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">Y</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">s2.samps</span><span class="p">[</span><span class="n">i</span><span class="m">-1</span><span class="p">]</span><span class="w"> </span><span class="p">)</span><span class="w">
  </span><span class="n">beta.samps</span><span class="p">[,</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rmvnorm</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">V</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"svd"</span><span class="p">)</span><span class="w">
    
  </span><span class="c1"># s2[i] | beta[i]</span><span class="w">
  </span><span class="n">a</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">n</span><span class="o">/</span><span class="m">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a.s2</span><span class="w">
  </span><span class="n">b</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">b.s2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="w"> </span><span class="n">Y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">X_design</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">beta.samps</span><span class="p">[,</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="n">Y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">X_design</span><span class="w"> </span><span class="o">%*%</span><span class="w"> </span><span class="n">beta.samps</span><span class="p">[,</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">2</span><span class="w">
  </span><span class="n">s2.samps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rinvgamma</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="o">=</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">scale</span><span class="o">=</span><span class="n">b</span><span class="p">)</span><span class="w">
  </span><span class="n">s2.samps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">t</span><span class="p">(</span><span class="n">s2.samps</span><span class="p">)</span><span class="w">
</span><span class="p">}</span><span class="w">
  </span><span class="c1"># burn-in</span><span class="w">
  </span><span class="n">beta.samps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">beta.samps</span><span class="p">[,</span><span class="m">51</span><span class="o">:</span><span class="n">B</span><span class="p">]</span><span class="w">
  </span><span class="n">s2.samps</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">s2.samps</span><span class="p">[</span><span class="m">51</span><span class="o">:</span><span class="n">B</span><span class="p">]</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li><strong>Checking the Samples</strong>
    <ul>
      <li>density plot, trace plot 등 다양한 tools를 활용하여 결과를 확인해야 하지만, posterior mean(samples의 평균)만 확인한다. 상당히 정확하게 sampling 되었다는 것을 알 수 있다.</li>
    </ul>

    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># posterior mean</span><span class="w">
</span><span class="n">cat</span><span class="p">(</span><span class="s2">"posterior mean of beta0:"</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">1</span><span class="p">,]),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"posterior mean of beta1:"</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">2</span><span class="p">,]),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"posterior mean of beta2:"</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">3</span><span class="p">,]),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"posterior mean of beta3:"</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">4</span><span class="p">,]),</span><span class="w"> </span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"posterior mean of sigma2:"</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">s2.samps</span><span class="p">)</span><span class="w"> </span><span class="p">)</span><span class="w">

</span><span class="c1">##### result #####</span><span class="w">
</span><span class="c1">## posterior mean of beta0: 0.4976068</span><span class="w">
</span><span class="c1">##  posterior mean of beta1: 0.9989775</span><span class="w">
</span><span class="c1">##  posterior mean of beta2: 2.00346</span><span class="w">
</span><span class="c1">##  posterior mean of beta3: -1.00101</span><span class="w">
</span><span class="c1">##  posterior mean of sigma2: 0.9986912</span><span class="w">
</span></code></pre></div>    </div>
    <ul>
      <li>Gibbs Sampler는 proposed sample이 항상 accept된다는 점에서 MH-algorithm의 speecial case라고 할 수 있다. samples의 unique value의 개수와 B=1000의 비율을 출력한다.</li>
    </ul>

    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># acceptance ratio</span><span class="w">
</span><span class="c1"># (Because I used Gibbs sampler, samples was always accepted !)</span><span class="w">
</span><span class="n">cat</span><span class="p">(</span><span class="s2">"Acceptance ratio of beta0 :"</span><span class="p">,</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">unique</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">1</span><span class="p">,]))</span><span class="o">/</span><span class="n">B</span><span class="w"> </span><span class="p">,</span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Acceptance ratio of beta1 :"</span><span class="p">,</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">unique</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">2</span><span class="p">,]))</span><span class="o">/</span><span class="n">B</span><span class="w"> </span><span class="p">,</span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Acceptance ratio of beta2 :"</span><span class="p">,</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">unique</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">3</span><span class="p">,]))</span><span class="o">/</span><span class="n">B</span><span class="w"> </span><span class="p">,</span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Acceptance ratio of beta3 :"</span><span class="p">,</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">unique</span><span class="p">(</span><span class="n">beta.samps</span><span class="p">[</span><span class="m">4</span><span class="p">,]))</span><span class="o">/</span><span class="n">B</span><span class="w"> </span><span class="p">,</span><span class="s2">"\n"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Acceptance ratio of sigma2 :"</span><span class="p">,</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">unique</span><span class="p">(</span><span class="n">s2.samps</span><span class="p">))</span><span class="o">/</span><span class="n">B</span><span class="w"> </span><span class="p">)</span><span class="w">
  
</span><span class="c1">##### result #####</span><span class="w">
</span><span class="c1">## Acceptance ratio of beta0 : 0.95</span><span class="w">
</span><span class="c1">##  Acceptance ratio of beta1 : 0.95</span><span class="w">
</span><span class="c1">##  Acceptance ratio of beta2 : 0.95</span><span class="w">
</span><span class="c1">##  Acceptance ratio of beta3 : 0.95</span><span class="w">
</span><span class="c1">##  Acceptance ratio of sigma2 : 0.95</span><span class="w">
</span></code></pre></div>    </div>
    <ul>
      <li>앞서 burn-in으로 각 parameters에서 50개의 samples를 버린 것을 감안하면 sample가 항상 accept되었음을 알 수 있다. (acceptance probabilties = 1)
        <ul>
          <li>Acceptance probabilies는 각 proposed sample이 accept될 확률이고</li>
          <li>Acceptance ratio는 전체 sampling 횟수 중에서 accept된 비율을 의미한다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="32-ex2--truncated-exponential-distribution">3.2. Ex.2 : Truncated Exponential distribution</h3>
<ul>
  <li>to be continued…</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="stat" /><summary type="html"><![CDATA[1. Introduction 만약 sampling하고자 하는 parameter의 full conditional distribution을 알 수 있다면 Gibbs sampler를 사용할 수 있다. Gibbs sampler는 MH-algorithm의 special case라고 할 수 있다. Acceptance rate = 1이 되어 accept/reject 과정이 없다. Full conditional distribution : 만약 model parameters가 \(\mathbf{\theta}=\left(\theta_1, \cdots, \theta_k\right)\)이라면, full conditional distribution은 \(\pi\left(\theta_i \mid \theta_1, \cdots, \theta_{i-1}, \theta_{i+1}, \cdots, \theta_k, \mathbf{X}\right)\)이다. 즉 다른 parameters는 모두 given일 때 관심있는 parameter의 분포를 의미한다. 정확히는 full conditional distribution이 모두 closed-form이어야 한다. 즉 k개의 conditional distributions가 standard한 분포(Normal, Gamma, …)를 따른다. 그러므로 Gibss sampling 방식은 k개의 parameters로 이루어지는 확률변수 \(\mathbf{\theta}\)를 sampling을 할 때 k개 parameters를 한 번에 sampling하는 것이 아니라, 하나씩 sampling한 다음 k개를 모아서 하나의 sample로 만든다. Choose starting values \(\mathbf{\theta}=\left(\theta_1^{(1)}, \cdots, \theta_k^{(1)}\right)\) For \(i=2, \cdots, T\) sample \(\begin{aligned} &amp; \theta_1^{(i)} \mid \theta_2^{(i-1)}, \cdots, \theta_k^{(i-1)}, \mathbf{X} \\ &amp; \theta_2^{(i)} \mid \theta_1^{(i)}, \theta_3^{(i-1)}, \cdots, \theta_k^{(i-1)}, \mathbf{X} \\ &amp; \theta_k^{(i)} \mid \theta_1^{(i)}, \cdots, \theta_{k-1}^{(i)}, \mathbf{X} \end{aligned}\) 주의할 점은 \(\theta_2^{(i)}\)를 sampling할 때에는 아직 sampling하지 않은 \(\theta_3^{(i)}\)부터 \(\theta_k^{(i)}\)까지는 이전 시점의 값을 사용하지만, 이미 sampling을 한 \(\theta_1^{(i)}\)은 sampling한 값을 사용한다는 점이다.]]></summary></entry><entry><title type="html">MCMC with Implementation (1) : Metropolis Hastings algorithm</title><link href="http://localhost:4000/stat/2024-03-04-mcmc/" rel="alternate" type="text/html" title="MCMC with Implementation (1) : Metropolis Hastings algorithm" /><published>2024-03-04T00:00:00+09:00</published><updated>2024-03-07T15:13:15+09:00</updated><id>http://localhost:4000/stat/mcmc</id><content type="html" xml:base="http://localhost:4000/stat/2024-03-04-mcmc/"><![CDATA[<h2 id="1-probabilistic-ml-model">1. Probabilistic ML Model</h2>
<ul>
  <li>\(x\) : set of observed variables <br />
\(y\) : set of hidden / latent variables <br />
\(\theta\) : model parameters</li>
  <li>
    <p>Discriminative probabilistic ML model</p>

    <ul>
      <li>\(p(Y \mid X)\) : 데이터 \(X\)가 주어졌을 때 결과 \(y\) 예측하기 (Classification, Regression, …)</li>
    </ul>
  </li>
  <li>
    <p>Generative probabilistic ML model</p>

    <ul>
      <li>Bayes Theorem : \(p(Y \mid X)=\frac{p(X, Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{\int p(X \mid Y) p(Y) d Y}\)
<img src="/assets/img/stat/vi/fig1.png" alt="그림1" /></li>
    </ul>
  </li>
  <li>Discriminative model은 클래스(y) 사이의 차이를 의미하는 decision boundary를 학습하고, (\(p(Y\mid X)\))
Generative model은 분포 \(p(X), p(X,Y)\)를 학습하여 posterior \(p(Y\mid X)\)를 추정한다.</li>
  <li>\(Y\)의 차원이 높아질수록 분모에 있는 \(Y\)에 대한 적분이 어려워지기 때문에(intractable), 아래 두 가지 방법으로 \(p(Y\mid X)\)를 추정한다.
    <ul>
      <li>Variational Inference (optimization)</li>
      <li>Markov chain Monte Carlo (sampling)</li>
      <li>MCMC는 분포를 근사하기 위해 sampling으로 inference하는 것이고, VI는 분포를 근사하기 위해 optimization 문제로 바꾼 것이다.</li>
      <li>일반적으로 VI는 빠르고, MCMC는 정확하다.(상대적으로 그렇다는 것)</li>
    </ul>
  </li>
</ul>

<h2 id="2-markov-chain-monte-carlo">2. Markov Chain Monte Carlo</h2>
<h3 id="21-the-properties-of-mc">2.1. The properties of MC</h3>
<ul>
  <li><strong>Markov Chain</strong> : \(\operatorname{Pr}\left\{X_{t+1}=j_{t+1} \mid X_t=j_t, X_{t-1}=j_{t-1}, \cdots, X_0=j_0\right\} = \operatorname{Pr}\left\{X_{t+1}=j_{t+1} \mid X_t=j_t\right\}\)</li>
  <li><strong>Transition probability</strong> : \(\mathbf{P}=\left(\left(p_{i j}\right)\right) ; \quad \operatorname{Pr}\left\{X_t=j \mid X_0=i\right\}=\left(\mathbf{P}^t\right)_{i j}\) <br />
where \(p_{i j}=\operatorname{Pr}\left\{X_{t+1}=j \mid X_t=i\right\}\)
<img src="/assets/img/stat/mcmc/fig1.jpeg" alt="그림2" /></li>
  <li><strong>Irreducible</strong> : \(\left(\mathbf{P}^t\right)_{i j}=\operatorname{Pr}\left\{X_t=j \mid X_0=i\right\}&gt;0\) for some \(t&gt;0, and all $i$ and $j$ in $\Omega$.\)
    <ul>
      <li>현재 state가 무엇이든, 모든 state에 언젠가는 도달할 수 있어야 한다.</li>
      <li>Markov Chain이 irreducible하면 unique한 stationary probabilities를 가진다. <br />
i.e. \(\pi_j=\lim _{n \rightarrow \infty} \frac{1}{n} \sum_{t=1}^n I\left(X_t=j\right) \text { w.p.1 for all initial states}\)</li>
      <li>Indicator의 expectation은 probability이므로 \(\pi_j=\lim _{n \rightarrow \infty} \frac{1}{n} \sum_{t=1}^n \operatorname{Pr}\left\{X_t=j \mid X_0=i\right\}, \text { for all initial states}\)</li>
    </ul>
  </li>
  <li><strong>Aperiodic</strong> : \(\operatorname{Pr}\left\{X_t=j \mid X_0=j\right\}&gt;0 \text { and } \operatorname{Pr}\left\{X_{t+1}=j \mid X_0=j\right\}&gt;0\)
    <ul>
      <li>주기가 없다는 것을 수학적으로 표현하면 위와 같다. Irreducible한 Markov Chain이 하나 이상의 self-loop를 가진다면 aperiodic하다.</li>
    </ul>
  </li>
  <li><strong>Time-reversible</strong> : \(\pi_i p_{i j}=\pi_j p_{j i}, \quad \forall i \neq j\)
    <ul>
      <li><code class="language-plaintext highlighter-rouge">i에 도달하고 i에서 j가 될 확률</code>과 <code class="language-plaintext highlighter-rouge">j에 도달하고 j에서 i가 될 확률</code>이 같다는 의미</li>
    </ul>
  </li>
  <li>많은 경우의 Markov Chains는 irreducible, aperiodic, time-reversible하다.</li>
  <li>결국 하고자 하는 것은 \(E[h(X)]=\sum_{j=1}^N h(j) \pi_j\)를 \(\frac{1}{n} \sum_{t=1}^n h\left(X_t\right)\)로 추정하는 것이다.</li>
</ul>

<h3 id="22-metropolis-hastings-algorithm">2.2. Metropolis-Hastings algorithm</h3>
<ul>
  <li>Goal : (MCMC를 왜 할까?)
    <ul>
      <li>\(X \sim F\) with density f를 sampling하고 싶은데 independent sampling이 불가능하기 때문에 최대한 independent한 samples를 만드는 것</li>
    </ul>
  </li>
  <li>\(F\)로부터 직접 sampling하기 어려운 경우에, sampling이 쉬운 proposal density \(q(x' \mid x)\)에서 propose</li>
  <li>\(q(x' \mid x)\)에서의 proposed sample은 \(\alpha=\min \left(\frac{f\left(x^{\prime}\right) q\left(x \mid x^{\prime}\right)}{f(x) q\left(x^{\prime} \mid x\right)}, 1\right)\)확률로 sample에 추가, 아니면 stay \(x\)</li>
  <li>정리하면
    <ul>
      <li>Step1. Proposal density \(q(x' \mid x)\)를 선택한다.</li>
      <li>Step2. 적당한 initial state \(X_0 = x_0\)를 정한다.</li>
      <li>
        <p>Step3. \(X' \sim q(x' \mid X_t)\)와 \(U \sim Unif(0,1)\)을 생성한다.</p>
      </li>
      <li>Step4. \(U&lt;\frac{f\left(X^{\prime}\right) q\left(X_t \mid X^{\prime}\right)}{f\left(X_t\right) q\left(X^{\prime} \mid X_t\right)}, \text { then } X_{t+1}=X^{\prime} . \text { Else } X_{t+1}=X_t\)</li>
      <li>Step5. \(t = t + 1\), Go to Step3</li>
    </ul>
  </li>
  <li>이 때 proposal density가 symmetric density이면 \(\frac{q\left(X_t \mid X^{\prime}\right)}{q\left(X^{\prime} \mid X_t\right)}=1\)이 되어 계산할 필요가 없어진다.</li>
  <li><img src="/assets/img/stat/mcmc/fig2.png" alt="그림3" /></li>
  <li>예를 들어, MCMC로 생성한 samples의 trace plot이 위와 같다면 target distribution은 \((-2,2)\)에서 높은 density를 갖는다는 것을 알 수 있고, initial state와 무관하게 빠르게 수렴하는 것을 볼 수 있다.</li>
</ul>

<h2 id="3-r-implementation--mh-algorithm">3. R Implementation : MH-algorithm</h2>
<ul>
  <li>예시를 통해 MH-algorithm을 구현해본다.
    <ul>
      <li>Target density : \(g(x)=\exp \left(-(x+1)^2-y^2\right)+\exp \left(-150\left(x^2-y\right)^2-150\left(x-y^2\right)^2\right)\)
        <ul>
          <li>복잡한 un-normalized density이므로 직접 sampling하기가 어렵기 때문에 MH-algorithm으로 sampling한다.</li>
        </ul>
      </li>
      <li>Proposal distribution : \(\left(\begin{array}{l} x_{new} \\ y_{new} \end{array}\right) \sim N\left(\left(\begin{array}{l} x_{now} \\ y_{now} \end{array}\right), \sigma^2\left(\begin{array}{ll} 1 &amp; \rho \\ \rho &amp; 1 \end{array}\right)\right)\) where \(\sigma^2 &gt; 0, \rho \in (-1,1)\)’</li>
    </ul>
  </li>
  <li>먼저 target density를 visualization해서 파악한다.</li>
  <li>
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">g</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">exp</span><span class="p">(</span><span class="m">-150</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">150</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="o">^</span><span class="m">2</span><span class="p">)}</span><span class="w">

</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">-3</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">);</span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">-2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">)</span><span class="w">
</span><span class="n">z</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">outer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">g</span><span class="p">)</span><span class="w">
</span><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="w">
</span><span class="n">contour</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"X"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Y"</span><span class="p">,</span><span class="w">
        </span><span class="n">main</span><span class="o">=</span><span class="s2">"The contour plot of density g"</span><span class="p">)</span><span class="w">
</span></code></pre></div>    </div>
    <p><img src="/assets/img/stat/mcmc/fig3.png" alt="그림4" /></p>
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">))</span><span class="w">
</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">-3</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">);</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">seq</span><span class="p">(</span><span class="m">-2</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">length.out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">)</span><span class="w">
</span><span class="n">z</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">outer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">g</span><span class="p">)</span><span class="w">
</span><span class="n">res1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">persp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="n">theta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">,</span><span class="w"> </span><span class="n">phi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">expand</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w">
              </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"green"</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"X"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Y"</span><span class="p">,</span><span class="w"> </span><span class="n">zlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Z"</span><span class="p">,</span><span class="w">
              </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"The density plot of g"</span><span class="p">)</span><span class="w">
</span><span class="n">res2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">persp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="n">theta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">70</span><span class="p">,</span><span class="w"> </span><span class="n">phi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">expand</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w">
              </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"green"</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"X"</span><span class="p">,</span><span class="w"> </span><span class="n">ylab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Y"</span><span class="p">,</span><span class="w"> </span><span class="n">zlab</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Z"</span><span class="p">,</span><span class="w">
              </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"The density plot of g"</span><span class="p">)</span><span class="w">
</span></code></pre></div>    </div>
    <p><img src="/assets/img/stat/mcmc/fig4.png" alt="그림5" /></p>
  </li>
  <li>MH-algorithm을 함수로 작성한다.
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MCMC.MH</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">init</span><span class="p">,</span><span class="w"> </span><span class="n">sigma</span><span class="p">,</span><span class="w"> </span><span class="n">rho</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  
</span><span class="c1">############################################################</span><span class="w">
</span><span class="c1"># n : sample size</span><span class="w">
</span><span class="c1"># init : starting value (initialization)</span><span class="w">
</span><span class="c1"># sigma, rho : parameters for covariance matrix of proposal distribution</span><span class="w">
</span><span class="c1">############################################################</span><span class="w">

</span><span class="c1"># sample space for x, y</span><span class="w">
</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rep</span><span class="p">(</span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w">

</span><span class="c1"># initialization</span><span class="w">
</span><span class="n">x</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">init</span><span class="p">[</span><span class="m">1</span><span class="p">];</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">init</span><span class="p">[</span><span class="m">2</span><span class="p">]</span><span class="w">
  
</span><span class="c1"># run the loop until sample space is full</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">2</span><span class="o">:</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">

  </span><span class="c1"># 현재값(=current, =now)이 new x, new y의 분포를 결정한다. (Markov chain의 property)</span><span class="w">
  </span><span class="n">current</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="m">-1</span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="m">-1</span><span class="p">])</span><span class="w">

  </span><span class="c1"># Proposed sample</span><span class="w">
  </span><span class="n">proposal</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rmvnorm</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">current</span><span class="p">,</span><span class="w">
                         </span><span class="n">sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">rho</span><span class="p">,</span><span class="w"> </span><span class="n">rho</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">sigma</span><span class="o">^</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">ncol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">))</span><span class="w">

  </span><span class="c1"># Accept probability</span><span class="w">
  </span><span class="c1"># Note: Proposal function이 normal(symmetric)이므로 q항이 약분된다.                       </span><span class="w">
  </span><span class="n">a</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">g</span><span class="p">(</span><span class="n">proposal</span><span class="p">[</span><span class="m">1</span><span class="p">],</span><span class="w"> </span><span class="n">proposal</span><span class="p">[</span><span class="m">2</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">g</span><span class="p">(</span><span class="n">current</span><span class="p">[</span><span class="m">1</span><span class="p">],</span><span class="w"> </span><span class="n">current</span><span class="p">[</span><span class="m">2</span><span class="p">])</span><span class="w">
    
  </span><span class="c1"># Accept or Reject</span><span class="w">
  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">runif</span><span class="p">(</span><span class="m">1</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">a</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">proposal</span><span class="p">[</span><span class="m">1</span><span class="p">];</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">proposal</span><span class="p">[</span><span class="m">2</span><span class="p">]}</span><span class="w">
  </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">current</span><span class="p">[</span><span class="m">1</span><span class="p">];</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">current</span><span class="p">[</span><span class="m">2</span><span class="p">]}}</span><span class="w">

</span><span class="c1"># when sample space is full, we will return  </span><span class="w">
</span><span class="nf">return</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">))}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li>이제 MCMC를 실행하고 결과를 본다.
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1e6</span><span class="w">
</span><span class="n">samples.1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MCMC.MH</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">init</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">-10</span><span class="p">,</span><span class="w"> </span><span class="m">-10</span><span class="p">),</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">,</span><span class="w"> </span><span class="n">rho</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">)</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">samples.1</span><span class="o">$</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Scatter plot of x and y"</span><span class="p">,</span><span class="w"> </span><span class="n">pch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">)</span><span class="w">
</span></code></pre></div>    </div>
    <p><img src="/assets/img/stat/mcmc/fig5.png" alt="그림6" /></p>
    <ul>
      <li>생성된 samples가 점점 target density가 높은 방향으로 움직인다.</li>
    </ul>
  </li>
  <li>Density plot가 target density와 비슷한지, trace plot으로 chain이 잘 수렴하는지, acf plot으로 얼마나 dependent한지 눈으로 확인할 수 있다.
    <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># density plot</span><span class="w">
</span><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">))</span><span class="w">
</span><span class="n">hist</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Histogram of x"</span><span class="p">,</span><span class="w"> </span><span class="n">freq</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="o">=</span><span class="m">100</span><span class="p">)</span><span class="w">
</span><span class="n">hist</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Histogram of y"</span><span class="p">,</span><span class="w"> </span><span class="n">freq</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">breaks</span><span class="o">=</span><span class="m">100</span><span class="p">)</span><span class="w">

</span><span class="c1"># trace plot</span><span class="w">
</span><span class="n">ts.plot</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Trace plot of x"</span><span class="p">)</span><span class="w">
</span><span class="n">ts.plot</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Trace plot of y"</span><span class="p">)</span><span class="w">

</span><span class="c1"># acf plot</span><span class="w">
</span><span class="n">acf</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Autocorrelation of x"</span><span class="p">)</span><span class="w">
</span><span class="n">acf</span><span class="p">(</span><span class="n">samples.1</span><span class="o">$</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Autocorrelation of y"</span><span class="p">)</span><span class="w">
</span></code></pre></div>    </div>
    <p><img src="/assets/img/stat/mcmc/fig6.jpg" alt="그림7" /></p>
  </li>
  <li>Tuning :
    <ul>
      <li>initial point가 (-10, 10)이므로 x와 y가 모두 커져야 target density가 높은 방향으로 움직인다.
        <ul>
          <li>\(rho&gt;0\)으로 설정</li>
        </ul>
      </li>
      <li>initial point가 target density가 높은 곳과 멀리 떨어져있다
        <ul>
          <li>\(sigma &gt;&gt; 0.1\)으로 설정</li>
        </ul>
      </li>
      <li>결과는 아래와 같다.
        <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">samples.4</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">MCMC.MH</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">init</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">-10</span><span class="p">,</span><span class="w"> </span><span class="m">-10</span><span class="p">),</span><span class="w"> </span><span class="n">sigma</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">rho</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.8</span><span class="p">)</span><span class="w">
</span><span class="n">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">1</span><span class="p">))</span><span class="w">
</span><span class="n">plot</span><span class="p">(</span><span class="n">samples.4</span><span class="o">$</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">samples.4</span><span class="o">$</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Scatter plot of x and y"</span><span class="p">,</span><span class="w"> </span><span class="n">pch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.1</span><span class="p">)</span><span class="w">
</span><span class="c1"># 얼마나 빠르게 수렴하는지 보기 위해 첫 10개 sample을 색칠을 해주었다.</span><span class="w">
</span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">10</span><span class="p">){</span><span class="n">points</span><span class="p">(</span><span class="n">samples.4</span><span class="o">$</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">samples.4</span><span class="o">$</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">pch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)}</span><span class="w">
</span></code></pre></div>        </div>
        <p><img src="/assets/img/stat/mcmc/fig7.png" alt="그림8" /></p>
      </li>
      <li>Scatter plot으로부터 수렴이 훨씬 빠르게 되었음을 확인할 수 있다. sigma로 보폭을, rho로 방향을 적절하게 설정했기 때문이다.</li>
      <li>물론 burn-in을 통해 수렴하기 전의 samples를 제거할 수 있다. 하지만 target distribution이 퍼져있는 정도를 고려했을 때, sigma를 늘리지 않을 이유는 없다.
<img src="/assets/img/stat/mcmc/fig8.jpeg" alt="그림9" /></li>
      <li>Acf plot이 유의미하게 낮아졌다. sigma가 커짐에 따라 현재값으로부터 멀리 떨어진 new sample이 proposed되었기 때문이다.</li>
      <li>그렇다고 sigma가 클수록 좋다는 것은 아니다. sigma가 충분히 큰 덕분에 빠르게 수렴했지만, sigma가 너무 크면 target density가 낮은 위치에서 sample이 생성될 확률이 높아지기 때문에 acceptance rate가 낮아지고 sampling에 시간이 지나치게 오래 걸린다.</li>
    </ul>
  </li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="stat" /><summary type="html"><![CDATA[1. Probabilistic ML Model \(x\) : set of observed variables \(y\) : set of hidden / latent variables \(\theta\) : model parameters Discriminative probabilistic ML model \(p(Y \mid X)\) : 데이터 \(X\)가 주어졌을 때 결과 \(y\) 예측하기 (Classification, Regression, …) Generative probabilistic ML model]]></summary></entry><entry><title type="html">Advanced Variational Inference(VI), Variational Autoencoder(VAE)</title><link href="http://localhost:4000/stat/2024-03-02-vi/" rel="alternate" type="text/html" title="Advanced Variational Inference(VI), Variational Autoencoder(VAE)" /><published>2024-03-02T00:00:00+09:00</published><updated>2024-03-04T16:34:37+09:00</updated><id>http://localhost:4000/stat/vi</id><content type="html" xml:base="http://localhost:4000/stat/2024-03-02-vi/"><![CDATA[<ul>
  <li>Paper : <a href="https://arxiv.org/abs/1601.00670">Variational Inference : A Review for Statisticians</a></li>
  <li>Paper : <a href="https://arxiv.org/pdf/1711.05597.pdf">Advances in Variational Inference</a></li>
  <li>Paper : <a href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes</a></li>
</ul>

<h2 id="1-probabilistic-ml-model">1. Probabilistic ML Model</h2>
<ul>
  <li>\(x\) : set of observed variables <br />
\(y\) : set of hidden / latent variables <br />
\(\theta\) : model parameters</li>
  <li>Discriminative probabilistic ML model
    <ul>
      <li>\(p(Y \mid X)\) : 데이터 \(X\)가 주어졌을 때 결과 \(y\) 예측하기 (Classification, Regression, …)</li>
    </ul>
  </li>
  <li>
    <p>Generative probabilistic ML model</p>

    <ul>
      <li>Bayes Theorem : \(p(Y \mid X)=\frac{p(X, Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{p(X)}=\frac{p(X \mid Y) p(Y)}{\int p(X \mid Y) p(Y) d Y}\)
<img src="/assets/img/stat/vi/fig1.png" alt="그림1" /></li>
    </ul>
  </li>
  <li>Discriminative model은 클래스(y) 사이의 차이를 의미하는 decision boundary를 학습하고, (\(p(Y\mid X)\))
Generative model은 분포 \(p(X), p(X,Y)\)를 학습하여 posterior \(p(Y\mid X)\)를 추정한다.</li>
  <li>\(Y\)의 차원이 높아질수록 분모에 있는 \(Y\)에 대한 적분이 어려워지기 때문에(intractable), 아래 두 가지 방법으로 \(p(Y\mid X)\)를 추정한다.
    <ul>
      <li>Variational Inference (optimization)</li>
      <li>Markov chain Monte Carlo (sampling)</li>
      <li>MCMC는 분포를 근사하기 위해 sampling으로 inference하는 것이고, VI는 분포를 근사하기 위해 optimization 문제로 바꾼 것이다.</li>
      <li>일반적으로 VI는 빠르고, MCMC는 정확하다.(상대적으로 그렇다는 것)</li>
    </ul>
  </li>
</ul>

<h2 id="2-variational-inference">2. Variational Inference</h2>
<ul>
  <li>The model: \(p_\theta(x)\) <br />
The data: \(\stackrel{}{D}=\left\{x_1, \ldots, x_N\right\}\) <br />
Maximum likelihood fit: \(\theta \leftarrow \operatorname{argmax}_\theta \frac{1}{N} \sum_i \log p_\theta\left(x_i\right)\) 
    <ul>
      <li>i.e. \(\theta \leftarrow \operatorname{argmax}_\theta \frac{1}{N} \sum_i \log \left(\int p_\theta\left(x_i \mid z\right) p(z) d z\right)\)</li>
      <li>i.e. \(\theta \leftarrow \operatorname{argmax}_\theta \frac{1}{N} \sum_i E_{z \sim p\left(z \mid x_i\right)}\left[\log p_\theta\left(x_i, z\right)\right]\)</li>
    </ul>
  </li>
  <li>log-likelihood \(\log p_\theta\)를 maximize : 
\(\begin{aligned}
  \log p\left(x_i\right) &amp; =\log \int p\left(x_i \mid z\right) p(z) d z \\
  &amp; =\log \int p\left(x_i \mid z\right) p(z) \frac{q_i(z)}{q_i(z)} d z \\
  &amp; =\log E_{z \sim q_i(z)}\left[\frac{p\left(x_i \mid z\right) p(z)}{q_i(z)}\right] \quad \left(\because E_{q(z)}[f(Z)]=\int f(z)q(z) dz\right) \\
  &amp; \geq E_{z \sim q_i(z)}\left[\log \frac{p\left(x_i \mid z\right) p(z)}{q_i(z)}\right] \quad (\because \text{Jensen's Inequality} : \varphi(E[X]) \geq E[\varphi(X)] (\varphi \ \text{is concave fn})) \\
  &amp; =E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]-E_{z \sim q_i(z)}\left[\log q_i(z)\right] \\
  &amp; =E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]+H\left(q_i\right) \quad (\text{where} \ H \ \text{is Entropy}) \\
  &amp; =E_{z \sim q_i(z)}\left[\log p_\theta \left(x_i, z\right)\right]+H\left(q_i\right) \\
  \\
  &amp; = \mathcal{L}_{i}\left(p, q_{i}\right)
  \end{aligned}\)</li>
  <li>위 식에서 \(E_{z \sim q_i(z)}\left[\log p\left(x_i, z\right)\right]\)은 \(q_i(z)\)가 \(p(x_i, z)\)의 density가 높은 곳에서 높은 density를 가질 때 커지고, \(H\left(q_i\right)\)는 \(q_i(z)\)가 고르게 퍼져있을 때 커진다.</li>
  <li>
    <p>위 전개식에서 부등식 앞뒤 식의 차이가 \(D_{\mathrm{KL}}\left(q_i\left(z_i\right) \| p\left(z \mid x_i\right)\right)\)가 되고, 그러므로 \(\mathcal{L}_{i}\left(p, q_{i}\right)\)를 maximize한다는 것은 \(D_{\mathrm{KL}}\left(q_i\left(z_i\right) \| p\left(z \mid x_i\right)\right)\)를 minimize한다는 것과 같다. (아래 전개식 참고)</p>

    <p><br />
\(\begin{aligned}
  D_{\mathrm{KL}}\left(q_i\left(x_i\right) \| p\left(z \mid x_i\right)\right) &amp; =E_{z \sim q_i(z)}\left[\log \frac{q_i(z)}{p\left(z \mid x_i\right)}\right]=E_{z \sim q_i(z)}\left[\log \frac{q_i(z) p\left(x_i\right)}{p\left(x_i, z\right)}\right] \\
  &amp; =-E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]+E_{z \sim q_i(z)}\left[\log q_i(z)\right]+E_{z \sim q_i(z)}\left[\log p\left(x_i\right)\right] \\
  \\
  &amp; =-E_{z \sim q_i(z)}\left[\log p\left(x_i \mid z\right)+\log p(z)\right]-\mathcal{H}\left(q_i\right)+\log p\left(x_i\right) \\
  &amp; =-\mathcal{L}_i\left(p, q_i\right)+\log p\left(x_i\right)
  \end{aligned}\)
\(\begin{aligned}
  &amp;\log p\left(x_i\right)=D_{\mathrm{KL}}\left(q_i(z) \| p\left(z \mid x_i\right)\right)+\mathcal{L}_i\left(p, q_i\right)
  \end{aligned}\)</p>
  </li>
  <li>\(\log p\left(x_i\right)\)가 고정되어 있다면, \(\mathcal{L}_i\left(p, q_i\right)\)를 maximize할 때 \(D_{\mathrm{KL}}\left(q_i(z) \| p\left(z \mid x_i\right)\right)\)가 minimize된다. <br />
(\(\mathcal{L}_i\left(p, q_i\right)\)은 ELBO이고, \(D_{\mathrm{KL}}\left(q_i(z) \| p\left(z \mid x_i\right)\right)\)은 variational distribution)</li>
  <li>이 때 학습되는 parameters는 아래와 같다.
    <ul>
      <li>\(z\)를 \(\hat x\)으로 mapping시키는 \(\theta\) (\(\theta\)는 \(\hat x\)가 \(x\)와 비슷해지도록 학습)</li>
      <li>\(z\)의 분포인 \(q_i(z)\)의 평균과 분산 (Gaussian을 가정)</li>
      <li>총 \(\mid \theta \mid +\left(\mid \mu_i\mid +\mid \sigma_i\mid \right) \times N\)개</li>
    </ul>
  </li>
</ul>

<h2 id="21-amortized-variational-inference">2.1. Amortized Variational Inference</h2>
<ul>
  <li>\(\mid \theta \mid +\left(\mid \mu_i\mid +\mid \sigma_i\mid \right) \times N\)개의 parameters는 데이터 개수가 늘어날수록 커진다는 단점이 있다.</li>
  <li>
    <p>Amortized Variational Inference는 \(q_i(z)\)가 아니라 \(q_\phi(z \mid x)=\mathcal{N}\left(\mu_\phi(x), \sigma_\phi(x)\right)\)가 \(p(x \mid z)\)와 비슷해지도록 학습한다.</p>

    <p><img src="/assets/img/stat/vi/fig2.png" alt="그림2" /></p>
  </li>
  <li>Basic Variational Inference는 sampled \(z\)로 \(\hat x\)를 만들어내는 것인데, Amortized Variational Inference는 \(x\)가 input으로 들어가면 latent vector \(z\)의 분포가 결정되고 그 분포에서 \(z\)를 sampling해서 \(\hat x\)를 만들어내기 때문에, autoencoder의 아이디어와 같다. 즉 VAE는 Amortized Variational Inference의 예시 중 하나이다.</li>
  <li>\(x\)가 input으로 들어가서 \(z\)의 분포가 결정되는 네트워크(\(\phi\))를 encoder, inference network가 되고, \(z\)로 \(\hat x\)을 만드는 네트워크(\(\theta\))를 decoder, generative network가 된다.</li>
  <li>\(p_\theta(x_i \mid z)\)를 Gaussian으로 가정한다는 것은, log를 씌웠을 때 exp 안에 있는 L2 term만 남기 때문에 \(\hat x\)과 \(x\)를 비교할 때 euclidean distance를 사용한다는 의미이다.</li>
  <li>이외에도 많은 variants of VI가 있지만 Amortized VI만 소개하는 이유는 VAE와 관련이 있기 때문이다.</li>
</ul>

<h2 id="22-mean-field-variational-inference">2.2. Mean-field Variational Inference</h2>
<ul>
  <li>Assumption : all latent variables are mutually independent (i.e. \(q(\mathbf{z})=\prod_{j=1}^m q_j\left(z_j\right) .\))</li>
  <li>Mean-field 가정을 하면 true posterior의 variables가 highly dependent인 경우에 approximation의 정확도가 다소 떨어지는 단점이 있지만, fully factorized distribution으로 계산이 간단해진다.</li>
  <li>ELBO를 maximize하는 \(q(z_i)\)들을 각각 찾고 다 곱해서 \(q(z)=q(z_1) \times ... \times q(z_M)\)을 계산하기 때문이다</li>
  <li>Mean-filed 가정을 하면 아까 봤던 식이 아래와 같이 전개된다.
\(\begin{aligned}
\mathrm{ELBO} &amp; =E_{q(z)}[\log p(x, z)-\log q(z)] \\
&amp; =E_{\prod_i q_i}\left[\log p(x, z)-\log \prod_i q_i\right] \ (\because \text{Mean-field assumption})\\
&amp; =\int \prod_i q_i\left\{\log p(x, z)-\log \prod_i q_i\right\} d z \ (\text{The definition of Expectation})\\
\\
&amp; =\int \prod_i q_i\left\{\log p(x, z)-\sum_i \log q_i\right\} d z \ (\text{Property of logarithm}) \\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int \prod_i q_i \sum_i \log q_i d z \ (\text{j번째 적분만 바깥으로 뺀 것})\\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int \prod_i q_i \log q_1 d z+\ldots \int \prod_i q_i \log q_M d z \\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int \prod_i q_i \log q_j d z+\text{(Constant)} \\
&amp; =\int q_j\left\{\int \log p(x, z) \prod_{i \neq j} q_i d z_i\right\} d z_j-\int q_j \log q_j d z_j+\text{(Constant)} \ (q_j\text{와 무관한 항들은 constant}) \\
&amp; =\int q_j E_{i \neq j}[\log p(x, z)] d z_j-\int q_j \log q_j d z_j+\text{(Constant)} \\
\\
&amp; =\int q_j \log \widetilde{p}\left(x, z_j\right) d z_j-\int q_j \log q_j d z_j+\text{(Constant)} \\
&amp; =\int q_j \log \frac{\widetilde{p}\left(x, z_j\right)}{q_j} d z_j+\text{(Constant)} \\
&amp; =-\mathrm{KL}\left[q_j \| \widetilde{p}\left(x, z_j\right)\right]+\text{(Constant)}
\end{aligned}\)</li>
  <li>위 결과로부터 \(q_j\)가 \(\tilde p(x,z_j)\)와 비슷해져야 한다는 것을 알 수 있다. 그러므로 \(q_j\)를 전개하고 normalization하면 아래와 같다. <br />
\(\begin{aligned}
q_j &amp; =\widetilde{p}\left(x, z_j\right) \\
\log q_j &amp; =\log \widetilde{p}\left(x, z_j\right) \\
\log q_j &amp; \propto E_{i \neq j}[\log p(x, z)] \\
q_j &amp; \propto \exp \left(E_{i \neq j}[\log p(x, z)]\right) \\
q_j &amp; =\frac{\exp \left(E_{i \neq j}[\log p(x, z)]\right)}{\int \exp \left(E_{i \neq j}[\log p(x, z)]\right) d z_j}
\end{aligned}\)</li>
  <li>optimal \(q^*_j\)를 알기 위해서 \(i\ne j\)에 대해 \(log\ p(x,z)\)의 expectation을 계산한다.</li>
</ul>

<h2 id="3-variational-autoencoder">3. Variational Autoencoder</h2>
<ul>
  <li>VAE는 2개의 neural network로 구성된다. 을 사용한다. (2개의 NN)
    <ul>
      <li>1) top-down generative model(=decoder) : mapping from the latent variable \(z\) to the data \(x\)</li>
      <li>2) bottom-up inference model(=encoder) : approximates the posterior \(p(z \mid x)\) (using amortized mean-field variational distribution)
<img src="/assets/img/stat/vi/fig3.png" alt="그림3" /></li>
    </ul>
  </li>
  <li>위 그림에서 나와있듯이 encoder를 거치면 deterministic하게 latent variable이 output으로 나오는 것이 아니다. output은 mean vector와 std dev vector이고, 이렇게 결정된 gaussian 분포에서 sampling을 통해 latent variable을 만든다. (VAE가 generative model인 이유이다.)</li>
  <li>Reparameterization trick : \(N(mean, std)\)에서 sampling하지 않고 \(N(0,1)\)에서 생성한 뒤 std를 곱하고 mean을 더해줌으로써 미분이 가능하도록 (backpropagation이 가능하도록) 한다.</li>
  <li>latent variable이 decoder를 거치면 input과 유사한(ideally) 새로운 데이터가 생성된다.</li>
  <li>
    <p>VAE의 loss는 다음과 같다.</p>

    <p>\(\arg \min _{\theta, \phi} \sum_i-\mathbb{E}_{q_\phi\left(z \mid x_i\right)}\left[\log \left(p\left(x_i \mid g_\theta(z)\right)\right)\right] \oplus K L\left(q_\phi\left(z \mid x_i\right) \| p(z)\right)\)</p>
    <ul>
      <li>학습 parameters는 encoder의 \(\phi\)와 decoder의 \(\theta\)이다.</li>
      <li>Reconstruction Error \(-\mathbb{E}_{q_\phi\left(z \mid x_i\right)}\left[\log \left(p\left(x_i \mid g_\theta(z)\right)\right)\right]\)
        <ul>
          <li>\(x\)가 주어졌을 때 encoder \(q_\phi\)를 지나 \(z\)생성 : \(q_\phi(z \mid x)\)</li>
          <li>그 \(z\)가 decoder \(g_\theta\)를 지나 \(x\) 생성 : \(g_\theta(z)\)</li>
          <li>이렇게 생성한 \(\hat x\)에 대한 \(x\)의 negative log-likelihood</li>
        </ul>
      </li>
      <li>Regularization Error \(K L\left(q_\phi\left(z \mid x_i\right) \| p(z)\right)\)
        <ul>
          <li>\(x\)가 주어졌을 때 encoder \(q_\phi\)를 지나 \(z\)생성 : \(q_\phi(z \mid x)\)</li>
          <li>그 \(z\)와 gaussian의 KL-divergence</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="stat" /><summary type="html"><![CDATA[Paper : Variational Inference : A Review for Statisticians Paper : Advances in Variational Inference Paper : Auto-Encoding Variational Bayes]]></summary></entry><entry><title type="html">(GAFormer) Enhancing Timeseries Transformers Through Group-Aware Embeddings (ICLR 2024)</title><link href="http://localhost:4000/timeseries/2024-03-01-GAFormer/" rel="alternate" type="text/html" title="(GAFormer) Enhancing Timeseries Transformers Through Group-Aware Embeddings (ICLR 2024)" /><published>2024-03-01T00:00:00+09:00</published><updated>2024-03-03T19:02:43+09:00</updated><id>http://localhost:4000/timeseries/GAFormer</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-03-01-GAFormer/"><![CDATA[<h2 id="abstract">Abstract</h2>
<ul>
  <li>Multivariate TS의 복잡한 inter-channel relationship과 dynamic shifts로 인해 Robust and generalizable representation을 학습하기 어렵다.</li>
  <li>본 논문에서 제시하는 GAFormer는 set of group tokens를 학습하고 instance-specific group embedding layer를 만든다.</li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>Multivariate TS의 temporal dynamics(temporal structure) of each channel, 그리고 relationship across channels(channel-wise structure)는 TS의 representation을 만드는 요소</li>
  <li>TS는 <strong>no predetermined ordering</strong>, 그리고 <strong>instance-specific relationships across channels and time</strong>으로 인해 position embedding을 그대로 사용하기에 적절하지 않다.</li>
  <li>본 논문에서 제시하는 GAFormer는 channel structure와 temporal structure를 통합하여 token에 ‘group embedding’한다.</li>
</ul>

<h2 id="2-method">2. Method</h2>
<ul>
  <li>Instance-specific group embeddings : grouping across different tokens, either channel-wise (spatially) or time-wise (temporally)
    <h3 id="21-group-embeddings">2.1. Group Embeddings</h3>
  </li>
  <li>Sequence of tokens : \(X=\left[\mathbf{x}_1, \ldots, \mathbf{x}_N\right] \in \mathbb{R}^{N \times D}\) (시계열의 채널, 길이와 다름)
    <ul>
      <li>\(N\) : the total # of tokens in a seq</li>
      <li>\(D\) : token dim</li>
    </ul>
  </li>
  <li>Linear weight matrix : \(W \in \mathbb{R}^{D \times K}\) project each token down to a space of \(K\) dim
    <ul>
      <li><code class="language-plaintext highlighter-rouge">operation</code> \(\operatorname{Encoder}(X) W \in \mathbb{R}^{N \times K}\)</li>
    </ul>
  </li>
  <li>그 다음 softmax : sparsify the coefficients that assign group tokens to input tokens (group awareness)
    <ul>
      <li><code class="language-plaintext highlighter-rouge">operation</code> \(\mathbb{S}(\operatorname{Encoder}(X) W)\)
        <ul>
          <li>where \(\mathbb{S}\) represents the softmax (along \((D)\) dim)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>각 tokens를 K차원으로 줄였기 때문에,  \(\mathbf{G} \in \mathbb{R}^{N \times D}\)을 곱해줄 수 있다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">operation</code> \(\operatorname{GE}(X)=\mathbb{S}(\operatorname{Encoder}(X) W) \cdot G\)</li>
    </ul>
  </li>
  <li>이제 \(X\)에 더해준다
    <ul>
      <li><code class="language-plaintext highlighter-rouge">operation</code> \(X \leftarrow X+\operatorname{GE}(X)\)</li>
    </ul>
  </li>
</ul>

<h3 id="22-gaformer-a-group-aware-spatiotemporal-transformer">2.2. GAFormer: A Group-Aware SpatioTemporal Transformer</h3>
<ul>
  <li><strong>Tokenization Layer</strong> : 시계열 \(X \in \mathbb{R}^{C \times T}\)를 P개의 패치로 잘라서 tensor \(X \in \mathbb{R}^{C \times P \times L}\)를 만든다. 그리고 <code class="language-plaintext highlighter-rouge">Token</code>이라는 encoder를 통과시키면 \(Z=\operatorname{Token}(X) \in \mathbb{R}^{C \times P \times D}\)가 된다. 이 때 channel-wise separation이 유지되고 각 channel에서의 temporal semantics는 알아낼 수 있다.</li>
  <li><strong>Spatial (Channel-Wise) Group Awareness</strong> : <code class="language-plaintext highlighter-rouge">Trans-S</code>(Transformer encoder)와 <code class="language-plaintext highlighter-rouge">SGE</code>(spatial group embedding)으로 channel-wise group embedding을 학습한다. <br />
<img src="/assets/img/timeseries/GAFormer/fig2.jpeg" alt="사진2" />
(\(Z^{\prime}=\operatorname{Trans}-\mathrm{S}\left(Z_S+\operatorname{SGE}\left(Z_S\right)\right)\)) Group embedding을 하지 않고 fixed positional embedding을 하면 두 시계열에 같은 사건이 발생했는데도 발생 시점이 다르다는 이유로 두 시계열의 structure를 다르게 학습하는데, group embedding을 하면 사건이 발생한 인접 시점들에 대해 embedding을 하기 때문에 같은 structure로 학습할 수 있다.
<img src="/assets/img/timeseries/GAFormer/fig1.jpeg" alt="사진1" /></li>
  <li><strong>Temporal Group Awareness</strong> : 먼저 dimension reduction layer \(H\)를 통과시켜 \(D\)차원 token을 \(D'\)차원 token으로 압축할 수 있다. 그리고 Spatial Group Awareness layer와 유사하게 학습한다. <br />
(\(Z^{\text {final}}=\operatorname{Trans}-\mathrm{T}\left(Z_T+\operatorname{TGE}\left(Z_T\right)\right)\)) 이렇게 학습된 \(Z^{\text {final}}\)은 linear classifier로 들어간다.</li>
</ul>

<h2 id="3-results">3. Results</h2>
<h3 id="31-an-intuitive-example--noisy-many-body-systems">3.1. An Intuitive example : Noisy many-body systems</h3>
<ul>
  <li>본 논문에서는 multivariate TS를 생성하기 위해 상호 작용하는 입자들로 구성된 many-body system의 궤적을 기반으로 한 실험 결과를 제시한다.</li>
  <li>시스템의 총 에너지를 분류하여, 고에너지 시스템인지 저에너지 시스템인지를 결정하는 것인데, 실험의 복잡성을 증가시키기 위해 상호 작용하지 않는 무관한 body들이 시스템을 오염시키는 상황을 가정했다.</li>
  <li>3가지의 embedding 방식을 실험했다.
    <ul>
      <li>1) learnable positional embedding</li>
      <li>2) parameter-free sin-cos positional embedding</li>
      <li>3) Group embedding</li>
    </ul>
  </li>
  <li>3가지의 setting을 실험했다.
    <ul>
      <li>1) Stable : the relative position of object(channels) never shifts</li>
      <li>2) Shuffle : the observed objects could be in any position and are randomized similarly</li>
      <li>3) Biased : the observed objects have different position that are randomly sampled from non-overapping set</li>
    </ul>
  </li>
  <li>실험 결과 Group embedding은 channel mismatch와 distribution shifts가 있을 때 다른 embedding보다 robust했다.
<img src="/assets/img/timeseries/GAFormer/fig3.jpeg" alt="사진3" />
    <h3 id="32-time-series-classification-tasks">3.2. Time series Classification tasks</h3>
  </li>
  <li>table1, table2 : TGE(temporal dimension embedding)에 Group embedding을 했을 때 classification 성능이 향상된다.
<img src="/assets/img/timeseries/GAFormer/table1.jpeg" alt="사진3" />
<img src="/assets/img/timeseries/GAFormer/table2.jpeg" alt="사진4" />
    <h3 id="33-classification-and-regression-tasks-on-neural-recordings">3.3. Classification and Regression tasks on Neural Recordings</h3>
    <p><img src="/assets/img/timeseries/GAFormer/table3.jpeg" alt="사진5" /></p>
    <h3 id="34-ablation-studies">3.4. Ablation Studies</h3>
  </li>
  <li>table4 :  temporal group embedding 또는 spatial group embedding 둘 중 하나만 적용하거나 둘 다 적용한 결과 둘 다 성능 향상에 필요하다.
<img src="/assets/img/timeseries/GAFormer/table4.jpeg" alt="사진6" /></li>
</ul>

<h2 id="4-related-work">4. Related Work</h2>
<h2 id="5-discussion">5. Discussion</h2>
<ul>
  <li>본 논문에서는 TS의 group-level structure를 다루는 새로운 프레임워크를 제안하였다.</li>
  <li>Group embedding은 group token across channel and temporal dimension을 학습해서 representation space로 보낸다.</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[ICLR 2024](https://openreview.net/forum?id=c56TWtYp0W)]]></summary></entry><entry><title type="html">(iTransformer) Inverted Transformers are Effective for Time Series Forecasting (ICLR 2024)</title><link href="http://localhost:4000/timeseries/2024-02-23-iTransformer/" rel="alternate" type="text/html" title="(iTransformer) Inverted Transformers are Effective for Time Series Forecasting (ICLR 2024)" /><published>2024-02-23T00:00:00+09:00</published><updated>2024-03-06T17:11:13+09:00</updated><id>http://localhost:4000/timeseries/iTransformer</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-02-23-iTransformer/"><![CDATA[<h2 id="abstract">Abstract</h2>
<ul>
  <li>Transformer-based TS : larger lookback \(\to\) performance degradation &amp; computation explosion.</li>
  <li>iTransformer : attention과 feed-forward network(FFN)를 inverted dimension에서 적용
<img src="/assets/img/timeseries/iTransformer/fig2'.jpeg" alt="사진1" class="lead" width="00" height="100" /></li>
  <li>각 time point가 token이 되는 것이 아니라 각 series(variate)가 token이 된다.</li>
  <li>Inverted dimension만 다르고 이외의 Transformer의 components는 수정 없이 그대로 사용한다.</li>
</ul>

<h2 id="1-introduction">1. introduction</h2>
<ul>
  <li>Transformer가 다른 fields에서는 linear model보다 성능이 좋은데, multivariate ts forecasting에서는 not sutable하다. <br />
(특히 time points 사이에 semantic 관계보다 numerical 관계가 강한 경우에는 그냥 simple linear layer의 성능이 더 좋았다.)</li>
  <li>그 이유는 한 시점에 기록된 서로 다른 변수들의 값들이 하나의 token으로 기록되기 때문이다. 논문에서는 아래처럼 표현하고 있다. <br />
(= embed multiple variates of the same timestamp into indistinguishable channels…) <br />
(= the points of the same time step that represent different physical meanings recorded by inconsistent mesurements are embedded into one token …)</li>
  <li>이러한 single time step의 token 형태는 receptive field가 너무 좁아서 유용한 정보를 얻어내기가 어렵다.</li>
  <li>
    <p>또한 시계열은 데이터의 순서가 중요한데, transformer는 permutation-invariant attention mechanism이라서 temporal dimension을 잘 잡지 못한다.</p>
  </li>
  <li>그래서 iTransformer는 각각의 variate를 독립적으로 token으로 embedding해서 receptive field를 늘려준다.(Patching의 extreme case)</li>
  <li>그러면 token은 series의 global representation을 통합해서 variate-centric하다.</li>
  <li>FFN은 개별 변수에 대해 인코딩된 lookback series를 보고 예측할 수 있을 정도의 generalizable representation을 학습할 수 있다.</li>
  <li>본 논문의 contribution은 아래와 같다.
    <ul>
      <li>Transformer가 비효과적인 것이 아니라 아직 underexplored라서 잘못 사용되었으니 component를 개선한다.</li>
      <li>독립적인 개별 시계열을 token으로 간주하여 self-attention으로 multivariate correlations를 파악하고, FFN으로 forecasting을 위한 series-global representation을 학습한다.</li>
    </ul>
  </li>
</ul>

<h2 id="2-related-work">2. Related Work</h2>
<ul>
  <li>TCN-based, RNN-base forecasters를 지나서 Transformer가 시퀀스 모델링과 확장 가능성으로 좋은 성능을 보여주며 많은 variant가 나왔다.</li>
  <li>Transformer의 variant는 component를 수정하는지, architecture를 수정하는지에 따라 4가지로 구분된다.
<img src="/assets/img/timeseries/iTransformer/fig3.jpeg" alt="사진2" />
    <ul>
      <li>1) Temporal dependency 모델링을 위한 attention module 수정 (Component adaptation)</li>
      <li>2) Linear model이 떠오르면서, transformer에서도 component나 architecture를 바꾸지 않고 Stationarization, Channel independence, Patching 등을 통해 효율적으로 성능 향상</li>
      <li>3) Transformer의 component와 architecture를 모두 수정하여 multivariate의 cross-time and cross-variate dependency를 파악</li>
      <li>4) iTransformer는 Transformer의 component는 그대로 가져오지만 inverted하게 가져온다. (architecture만 바뀜)</li>
    </ul>
  </li>
</ul>

<h2 id="3-itransformer">3. ITransformer</h2>
<ul>
  <li>현실 시나리오에서는 각각의 variate마다 발생 시점과 기록 시점의 delay 정도가 다를 수 있기 때문에 시점 \(t\)에서 모든 variates가 관측되지 않을 수도 있다. 뿐만 아니라 각각의 variate마다 통계적 분포 자체가 다를 수도 있다.</li>
</ul>

<h3 id="31-structure-overview">3.1. Structure Overview</h3>
<ul>
  <li><img src="/assets/img/timeseries/iTransformer/fig4.png" alt="사진3" /></li>
  <li>iTransformer는 Transformer의 encoder-only architecture (including the embedding, projection, and Transformer blocks)</li>
  <li><strong>Embedding the whole series as the token</strong> : 한 시점에서 많은 변수들을 하나의 token으로 간주하면 attention map을 학습하기 어렵다는 것은 patching으로 respective field를 늘리는 방식들이 좋은 성능을 낸다는 것으로부터 알 수 있다. 그러므로 each time series가 token이 되어 해당 변수의 properties를 다루고, self-attention으로 mutual interactions를, feed-forward networks로 series representations를 처리한다.</li>
  <li>iTransformer가 예측하는 future series \(\hat{\mathbf{Y}}_{:, n}\) based on \(\mathbf{X}_{:, n}\)의 formula :
<img src="/assets/img/timeseries/iTransformer/formula1.png" alt="사진4" />
    <ul>
      <li>\(\mathbf{H}=\left\{\mathbf{h}_1, \cdots, \mathbf{h}_N\right\} \in \mathbb{R}^{N \times D}\)은 \(D\)차원의 embedded tokens \(N\)개이고 \(h\)의 아래첨자는 layer index이다.</li>
      <li>Embedding \(\mathbb{R}^T \mapsto \mathbb{R}^D\)과 Projection \(\mathbb{R}^D \mapsto \mathbb{R}^S\)는 MLP가 한다.</li>
      <li>Inverted dimension으로 sequence의 순서가 FFN에 저장되므로 position embedding이 더이상 필요하지 않다.</li>
    </ul>
  </li>
  <li><strong>iTransformers</strong> : Attention에 multivariate correlation 외에는 requirements가 없어서 variates가 많아질 때 효율적이다. 또한 training과 inference에서 token의 개수가 다를 수 있어서 variates의 개수에 대해 유연한 모델이다.</li>
</ul>

<h3 id="32-inverted-transformer-components">3.2. Inverted Transformer Components</h3>
<ul>
  <li><strong>Layer normalization</strong> : Layer normalization은 훈련할 때 convergence speed and stability를 위한 것이다. 기존 Transformer에서는 한 시점에서 multivariate representation을 normalize했었는데, non-causal이나 앞서 언급한 delay를 고려하면 interaction noise의 원인이 될 수 있다. 그러므로 개별 variate를 normalize한다. 그러면 measurements(=variates, sensor, series)끼리의 불일치성도 해소된다.
\(\text { LayerNorm }(\mathbf{H})=\left\{\left.\frac{\mathbf{h}_n-\operatorname{Mean}\left(\mathbf{h}_n\right)}{\sqrt{\operatorname{Var}\left(\mathbf{h}_n\right)}} \right\rvert\, n=1, \cdots, N\right\}\)</li>
  <li><strong>Feed-Forward network</strong> : 각각의 variate token을 FFN에 태우면 universal approximation therem(Hornik, 1991)에 의해 시계열의 복잡한 representation을 추출할 수 있다. 이러한 inverted blocks를 쌓으면 observed를 encoding하고 future series를 decoding하는 과정을 <a href="/timeseries/2024-02-16-DLinear">MLP</a>처럼 할 수 있다. (MLP 방식은 시계열의 amplitude, periodicity, frequency spectrums까지 학습할 수 있고, time point self-attention보다도 좋은 성능을 낼 수 있다.)</li>
  <li><strong>Self-attention</strong> : Inverted dimenstion으로 self-attention을 계산하면 \(Q, K, V \in \mathbf R^{N \times d_k}\)를 linear projection으로 구한다. 사전에 feature-dimension으로 normalize를 해놓았으니 pre-Softmax score \(\mathbf{A}_{i, j}=\left(\mathbf{Q} \mathbf{K}^{\top} / \sqrt{d_k}\right)_{i, j} \propto \mathbf{q}_i^{\top} \mathbf{k}_j\)는 variate-wisecorrelation을 의미하고, whole score map \(\mathbf{A} \in \mathbb{R}^{N \times N}\)는 multivariate correlations btw paired variate tokens가 된다.</li>
</ul>

<h2 id="4-experiments">4. Experiments</h2>

<h3 id="41-forecasting-results">4.1. Forecasting Results</h3>
<ul>
  <li>7개의 데이터셋 사용(ECL, ETT, Exchange, Traffic, Weather, Solar-Energy, PEMS), 10개의 forecasting models과 비교
    <ul>
      <li>Transformer-based : Autoformer, FEDformer, Stationary, Crossformer, PatchTST</li>
      <li>Linear-based : DLinear, TiDE, RLinear</li>
      <li>TCN-based : SCINet, TimesNet
<img src="/assets/img/timeseries/iTransformer/table1.png" alt="사진5" /></li>
    </ul>
  </li>
  <li>SOTA였던 PatchTST는 변동이 심한 PEM 데이터를 처리하기 어렵고, 명시적으로 multivariate correlation을 파악하는 Crossformer보다 iTransformer의 성능이 뛰어나다.</li>
</ul>

<h3 id="42-itransformer-generality">4.2. ITransformer Generality</h3>
<ul>
  <li><strong>Performance promotion</strong>
<img src="/assets/img/timeseries/iTransformer/table2.png" alt="사진6" />
    <ul>
      <li>Transformer-based models에 inverted framework를 적용하여 성능을 비교한 결과 일관되게 성능이 향상되었다.</li>
    </ul>
  </li>
  <li><strong>Variate generalization</strong>
<img src="/assets/img/timeseries/iTransformer/fig5.png" alt="사진7" />
    <ul>
      <li>데이터의 20%만으로 training을 하더라도 100%로 training을 했을 때에 비해서 성능에 큰 차이가 없다는 것은 iTransformer가 효율적으로 훈련할 수 있는 모델임을 의미한다. 즉 unseen variates에 대해 generalization capability가 뛰어나다. 그 이유는 1) 각 variate를 token으로 embedding하니 variate의 개수에 제한이 없어지기 때문이고, 2) FFN이 각 token에 identically하게 적용되어 어떤 time series에서든 존재하는 본질적인 패턴을 학습할 수 있기 때문이다.</li>
    </ul>
  </li>
  <li><strong>Increasing lookback length</strong>
<img src="/assets/img/timeseries/iTransformer/fig6.png" alt="사진8" />
    <ul>
      <li>Transformer-based models는 look-back window가 길어져도 성능 향상으로 이어지지 않았지만, inverted framework는 look-back window가 길어지면 성능이 향상된다.</li>
    </ul>
  </li>
</ul>

<h3 id="43-model-analysis">4.3. Model Analysis</h3>
<ul>
  <li><strong>Ablation Study</strong>
<img src="/assets/img/timeseries/iTransformer/table3.png" alt="사진9" />
    <ul>
      <li>Time series의 multivariate correlation(Variate)와 series representation(Temporal)을 학습하기 위해 Attention을 FFN으로 바꿔도 보고 아예 안써보기도 하면서 iTransformer가 가장 좋은 성능을 낸다는 것을 확인하였다.</li>
    </ul>
  </li>
  <li><strong>Analysis of multivariate Representations and Correlations</strong>
<img src="/assets/img/timeseries/iTransformer/fig7.png" alt="사진10" />
    <ul>
      <li>The centered kernel alignment (CKA)는 높을수록 similar representation을 의미하는데, inverted frameworks가 유의미하게 높다.</li>
      <li>또한 얕은 layer의 attention map은 input series와 상관관계가 높고, 깊은 layer의 attention map은 future series와 상관관계가 높다는 점에서 interpretable attention이다.</li>
    </ul>
  </li>
  <li><strong>Efficient training strategy</strong>
<img src="/assets/img/timeseries/iTransformer/fig8.png" alt="사진11" />
    <ul>
      <li>각 배치에서 변수의 일부만 사용하여 훈련하더라도 MSE가 안정적이고, sample ratio가 낮아짐에 따라 memory가 적게 사용되므로 효율적인 모델이라 할 수 있다.</li>
    </ul>
  </li>
</ul>

<h2 id="5-conclusion-and-future-work">5. Conclusion and Future work</h2>
<ul>
  <li>iTransformer는 각 series를 variate token으로 보고 multivariate correlation을 파악하기 위해 attention과 FFN을 사용하였다.</li>
  <li>실험 결과를 통해 기존 Transformer-based time series forecasters보다 뛰어날 뿐만 아니라 interpretable한 성능을 보여주었다.</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[ICLR 2024](https://arxiv.org/abs/2310.06625)]]></summary></entry><entry><title type="html">FITS: Modeling Time Series with 10k Parameters (ICLR 2023)</title><link href="http://localhost:4000/timeseries/2024-02-22-FITS/" rel="alternate" type="text/html" title="FITS: Modeling Time Series with 10k Parameters (ICLR 2023)" /><published>2024-02-22T00:00:00+09:00</published><updated>2024-03-03T18:59:39+09:00</updated><id>http://localhost:4000/timeseries/FITS</id><content type="html" xml:base="http://localhost:4000/timeseries/2024-02-22-FITS/"><![CDATA[<h2 id="abstract">Abstract</h2>

<ul>
  <li>FITS(Frequency Interpolation Time Series)라는 lightweight yet powerful model 제안</li>
  <li>Raw time domain이 아니라 complex frequency domain에서 interpolation</li>
  <li>10k개의 parameters만 사용</li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>

<ul>
  <li>Time series domain에서는 시계열의 complexity와 dynamism 때문에 sparse and scattered하다.</li>
  <li>Frequency domain에서 time series를 representation하면 compact and efficient하다.</li>
  <li>Forecasting : simply extending the given look-back window with frequency interpolation</li>
  <li>Reconstruction : recover the original segment by interpolating the frequency representation of its downsampled counterpart</li>
  <li>FITS의 핵심은 <strong>complex-valued linear layer</strong> : amplitude scaling과 phase shift를 학습하여 complex domain에서 interpolation을 가능하게 한다.</li>
  <li>FITS의 <strong>low-pass filter</strong>를 통해 핵심적인 정보는 보존하면서 압축적인 정보를 representation한다.</li>
</ul>

<h2 id="2-related-work-and-motivation">2. Related Work and Motivation</h2>

<h3 id="21-frequency-aware-time-series-analysis-models">2.1. Frequency-Aware Time Series Analysis Models</h3>

<ul>
  <li>Frequency domain에서 시계열의 pattern을 잡으려는 시도 (FNet(2022), FEDFormer(2022), FiLM(2022), …)</li>
  <li>시계열의 periodicity(주기성)을 잡는 것도 중요 (DLinear(2023), TimesNet(2023))</li>
  <li>하지만 여전히 데이터 전처리를 포함하는 feature engineering에 의존하는 면이 있다.</li>
</ul>

<h3 id="22-divide-and-conquer-the-frequency-components">2.2. Divide and Conquer the Frequency Components</h3>

<ul>
  <li>Time series를 signal로 이해한다면 ?
    <ul>
      <li>시계열을 linear combination of sinusoidal components로 쪼갤 수 있다. (정보 손실 없이 !)</li>
      <li>그러면 sinusoidal waves에 phase bias만 추가해주면 예측값이 되니까 매우 간단해진다.</li>
    </ul>
  </li>
  <li>하지만 time domain에서 sinusoidal component를 예측하는 일은 어려우니 frequency domain에서 한다면 정보 손실도 없고 compact하다.</li>
</ul>

<h2 id="3-method">3. Method</h2>

<h3 id="31-preliminary--fft-and-complex-frequency-domain">3.1. Preliminary : FFT and Complex Frequency Domain</h3>

<ul>
  <li><strong>FFT(Fast Fourier Transform)</strong> : DFT(Discrete Fourier Transform)을 빠르게 계산, DFT는 discrete-time signals을 time domain에서 frequency domain으로 보내는 방법이다. (\(N\)개의 real numbers \(\to\) \(\frac{N}{2}+1\)개의 complex numbers)</li>
  <li><strong>Complex Frequency Domain</strong> : complex frequency는 signal의 representation인데, 각각의 frequency에 있는 complex number가 amplitude(magnitude or strength)와 phase(temporal shift or delay)를 파악한다.</li>
  <li>Complex number : \(X(f) = \mid X(f)\mid e^{j \theta (f)}\)
    <ul>
      <li>\(X(f)\) : frequency에서 component의 complex number</li>
      <li>\(\mid X(f)\mid\). : component의 amplitude</li>
      <li>\(e^{j \theta(f)}\) : component의 phase</li>
      <li>\(X(f)\)는 length가 amplitude이고 angle이 phase인 벡터로 visualize된다.</li>
      <li>다시 표현하면 \(X(f)=\mid X(f)\mid (\cos \theta(f)+j \sin \theta(f))\)</li>
      <li><img src="/assets/img/timeseries/FITS/fig1.png" alt="사진1" /></li>
    </ul>
  </li>
  <li><strong>Time Shift and Phase Shift</strong> : Time shift는 phase shift와 같다. 즉 unit complex exponential element를 곱하는 것과 같다. 예를 들어 만약 \(\tau\)만큼 time shift했다면(\(x(t-\tau)\)), Fourier transform은 \(X_\tau (f)=e^{-j 2 \pi f \tau } X(f)=\mid X(f)\mid e^{j(\theta(f)-2 \pi f \tau)}=[\cos (-2 \pi f \tau)+j \sin (-2 \pi f \tau)] X(f)\)이 된다. Amplitude는 변하지 않았고 phase만 \(\theta_\tau(f)=\theta(f)-2 \pi f \tau\)만큼 변했다. (time shift에 대해 linear)</li>
  <li>결론적으로, amplitude scaling과 phase shifting은 multiplication of complex numbers와 같다. (fig1)</li>
</ul>

<h3 id="32-fits-pipeline">3.2. FITS Pipeline</h3>

<ul>
  <li>Time series가 길수록 higher frequency resolution이 되기 때문에, 시계열의 frequency representation을 interpolate한다는 말은 = 시계열을 extend한다는 말과 같다. (시계열이 길어지면 더 작은 간격의 주파수로 변환될 수 있다는 걸 반대로 생각하면 된다.)</li>
  <li><img src="/assets/img/timeseries/FITS/fig2.png" alt="사진2" /></li>
  <li>FITS의 low-pass filter(LPF)는 말 그대로 낮은 주파수만 pass시키고 high-frequency components는 제거한다. 시계열의 essential한 정보, coarse한 정보는 남기고 fine한 정보는 제거하여 모델을 가볍게 만든다. (주기가 큰 파동만 남고 주기가 작아서 노이즈에 가까운 파동은 제거한다.)</li>
  <li><strong>Forecasting</strong> : 모델은 frequency interpolation을 통해 look-back window를 늘릴 수 있고(논문에서는 <code class="language-plaintext highlighter-rouge">extending</code>, <code class="language-plaintext highlighter-rouge">generate</code>, <code class="language-plaintext highlighter-rouge">reconstruct</code>로 표현하고 있다.) forecasting results가 된다.</li>
  <li><strong>Reconstruction</strong> : 우리는 원본 시계열을 downsampling했다가 reconstruction하게 되는데, downsampling된 segment를 원래 형태로 되돌릴 때 FITS가 사용된다. (frequency interpolation)</li>
</ul>

<h3 id="33-key-mechanisms-of-fits">3.3. Key Mechanisms of FITS</h3>

<ul>
  <li><strong>Complex Frequency Linear Interpolation</strong> : 모델의 output의 length를 조절해주기 위해서 interpolation rate를 일정하게 만들어준다. 원본 시계열의 절반 길이가 되는 frequency domain에서 interpolation을 하는데 output의 길이를 \(L_o\)로 맞춰주기 위해서는 \(\eta_{f r e q}=\frac{L_o / 2}{L_i / 2}=\frac{L_o}{L_i}=\eta\)가 되어야 한다.</li>
  <li><strong>Low Pass Filter(LPF)</strong> : 아래 그림처럼 frequency domain에서 high-frequency component에 해당하는 75%를 버리더라도 원래 시계열의 structure와 periodicity를 잘 보존한다. 왜냐하면 high-frequency component는 주기가 매우 짧은 성분들이라 노이즈에 가깝고 애초에 모델이 학습할 수 있는 영역 밖이라고 할 수 있기 때문이다.</li>
  <li><img src="/assets/img/timeseries/FITS/fig3.png" alt="사진3" /></li>
  <li><strong>Weight Sharing</strong> : 한 데이터셋 내에서 channels는 base frequency가 비슷하고 그러면 sharing weights로 효율적으로 multivariate task를 수행할 수 있다. 만약 채널마다 base frequency가 다르더라도 채널들을 클러스터링 해서 클러스터마다 개별적으로 학습하면 된다.</li>
</ul>

<h2 id="4-experiments-for-forecasting">4. Experiments for Forecasting</h2>

<h3 id="41-forecasting-as-frequency-interpolation">4.1. Forecasting as Frequency Interpolation</h3>

<ul>
  <li>일반적으로 look-back window의 길이 \(L\)이 forecasting horizon의 길이 \(H\)보다 기니까 단순하게 interpolation하기보다는 interpolation rate를 \(\eta_{\text {Fore }}=1+\frac{H}{L}\)로 한다.</li>
  <li><img src="/assets/img/timeseries/FITS/table12.png" alt="사진4" /></li>
</ul>

<h2 id="5-experiments-for-anomaly-detection">5. Experiments for Anomaly Detection</h2>

<ul>
  <li><img src="/assets/img/timeseries/FITS/table6.png" alt="사진5" /></li>
</ul>

<h2 id="6-conclusion">6. Conclusion</h2>

<ul>
  <li>Frequency interpolation으로 10k개의 parameters만으로 SOTA의 성능을 냈다.</li>
  <li>Future work : frequency domain에서의 large-scale complex-valued NN (ex. Complex-valued Transformer)</li>
</ul>]]></content><author><name>GW Jeong</name><email>wjdrjsdn39@yonsei.ac.kr</email></author><category term="timeseries" /><summary type="html"><![CDATA[[ICLR 2023](https://arxiv.org/abs/2307.03756)]]></summary></entry></feed>