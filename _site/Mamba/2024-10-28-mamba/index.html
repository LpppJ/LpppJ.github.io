<!DOCTYPE html>
<html lang="en"><!--
 __  __                __                                     __
/\ \/\ \              /\ \             __                    /\ \
\ \ \_\ \   __  __    \_\ \      __   /\_\      __       ___ \ \ \/'\
 \ \  _  \ /\ \/\ \   /'_` \   /'__`\ \/\ \   /'__`\    /'___\\ \ , <
  \ \ \ \ \\ \ \_\ \ /\ \L\ \ /\  __/  \ \ \ /\ \L\.\_ /\ \__/ \ \ \\`\
   \ \_\ \_\\/`____ \\ \___,_\\ \____\ _\ \ \\ \__/.\_\\ \____\ \ \_\ \_\
    \/_/\/_/ `/___/> \\/__,_ / \/____//\ \_\ \\/__/\/_/ \/____/  \/_/\/_/
                /\___/                \ \____/
                \/__/                  \/___/

Powered by Hydejack v9.1.6 <https://hydejack.com/>
-->







<head>
  






  
    
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Arxiv 2023) | LpppJ</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Arxiv 2023)" />
<meta name="author" content="GW Jeong" />
<meta property="og:locale" content="en" />
<meta name="description" content="Arxiv 2023" />
<meta property="og:description" content="Arxiv 2023" />
<link rel="canonical" href="http://localhost:4000/mamba/2024-10-28-mamba/" />
<meta property="og:url" content="http://localhost:4000/mamba/2024-10-28-mamba/" />
<meta property="og:site_name" content="LpppJ" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-10-28T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Arxiv 2023)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"GW Jeong"},"dateModified":"2025-01-08T22:02:54+09:00","datePublished":"2024-10-28T00:00:00+09:00","description":"Arxiv 2023","headline":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Arxiv 2023)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/mamba/2024-10-28-mamba/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/me/logo.jpg"},"name":"GW Jeong"},"url":"http://localhost:4000/mamba/2024-10-28-mamba/"}</script>
<!-- End Jekyll SEO tag -->


  

  



  <meta name="theme-color" content="rgb(230, 217, 195)">


<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta http-equiv="x-ua-compatible" content="ie=edge">

<meta name="mobile-web-app-capable" content="yes">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-title" content="LpppJ">
<meta name="apple-mobile-web-app-status-bar-style" content="default">

<meta name="application-name" content="LpppJ">

<meta name="generator" content="Hydejack v9.1.6" />


<link rel="alternate" href="http://localhost:4000/mamba/2024-10-28-mamba/" hreflang="en">

<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="LpppJ" />


<link rel="shortcut icon"    href="/assets/icons/favicon.ico">
<link rel="apple-touch-icon" href="/assets/icons/icon-192x192.png">

<link rel="manifest" href="/assets/site.webmanifest">

<link rel="dns-prefetch" href="https://fonts.googleapis.com"><link rel="dns-prefetch" href="https://fonts.gstatic.com">



<link rel="preload" href="/assets/img/swipe.svg" as="image" id="_hrefSwipeSVG">






<script>!function(r,c){"use strict";function a(e,t,n,o){e.addEventListener?e.addEventListener(t,n,o):e.attachEvent?e.attachEvent("on"+t,n):e["on"+t]=n}r.loadJS=function(e,t){var n=c.createElement("script"),e=(n.src=e,t&&a(n,"load",t,{once:!0}),c.scripts[0]);return e.parentNode.insertBefore(n,e),n},r._loaded=!1,r.loadJSDeferred=function(e,t){var n=c.createElement("script");function o(){r._loaded=!0,t&&a(n,"load",t,{once:!0});var e=c.scripts[0];e.parentNode.insertBefore(n,e)}return n.src=e,r._loaded?o():a(r,"load",o,{once:!0}),n},r.setRel=r.setRelStylesheet=function(e){a(c.getElementById(e),"load",function(){this.rel="stylesheet"},{once:!0})}}(window,document);
!function(a){"use strict";var b=function(b,c,d){function e(a){return h.body?a():void setTimeout(function(){e(a)})}function f(){i.addEventListener&&i.removeEventListener("load",f),i.media=d||"all"}var g,h=a.document,i=h.createElement("link");if(c)g=c;else{var j=(h.body||h.getElementsByTagName("head")[0]).childNodes;g=j[j.length-1]}var k=h.styleSheets;i.rel="stylesheet",i.href=b,i.media="only x",e(function(){g.parentNode.insertBefore(i,c?g:g.nextSibling)});var l=function(a){for(var b=i.href,c=k.length;c--;)if(k[c].href===b)return a();setTimeout(function(){l(a)})};return i.addEventListener&&i.addEventListener("load",f),i.onloadcssdefined=l,l(f),i};"undefined"!=typeof exports?exports.loadCSS=b:a.loadCSS=b}("undefined"!=typeof global?global:this);
!function(a){if(a.loadCSS){var b=loadCSS.relpreload={};if(b.support=function(){try{return a.document.createElement("link").relList.supports("preload")}catch(b){return!1}},b.poly=function(){for(var b=a.document.getElementsByTagName("link"),c=0;c<b.length;c++){var d=b[c];"preload"===d.rel&&"style"===d.getAttribute("as")&&(a.loadCSS(d.href,d,d.getAttribute("media")),d.rel=null)}},!b.support()){b.poly();var c=a.setInterval(b.poly,300);a.addEventListener&&a.addEventListener("load",function(){b.poly(),a.clearInterval(c)}),a.attachEvent&&a.attachEvent("onload",function(){a.clearInterval(c)})}}}(this);
!function(w) {
  w._baseURL = '/';
  w._publicPath = '/assets/js/';
  w._noPushState = false;
  w._noDrawer = false;
  w._noNavbar = false;
  w._noToc = false;
  w._noSearch = false;
  w._search = {
    DATA_URL: '/assets/sitedata.json?no-cache',
    STORAGE_KEY: 'mini-search/',
    INDEX_KEY: 'index--2025-01-08T22:03:07+09:00',
  };
  w._clapButton = true;
}(window);</script>


<script async src="/assets/bower_components/MathJax/es5/tex-mml-chtml.js" id="_MathJax"></script>


<!--[if gt IE 8]><!---->

  




<link rel="stylesheet" href="/assets/css/hydejack-9.1.6.css" id="_stylePreload">
<link rel="stylesheet" href="/assets/icomoon/style.css" id="_iconsPreload">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700%7CNoto+Sans:400,400i,700,700i&display=swap" id="_fontsPreload">



  <style id="_pageStyle">

html{--accent-color: rgb(94, 97, 94);--accent-color-faded: rgba(94, 97, 94, 0.5);--accent-color-highlight: rgba(94, 97, 94, 0.1);--accent-color-darkened: #4b4e4b;--theme-color: rgb(230, 217, 195)}
</style>


<!--<![endif]-->




</head>

<body class="no-break-layout">
  


<hy-push-state
  id="_pushState"
  replace-selector="#_main"
  link-selector="a[href]:not([href^='/assets/']):not(.external):not(.no-push-state)"
  script-selector="script"
  duration="500"
  hashchange
>
  
  
  <div id="_navbar" class="navbar fixed-top">
  <div class="content">
    <span class="sr-only">Jump to:</span>
    <div class="nav-btn-bar">
      <a id="_menu" class="nav-btn no-hover" href="#_drawer--opened">
        <span class="sr-only">Navigation</span>
        <span class="icon-menu"></span>
      </a>
      <div class="nav-span"></div>
    </div>
  </div>
</div>
<hr class="sr-only" hidden />

  <main
  id="_main"
  class="content layout-post"
  role="main"
>
  <nav id="breadcrumbs" class="screen-only"><ul>
  
  
    <li><a href="/">home</a></li>
    
      <li>
        
          <span>/</span>
          
          
          <a href="/mamba/">mamba</a>
        
      </li>
    
      <li>
        
          <span>/</span>
          <span>2024-10-28-mamba</span>
        
      </li>
    
  
</ul></nav>
  










<article id="post-mamba-mamba" class="page post mb6" role="article">
  <header>
    <h1 class="post-title flip-project-title">
      
        Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Arxiv 2023)
      
    </h1>

    <div class="post-date">
      
      <span class="ellipsis mr1">
        <time datetime="2024-10-28T00:00:00+09:00">28 Oct 2024</time> in <span>Mamba</span> 
      </span>
      
    </div>

    
    

    



  
    <p class="note-sm" >
      <a href="https://arxiv.org/pdf/2312.00752">Arxiv 2023</a>

    </p>
  


  </header>

  
    <h2 id="abstract">Abstract</h2>

<ul>
  <li>많은 subquadratic-time architectures (linear attention, gated convolution and recurrent models, and structured state space models (SSMs))가 Transformer의 연산 효율성을 해결하기 위해 제안되었지만
    <ul>
      <li>content-based reasoning에서는 여전히 약한 모습</li>
    </ul>
  </li>
  <li>그래서 본 논문에서 제시하는 Mamba는
    <ul>
      <li><strong>SSM parameters를 input의 함수 형태</strong>로 놓아서 모델이 selectively propagate or forget information 할 수 있도록 함</li>
      <li>그리고 recurrent 모드로 학습을 진행하게 되면 중간 Hidden State 크기가 매우 커질 수 있기 때문에
        <ul>
          <li><strong>hardware-aware parallel algorithm</strong>을 사용하여 hidden State를 메모리에 저장하지 않고 병렬적으로 scan 연산함</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>

<ul>
  <li><strong>Selection Mechanism</strong>
    <ul>
      <li>parameterizing the SSM parameters based on the input
        <ul>
          <li>\(\to\) 필요한 정보만 기억하고 필요없는 정보 filter out</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Hardware-aware Algorithm</strong>
    <ul>
      <li>연산 커널을 결합하는 방식(커널 융합)으로 메모리 입출력 과정을 최적화하고 오버헤드를 줄임</li>
      <li>고속 메모리(SRAM)를 활용해 느린 GPU 메모리(HBM) 의존도를 줄여 연산 속도를 높이겠다는 것</li>
      <li>backpropagation 할 때에는 hidden state를 저장하지 않고 필요할 때마다 재계산함으로써 메모리 사용량을 최소화</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/Mamba/mamba_/fig1.png" alt="그림1" /></p>

<ul>
  <li><strong>Architecture</strong>
    <ul>
      <li>기존 SSM architectures와 Transformer의 MLP blocks을 합쳐서 Mamba를 만듬</li>
    </ul>
  </li>
</ul>

<h2 id="2-state-space-models">2. State Space Models</h2>

<ul>
  <li>Structured state space sequence models (S4)
    <ul>
      <li>inspired by a particular continuous system :
        <ul>
          <li>1-dimensional function or sequence $x(t) \in \mathbb{R} \mapsto y(t) \in \mathbb{R}$ through an implicit latent state $h(t) \in \mathbb{R}^N$.</li>
          <li>\(\begin{aligned} h^{\prime}(t) &amp; =A h(t)+B x(t) \\ y(t) &amp; =C h(t)\end{aligned}\) (1)</li>
          <li>4개의 parameters \((\Delta, A, B, C)\)로 정의됨 (아직 input의 함수 형태가 아님)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Discretization</strong>
    <ul>
      <li>첫번째 단계는 “continuous parameters” \((\Delta, A, B)\)를 “discrete parameters” \((\bar{A}, \bar{B})\)로 바꾸는 것
        <ul>
          <li>fixed formulas \(\overline{A}=f_A(\Delta, A)\) and \(\overline{B}=f_B(\Delta, A, B)\)를 사용</li>
          <li>\(\left(f_A, f_B\right)\)는 discretization rule</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Computation</strong>
    <ul>
      <li>\((\Delta, A, B, C) \mapsto(\bar{A}, \bar{B}, C)\) 변환이 끝났으면 그 다음에는 다음 두 가지 형태의 computation 가능
        <ul>
          <li>a linear recurrence :
            <ul>
              <li>\(\begin{aligned} h_t &amp; =\overline{A} h_{t-1}+\overline{B} x_t \\ y_t &amp; =C h_t\end{aligned}\) (2) 또는</li>
            </ul>
          </li>
          <li>a global convolution :
            <ul>
              <li>\(\begin{aligned} \bar{K} &amp; =\left(C \bar{B}, C \overline{A B}, \ldots, C \bar{A}^k \bar{B}, \ldots\right) \\ y &amp; =x * \bar{K}\end{aligned}\) (3)</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Linear Time Invariance (LTI)</strong>
    <ul>
      <li>위 (1) (2) (3) 모델들은 model’s dynamics가 time-invariant</li>
      <li>하지만 본 논문에서는 이러한 LTI property가 근본적인 한계가 있음을 밝히고
        <ul>
          <li>LTI를 제거하면서도 efficiency bottlenecks를 극복함을 제시함</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Structure and Dimensions</strong>
    <ul>
      <li>\(A\) matrix를 사용하기 때문에 SSM인거고, 이때 \(A \in \mathbb{R}^{N \times N}, B \in \mathbb{R}^{N \times 1}, C \in \mathbb{R}^{1 \times N}\)</li>
      <li>total hidden state has dimension은: \(𝐷𝑁\) per input</li>
      <li>the sequence length requires \(𝑂(𝐵𝐿𝐷𝑁)\)</li>
    </ul>
  </li>
</ul>

<h2 id="3-selective-state-space-models">3. Selective State Space Models</h2>

<ul>
  <li>3.1절에서는 selection mechanism을 소개하고</li>
  <li>3.2절에서는 어떻게 selection mechanism이 SSM과 같이 쓰일 수 있는지 보고</li>
  <li>3.3절에서는 hardware-aware algorithm을 알아보고</li>
  <li>3.4절에서는 simple SSM을 attention이나 MLP없이 알아보고</li>
  <li>3.5절에서는 additional properties of selection mechanisms를 논의한다</li>
</ul>

<h3 id="31-motivation-selection-as-a-means-of-compression">3.1. Motivation: Selection as a Means of Compression</h3>

<ul>
  <li>sequence modeling의 본질적인 문제는 <strong>small state에 context를 압축</strong>하는 것
    <ul>
      <li>Trade off : 압축을 안하면 inefficient하고(Transformer) efficient하면 압축을 너무 많이 하고(RNN)</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/Mamba/mamba_/fig2.png" alt="그림1" /></p>

<ul>
  <li>Synthetic task 2가지
    <ul>
      <li><strong>Selective Copying</strong>
        <ul>
          <li>필요한 tokens와 아닌 것들을 구별하기 위해 content-aware reasoning하는 task</li>
        </ul>
      </li>
      <li><strong>Induction Heads</strong>
        <ul>
          <li>다음에 뭐가 올지 추론하기 위해 context-aware reasoning하는 task</li>
        </ul>
      </li>
      <li>이 두 가지는 위에서 소개한 LTI mode로는 하기 어렵다</li>
    </ul>
  </li>
  <li>결국에는 efficient하려면 small state를 가져야 하는데, 그걸 “잘” 하려면 selectivity를 “잘” 해야 함</li>
</ul>

<h3 id="32--improving-ssms-with-selection">3.2.  Improving SSMs with Selection</h3>

<ul>
  <li>본 논문에서 소개하는 selection mechanism은 model의 parameters를 input-dependent하게 만드는 것
    <ul>
      <li>\(\Delta, B, C\)을 length dimension \(L\)로 만듬 (즉 time-invariant에서 time-varying으로)</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/Mamba/mamba_/algorithm12.png" alt="그림1" /></p>

<h3 id="33-efficient-implementation-of-selective-ssms">3.3 Efficient Implementation of Selective SSMs</h3>

<ul>
  <li>Convolution이나 attention처럼 GPU-friendly하게 Selective SSM을 만들고 싶은 거고</li>
  <li>즉 시간에 따라 필요한 정보를 선택적으로 처리하겠다는 것. 그러면 더 빠르게 긴 시퀀스를 처리</li>
</ul>

<p><strong>3.3.1 Motivation of Prior Models</strong></p>

<ul>
  <li>paying speed and memory costs 없이 maximize hidden state dimension하고 싶음</li>
  <li>Recurrent mode는 hidden이 input보다 훨씬 커서 메모리 사용량이 많음
    <ul>
      <li>그래서 input의 shape (=output의 shape)과 같은 conv를 쓰겠다</li>
    </ul>
  </li>
  <li>기존 LTI는 데이터 특성을 잘 반영 못했지만 Mamba는 순환적 요소와 컨볼루션적 요소를 동시에 사용해 모델의 효율성을 극대화 !</li>
</ul>

<p><strong>3.3.2 Overview of Selective Scan: Hardware-Aware State Expansion</strong></p>

<ul>
  <li>LTI의 한계를 극복하는 selection mechanism을 소개:</li>
  <li>문제는 (1) the sequential nature of recurrence, and (2) the large memory usage
    <ul>
      <li>(2) the large memory usage는 kernel fusion으로 해결
        <ul>
          <li>scan input \((\bar{A}, \bar{B})\) of size \((B, L, D, N)\)을 HBM에 저장하는 것이 아니라</li>
          <li>the SSM parameters \((\triangle, A, B, C)\)의 final output \((B, L, D)\)만 저장</li>
          <li>discretization이랑 recurrence는 SRAM에서 수행</li>
        </ul>
      </li>
      <li>(1) the sequential nature of recurrence는 recomputation으로 해결
        <ul>
          <li>intermediate states를 저장하지 않는데 이건 backpropagation에서 필요하니까</li>
          <li>그냥 다시 계산함 (recomputation)</li>
          <li>그 결과 FlashAttention과 유사한 memory efficiency</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="34-a-simplified-ssm-architecture">3.4 A Simplified SSM Architecture</h3>

<ul>
  <li>Mamba는 linear attention과 MLP를 결합해서 gated attention unit(GAP)처럼 만듬</li>
  <li>model dimension을 D에서 expansion factor E를 사용해서 늘려줌
    <ul>
      <li>대부분의 model parameters \(3ED^2\)개 \(2ED^2\)개가 input projection에, \(ED^2\)개가 output projection에 있음</li>
      <li>반면 SSM 안에는 parameters가 별로 없는데, Mamba는 이걸 반복해서 사용하기 때문에 효율적이다</li>
    </ul>
  </li>
</ul>

<h3 id="35-properties-of-selection-mechanisms">3.5 Properties of Selection Mechanisms</h3>

<ul>
  <li>The selection mechanism은 RNN이나 CNN에 쓸 수 있는 broader concept임</li>
</ul>

<p><strong>3.5.1 Connection to Gating Mechanisms</strong></p>

<ul>
  <li>SSM의 게이트 역할을 하는 \(\Delta\)가 RNN의 게이트와 유사하게 작동
    <ul>
      <li>입력된 정보 중 어떤 것을 유지하고 어떤 것을 버릴지 결정하는 역할인 점도 비슷</li>
      <li>When $N=1, A=-1, B=1, s_{\Delta}=\operatorname{Linear}(x)$, and $\tau_{\Delta}=$ softplus,</li>
      <li>\(\begin{aligned} &amp; g_t=\sigma\left(\operatorname{Linear}\left(x_t\right)\right) \\ &amp; h_t=\left(1-g_t\right) h_{t-1}+g_t x_t\end{aligned}\) .</li>
      <li>이런 식으로 \(g_t\)가 현재 입력 \(x_t\)가 얼마나 중요한지 표현하게 하고
        <ul>
          <li>\(g_t\)가 1에 가까울수록 \(x_t\)를 많이 반영, 0에 가까울수록 이전 state \(h_{t-1}\)을 많이 반영</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><strong>3.5.2 Interpretation of Selection Mechanisms</strong></p>

<ul>
  <li><strong>Variable Spacing</strong>
    <ul>
      <li>Selectivity의 역할은 filtering out irrelevant noise tokens that may occur between inputs of interest</li>
    </ul>
  </li>
  <li><strong>Filtering Context</strong>
    <ul>
      <li>context가 길어진다고 성능이 좋아지는 것이 아님. 대부분의 모델이 너무 긴 sequence에서 불필요한 정보를 제거하지 못해서 성능 저하가 발생</li>
      <li>selective model은 state를 언제든 초기화 할 수 있으니 긴 sequence가 들어왔을 때 성능이 더 좋아지도록 작동</li>
    </ul>
  </li>
  <li><strong>Boundary Resetting</strong>
    <ul>
      <li>LTI는 sequence의 경계에서 정보가 섞이는 문제가 있었는데, selective SSM은 그런 문제 없음
        <ul>
          <li>언제든지 state를 초기화할 수 있으니 그냥 boundaries에서 초기화 하면 됨 (\(g_t=1\))</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Interpretation of \(\Delta\)</strong>
    <ul>
      <li>\(\Delta\)가 크면 다 잊고 현재 정보를 위주로 state를 만드는거고, 작으면 이전 state를 유지</li>
    </ul>
  </li>
  <li><strong>Interpretation of A</strong>
    <ul>
      <li>사실 \(\bar{A}=\exp (\Delta A)\)도 \(\Delta\)를 통해 만들어지니 크게 건드리지 말고 단순하게 둔다</li>
    </ul>
  </li>
  <li><strong>Interpretation of 𝑩 and 𝑪.</strong>
    <ul>
      <li>결국 Selectivity의 역할은 filtering out.</li>
      <li>B와 C는 입력을 상태로 전달할지, 상태를 출력으로 내보낼지를 결정</li>
      <li>모델이 state(context)를 더 세밀하게 제어할 수 있음</li>
    </ul>
  </li>
</ul>

<h3 id="36-additional-model-details">3.6 Additional Model Details</h3>

<p>pass</p>

<h2 id="4-empirical-evaluation">4. Empirical Evaluation</h2>

<h3 id="41-synthetic-tasks">4.1 Synthetic Tasks</h3>

<p><strong>4.1.1 Selective Copying</strong></p>

<p><strong>4.1.2 Induction Heads</strong></p>

<p><img src="/assets/img/Mamba/mamba_/table12.png" alt="그림1" /></p>

<h3 id="42-language-modeling">4.2. Language Modeling</h3>

<p><img src="/assets/img/Mamba/mamba_/table3.png" alt="그림1" /></p>

<h3 id="45-speed-and-memory-benchmarks">4.5 Speed and Memory Benchmarks</h3>

<p><img src="/assets/img/Mamba/mamba_/fig8.png" alt="그림1" /></p>

<h3 id="46-model-ablations">4.6. Model Ablations</h3>

<p><img src="/assets/img/Mamba/mamba_/table6.png" alt="그림1" /></p>

<p><img src="/assets/img/Mamba/mamba_/table78.png" alt="그림1" /></p>

<h2 id="5-discussion">5. Discussion</h2>

<p>Pass</p>

<h2 id="6-conclusion">6. Conclusion</h2>

<ul>
  <li>a selection mechanism to structured state space models
    <ul>
      <li>to perform context-dependent reasoning</li>
      <li>Without attention ! (simple attention-free architecture)</li>
    </ul>
  </li>
</ul>

  
</article>



  <hr class="dingbat related mb6" />






  
     


  <aside class="about related mt4 mb4" role="complementary">
    
    

<div class="author mt4">
  

  
    


<img
  
    src="https://via.placeholder.com/128x128"
    srcset="/assets/img/me/me.JPG 1x,/assets/img/me/me.JPG 2x"
    
  
  alt="GW Jeong"
  class="avatar"
  
  width="120"
  height="120"
  loading="lazy"
/>

  

  
  
  <h2  class="page-title hr-bottom">
    About
  </h2>

  <p>Bachelor’s degree in Applied Statistics. Yonsei Univ. (2018~2024) <br />
DataScienceLab 8th 학회장 (2022~2023) <br />
Master’s degree in Statitstics. Yonsei Univ. (2024~)</p>


  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/lpppj" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="mailto:wjdrjsdn39@yonsei.ac.kr" title="Email" class="no-mark-external">
      <span class="icon-mail"></span>
      <span class="sr-only">Email</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>

  </aside>


  

  
  

  
    


  

  
  

  
    

  


  
<footer class="content" role="contentinfo">
  <hr/>
  
    <p><small class="copyright">© Geonwoo Jeong.
</small></p>
  
  
    <p><small>Powered by <a class="external" href="https://hydejack.com/">Hydejack</a> v<span id="_version">9.1.6</span></small></p>
  <hr class="sr-only"/>
</footer>


</main>

  <hy-drawer
  id="_drawer"
  class=""
  side="left"
  threshold="10"
  noscroll
  
>
  <header id="_sidebar" class="sidebar" role="banner">
    




<div class="sidebar-bg sidebar-overlay" style="background-color:rgb(230, 217, 195);background-image:url(/assets/img/me/sidebar.jpg)"></div>

    <div class="sidebar-sticky">
  <div class="sidebar-about">
    
      <a class="no-hover" href="/" tabindex="-1">
        <img src="/assets/img/me/logo.jpg" class="avatar" alt="LpppJ" width="120" height="120" loading="lazy" />
      </a>
    
    <a class="sidebar-title" href="/"><h2 class="h1">LpppJ</h2></a>
    
    
      <p class="">
        DataScience and AI

      </p>
    
  </div>

  <nav class="sidebar-nav heading" role="navigation">
    <span class="sr-only">Navigation:</span>
<ul>
  
    
      
      <li>
        <a
          id="_drawer--opened"
          href="/timeseries/"
          class="sidebar-nav-item "
          
        >
          TimeSeries
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/mamba/"
          class="sidebar-nav-item "
          
        >
          Mamba
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/pytorch/"
          class="sidebar-nav-item "
          
        >
          Pytorch
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/stat/"
          class="sidebar-nav-item "
          
        >
          Statistics
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/project/"
          class="sidebar-nav-item "
          
        >
          Project
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/presentation/"
          class="sidebar-nav-item "
          
        >
          Presentation
        </a>
      </li>
    
  
</ul>

  </nav>

  
  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/lpppj" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="mailto:wjdrjsdn39@yonsei.ac.kr" title="Email" class="no-mark-external">
      <span class="icon-mail"></span>
      <span class="sr-only">Email</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>
  </header>
</hy-drawer>
<hr class="sr-only" hidden />

</hy-push-state>


  <!--[if gt IE 10]><!---->
  <script nomodule>!function(){var t,n=document.createElement("script");!("noModule"in n)&&"onbeforeload"in n&&(t=!1,document.addEventListener("beforeload",function(e){if(e.target===n)t=!0;else if(!e.target.hasAttribute("nomodule")||!t)return;e.preventDefault()},!0),n.type="module",n.src=".",document.head.appendChild(n),n.remove())}();
</script>
  <script src="/assets/js/hydejack-9.1.6.js" type="module"></script>
  <script src="/assets/js/LEGACY-hydejack-9.1.6.js" nomodule defer></script>
  

  

<!--<![endif]-->
  <!-- <script>
  document.querySelector('hy-push-state').setAttribute('prefetch', '');

  document.querySelectorAll('.sidebar a[href^="/"]').forEach(function (el) { 
    el.addEventListener('click', function (e) {
      if (el.pathname === window.location.pathname) {
        e.preventDefault();
        e.stopPropagation();
        document.querySelector('hy-drawer').close();
      }
    });
  });
</script> -->

<!--
Code for integrating CloudFlare's email protection with Hydejack's single page app loading.
-->
<script>
  document.getElementById('_pushState').addEventListener('hy-push-state-after', function (e) {
    function e(e){
      (console.error?console.error:console.log).call(console,e)
    }

    function t(e){
      return l.innerHTML='<a href="'+e.replace(/"/g,"&quot;")+'"></a>',l.childNodes[0].getAttribute("href")
    }

    function r(e,t){
      var r=e.substr(t,2);return parseInt(r,16)
    }

    function n(e,n){
      for(var o="",c=r(e,n),a=n+2;a<e.length;a+=2){
        var l=r(e,a)^c;
        o+=String.fromCharCode(l)
      }
      return t(o)
    }

    var o="/cdn-cgi/l/email-protection#",
        c=".__cf_email__",
        a="data-cfemail",
        l=document.createElement("div");

    !function(){
      for(var t=document.getElementsByTagName("a"),r=0;r<t.length;r++)
        try{
          var c=t[r],a=c.href.indexOf(o);
          a>-1&&(c.href="mailto:"+n(c.href,a+o.length))
        }catch(t){
          e(t)
        }
    }(),
    function(){
      for(var t=document.querySelectorAll(c),r=0;r<t.length;r++)
        try{
          var o=t[r],l=n(o.getAttribute(a),0),i=document.createTextNode(l);
          o.parentNode.replaceChild(i,o)
        }catch(t){
          e(t)
        }
    }()
  });
</script>





<div hidden>
  
  <h2 class="sr-only">Templates (for web app):</h2>

  <template id="_animation-template">
  <div class="animation-main fixed-top">
    <nav id="breadcrumbs" class="screen-only"><ul>
  
  
</ul></nav>
    <div class="content">
      <div class="page"></div>
    </div>
  </div>
</template>

  <template id="_loading-template">
  <div class="loading nav-btn fr">
    <span class="sr-only">Loading…</span>
    <span class="icon-cog"></span>
  </div>
</template>

  <template id="_error-template">
  <div class="page">
    <h1 class="page-title">Error</h1>
    
    
    <p class="lead">
      Sorry, an error occurred while loading <a class="this-link" href=""></a>.

    </p>
  </div>
</template>

  <template id="_permalink-template">
  <a href="#" class="permalink">
    <span class="sr-only">Permalink</span>
    <span class="content-hash"></span>
  </a>
</template>

</div>


</body>
</html>
