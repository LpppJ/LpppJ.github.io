<h2 id="abstract">Abstract</h2>
<ul>
  <li>Financial deep learning 모델을 훈련시키기 위한 데이터가 부족한데, 그렇다고 synthetic data를 만들어내려 하니 irregular and scale-invariant patterns 때문에 어려움이 있음</li>
  <li>패턴이 irregular하다는 말은 패턴이 발생하는 간격이 일정하지 않아서 예측하기 어렵다는 것</li>
  <li>패턴이 scale-invariant하다는 말은 scale을 변화시켜도 형태가 유지된다는 말인데, 특정 패턴이 다양한 너비(폭)나 높이(진폭)로 나타날 수 있다는 말이다. 또한 프랙탈 구조처럼 축소해도 비슷한 패턴이 보이게 된다.</li>
  <li>본 논문에서는 irregular and scale-invariant patterns을 학습하고 생성하는 모델 FTS-Diffusion을 제시한다.</li>
</ul>

<p><img src="/assets/img/timeseries/fts-diff/fig1.jpeg" alt="사진1" />
<img src="/assets/img/timeseries/fts-diff/fig2.jpeg" alt="사진2" /></p>

<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>FTS-Diffusion은 3가지의 modules로 구성된다.</li>
  <li>Pattern recognition - Pattern generation - Pattern evolution</li>
  <li>패턴을 인식하고, 패턴을 생성한 뒤, 패턴을 이어붙여서 하나의 time series를 만든다는 것이다. 기존 time series generation 모델들이 어려워하던 irregular and scale-invariant 패턴을 모델링할 수 있다.</li>
</ul>

<h2 id="2-related-work">2. Related Work</h2>
<ul>
  <li>본 논문에서 제시하는 모델은 time series를 생성하는 모델이다. 생성 모델은 크게 VAE 계열, GAN 계열, Diffusion 계열이 있다.</li>
</ul>

<p><img src="/assets/img/timeseries/fts-diff/gm.jpeg" alt="사진3" /></p>

<ul>
  <li>일반적으로 좋은 생성 모델을 3가지 특성으로 정의하는데, 세 가지 모두 뛰어난 모델은 없고 상대적인 장단점이 존재한다.</li>
  <li>Diffusion이 속도는 상대적으로 느리지만 높은 퀄리티와 다양성 측면에서 뛰어나 많은 주목 받았고, 본 논문에서도 diffusion을 사용한다.</li>
</ul>

<h2 id="3-problem-statement">3. Problem Statement</h2>
<ul>
  <li>시계열 \(X=\{x_1,...,x_M\}\)은 \(M\)개의 segments로 이루어지고 \(x_m=\{x_{m,1},...,x_{m,t_m}\}\) 각 segment의 길이는 \(t_m\)</li>
  <li>conditional distribution \(f(\cdot\mid p,\alpha,\beta)\)에서 샘플링을 하는 것이고, \(p\)는 패턴, \(\alpha\)는 duration, \(\beta\)는 magnitude이다.</li>
  <li>tuple \((p,\alpha,\beta)\)는 하나의 state이고, 패턴끼리의 dynamic across를 모델링하기 위해 Markov chain을 사용한다. 즉 transition probability \(Q(p_j,\alpha_j,\beta_j \mid p_i,\alpha_i,\beta_i)\)를 통해 time series를 생성한다.</li>
  <li>이제 FTS-Diffusion의 각 모듈을 다시 살펴보면 아래와 같다.
    <ul>
      <li>Pattern recognition : 패턴 \(p\)를 인식하고 반복되는 패턴의 구조 \(\cal P\) 학습</li>
      <li>Pattern Generation : conditional distribution \(f(\cdot\mid p,\alpha,\beta), \forall p \in \cal P\) 학습</li>
      <li>Pattern Evolution : pattern transition probability \(Q(p_j,\alpha_j,\beta_j \mid p_i,\alpha_i,\beta_i)\) 학습</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/timeseries/fts-diff/fig3.jpeg" alt="사진4" /></p>

<h2 id="4-framework">4. Framework</h2>

<h3 id="1-pattern-recognition">(1) Pattern recognition</h3>
<ul>
  <li>전체 time series를 여러 개의 segments로 나누고 비슷한 segments끼리 묶어 K개의 clusters를 만드는 알고리즘 (Scale-Invariant Subsequence Clustering, SISC)</li>
  <li>SISC는 각 segment의 length는, 가장 가까운 centriod와의 거리가 최소가 되는 segment length로 결정한다.</li>
  <li>이 때 거리 metric은 일반적으로 사용하는 euclidean이 아니라 length나 magnitude에 구애받지 않는 dynamic time wraping (DTW)를 사용하였다.</li>
  <li>centroid initialization은 처음 1개만 랜덤하게 고른 뒤 먼 segment일수록 다음 centroid가 될 확률이 높도록 하였다. (k-Center-Greedy와 비슷)</li>
</ul>

<p><img src="/assets/img/timeseries/fts-diff/fig4.jpeg" alt="사진5" /></p>

<h3 id="2-pattern-generation">(2) Pattern generation</h3>
<ul>
  <li>패턴에 gaussian noise를 씌우고 denoising gradient를 학습하는 DDPM의 방식을 사용하여 패턴을 생성하였다.</li>
  <li>Diffusion으로 생성된 패턴을 (scaling) autoencoder에 통과시켜 원하는 length로 transform한다.</li>
  <li>Objective를 아래 식으로 사용하여 diffusion 모델과 autoencoder를 같이 학습시킨다.
\(\mathcal{L}(\theta)=\mathbb{E}_{\boldsymbol{x}_m}\left[\left\|\boldsymbol{x}_m-\hat{\boldsymbol{x}}_m\right\|_2^2\right]+\mathbb{E}_{\boldsymbol{x}_m^0, i, \epsilon}\left[\left\|\epsilon^i-\epsilon_\theta\left(\boldsymbol{x}_m^{i+1}, i, \boldsymbol{p}\right)\right\|_2^2\right]\)</li>
</ul>

<h3 id="3-pattern-generation">(3) Pattern generation</h3>
<ul>
  <li>Pattern evolution network \(\phi\)는 현재 state가 주어졌을 때 다음 state에 올 패턴들의 확률을 학습한다.
\((\hat p_{m+1}, \hat \alpha_{m+1}, \hat \beta_{m+1}) = \phi(p_m, \alpha_m, \beta_m)\)</li>
  <li>Pattern evolution objective는 아래와 같다.
\(\mathcal{L}(\phi)=\mathbb{E}_{\boldsymbol{x}_m}\left[\ell_{C E}\left(p_{m+1}, \hat{p}_{m+1}\right)+\left\|\alpha_{m+1}-\hat{\alpha}_{m+1}\right\|_2^2+\left\|\beta_{m+1}-\hat{\beta}_{m+1}\right\|_2^2\right]\)</li>
</ul>

<h2 id="4-experiments">4. Experiments</h2>
<ul>
  <li>S&amp;P500, GOOG, ZC=F(옥수수 선물) 데이터를 활용하였고, 자산 가격은 non-stationary random walk를 따른다고 알려져있으므로, 통계적 특성을 가지는 수익률(return)을 사용하였다.</li>
</ul>

<p><img src="/assets/img/timeseries/fts-diff/table1.jpeg" alt="사진6" /></p>

<ul>
  <li>위 결과는 실제 return의 분포와 synthesized 분포의 적합도를 테스트하는 KS test와 AD test 결과이다.</li>
</ul>

<p><img src="/assets/img/timeseries/fts-diff/fig6.jpeg" alt="사진7" /></p>

<ul>
  <li>Mixed data(생성된 synthesized data + 실제 observed data)로 training을 하고 real data로 test를 했을 때에도(TMTR, TATR), mixed data의 비율이 달라졌을 때에도 예측 성능이 일정하다는 것으로부터 FTS-Diffusion으로 생성한 synthesized data가 observed data와 유사하다고 볼 수 있다.</li>
</ul>

<h2 id="5-conclusion">5. Conclusion</h2>
<ul>
  <li>Pattern recognition : SISC designed to identify patterns</li>
  <li>Pattern generation : diffusion-based network to synthesize the segments of patterns</li>
  <li>Pattern evolution : assemble generated segments with proper temporal evoution</li>
</ul>

<h2 id="implementation">Implementation</h2>
<ul>
  <li>under review</li>
</ul>
