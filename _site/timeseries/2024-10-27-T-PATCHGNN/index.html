<!DOCTYPE html>
<html lang="en"><!--
 __  __                __                                     __
/\ \/\ \              /\ \             __                    /\ \
\ \ \_\ \   __  __    \_\ \      __   /\_\      __       ___ \ \ \/'\
 \ \  _  \ /\ \/\ \   /'_` \   /'__`\ \/\ \   /'__`\    /'___\\ \ , <
  \ \ \ \ \\ \ \_\ \ /\ \L\ \ /\  __/  \ \ \ /\ \L\.\_ /\ \__/ \ \ \\`\
   \ \_\ \_\\/`____ \\ \___,_\\ \____\ _\ \ \\ \__/.\_\\ \____\ \ \_\ \_\
    \/_/\/_/ `/___/> \\/__,_ / \/____//\ \_\ \\/__/\/_/ \/____/  \/_/\/_/
                /\___/                \ \____/
                \/__/                  \/___/

Powered by Hydejack v9.1.6 <https://hydejack.com/>
-->







<head>
  






  
    
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>T-PATCHGNN: Irregular Multivariate Time Series Forecasting: A Transformable Patching Graph Neural Networks Approach (ICML 2024) | LpppJ</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="T-PATCHGNN: Irregular Multivariate Time Series Forecasting: A Transformable Patching Graph Neural Networks Approach (ICML 2024)" />
<meta name="author" content="GW Jeong" />
<meta property="og:locale" content="en" />
<meta name="description" content="ICML 2024" />
<meta property="og:description" content="ICML 2024" />
<link rel="canonical" href="http://localhost:4000/timeseries/2024-10-27-T-PATCHGNN/" />
<meta property="og:url" content="http://localhost:4000/timeseries/2024-10-27-T-PATCHGNN/" />
<meta property="og:site_name" content="LpppJ" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-10-27T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="T-PATCHGNN: Irregular Multivariate Time Series Forecasting: A Transformable Patching Graph Neural Networks Approach (ICML 2024)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"GW Jeong"},"dateModified":"2024-10-27T11:03:31+09:00","datePublished":"2024-10-27T00:00:00+09:00","description":"ICML 2024","headline":"T-PATCHGNN: Irregular Multivariate Time Series Forecasting: A Transformable Patching Graph Neural Networks Approach (ICML 2024)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/timeseries/2024-10-27-T-PATCHGNN/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/me/logo.jpg"},"name":"GW Jeong"},"url":"http://localhost:4000/timeseries/2024-10-27-T-PATCHGNN/"}</script>
<!-- End Jekyll SEO tag -->


  

  



  <meta name="theme-color" content="rgb(230, 217, 195)">


<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta http-equiv="x-ua-compatible" content="ie=edge">

<meta name="mobile-web-app-capable" content="yes">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-title" content="LpppJ">
<meta name="apple-mobile-web-app-status-bar-style" content="default">

<meta name="application-name" content="LpppJ">

<meta name="generator" content="Hydejack v9.1.6" />


<link rel="alternate" href="http://localhost:4000/timeseries/2024-10-27-T-PATCHGNN/" hreflang="en">

<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="LpppJ" />


<link rel="shortcut icon"    href="/assets/icons/favicon.ico">
<link rel="apple-touch-icon" href="/assets/icons/icon-192x192.png">

<link rel="manifest" href="/assets/site.webmanifest">

<link rel="dns-prefetch" href="https://fonts.googleapis.com"><link rel="dns-prefetch" href="https://fonts.gstatic.com">



<link rel="preload" href="/assets/img/swipe.svg" as="image" id="_hrefSwipeSVG">






<script>!function(r,c){"use strict";function a(e,t,n,o){e.addEventListener?e.addEventListener(t,n,o):e.attachEvent?e.attachEvent("on"+t,n):e["on"+t]=n}r.loadJS=function(e,t){var n=c.createElement("script"),e=(n.src=e,t&&a(n,"load",t,{once:!0}),c.scripts[0]);return e.parentNode.insertBefore(n,e),n},r._loaded=!1,r.loadJSDeferred=function(e,t){var n=c.createElement("script");function o(){r._loaded=!0,t&&a(n,"load",t,{once:!0});var e=c.scripts[0];e.parentNode.insertBefore(n,e)}return n.src=e,r._loaded?o():a(r,"load",o,{once:!0}),n},r.setRel=r.setRelStylesheet=function(e){a(c.getElementById(e),"load",function(){this.rel="stylesheet"},{once:!0})}}(window,document);
!function(a){"use strict";var b=function(b,c,d){function e(a){return h.body?a():void setTimeout(function(){e(a)})}function f(){i.addEventListener&&i.removeEventListener("load",f),i.media=d||"all"}var g,h=a.document,i=h.createElement("link");if(c)g=c;else{var j=(h.body||h.getElementsByTagName("head")[0]).childNodes;g=j[j.length-1]}var k=h.styleSheets;i.rel="stylesheet",i.href=b,i.media="only x",e(function(){g.parentNode.insertBefore(i,c?g:g.nextSibling)});var l=function(a){for(var b=i.href,c=k.length;c--;)if(k[c].href===b)return a();setTimeout(function(){l(a)})};return i.addEventListener&&i.addEventListener("load",f),i.onloadcssdefined=l,l(f),i};"undefined"!=typeof exports?exports.loadCSS=b:a.loadCSS=b}("undefined"!=typeof global?global:this);
!function(a){if(a.loadCSS){var b=loadCSS.relpreload={};if(b.support=function(){try{return a.document.createElement("link").relList.supports("preload")}catch(b){return!1}},b.poly=function(){for(var b=a.document.getElementsByTagName("link"),c=0;c<b.length;c++){var d=b[c];"preload"===d.rel&&"style"===d.getAttribute("as")&&(a.loadCSS(d.href,d,d.getAttribute("media")),d.rel=null)}},!b.support()){b.poly();var c=a.setInterval(b.poly,300);a.addEventListener&&a.addEventListener("load",function(){b.poly(),a.clearInterval(c)}),a.attachEvent&&a.attachEvent("onload",function(){a.clearInterval(c)})}}}(this);
!function(w) {
  w._baseURL = '/';
  w._publicPath = '/assets/js/';
  w._noPushState = false;
  w._noDrawer = false;
  w._noNavbar = false;
  w._noToc = false;
  w._noSearch = false;
  w._search = {
    DATA_URL: '/assets/sitedata.json?no-cache',
    STORAGE_KEY: 'mini-search/',
    INDEX_KEY: 'index--2024-10-29T21:24:52+09:00',
  };
  w._clapButton = true;
}(window);</script>


<script async src="/assets/bower_components/MathJax/es5/tex-mml-chtml.js" id="_MathJax"></script>


<!--[if gt IE 8]><!---->

  




<link rel="stylesheet" href="/assets/css/hydejack-9.1.6.css" id="_stylePreload">
<link rel="stylesheet" href="/assets/icomoon/style.css" id="_iconsPreload">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700%7CNoto+Sans:400,400i,700,700i&display=swap" id="_fontsPreload">



  <style id="_pageStyle">

html{--accent-color: rgb(94, 97, 94);--accent-color-faded: rgba(94, 97, 94, 0.5);--accent-color-highlight: rgba(94, 97, 94, 0.1);--accent-color-darkened: #4b4e4b;--theme-color: rgb(230, 217, 195)}
</style>


<!--<![endif]-->




</head>

<body class="no-break-layout">
  


<hy-push-state
  id="_pushState"
  replace-selector="#_main"
  link-selector="a[href]:not([href^='/assets/']):not(.external):not(.no-push-state)"
  script-selector="script"
  duration="500"
  hashchange
>
  
  
  <div id="_navbar" class="navbar fixed-top">
  <div class="content">
    <span class="sr-only">Jump to:</span>
    <div class="nav-btn-bar">
      <a id="_menu" class="nav-btn no-hover" href="#_drawer--opened">
        <span class="sr-only">Navigation</span>
        <span class="icon-menu"></span>
      </a>
      <div class="nav-span"></div>
    </div>
  </div>
</div>
<hr class="sr-only" hidden />

  <main
  id="_main"
  class="content layout-post"
  role="main"
>
  <nav id="breadcrumbs" class="screen-only"><ul>
  
  
    <li><a href="/">home</a></li>
    
      <li>
        
          <span>/</span>
          
          
          <a href="/timeseries/">timeseries</a>
        
      </li>
    
      <li>
        
          <span>/</span>
          <span>2024-10-27-T-PATCHGNN</span>
        
      </li>
    
  
</ul></nav>
  










<article id="post-timeseries-T-PATCHGNN" class="page post mb6" role="article">
  <header>
    <h1 class="post-title flip-project-title">
      
        T-PATCHGNN: Irregular Multivariate Time Series Forecasting: A Transformable Patching Graph Neural Networks Approach (ICML 2024)
      
    </h1>

    <div class="post-date">
      
      <span class="ellipsis mr1">
        <time datetime="2024-10-27T00:00:00+09:00">27 Oct 2024</time> in <span>Timeseries</span> 
      </span>
      
    </div>

    
    

    



  
    <p class="note-sm" >
      <a href="https://openreview.net/pdf?id=UZlMXUGI6e">ICML 2024</a>

    </p>
  


  </header>

  
    <h2 id="abstract">Abstract</h2>

<ul>
  <li>Transformable Patching Graph Neural Networks (T-PATCHGNN)
    <ul>
      <li>transforms each univariate irregular time series into a series of transformable patches</li>
      <li>local semantics capture와, inter-time series correlation modeling는 하면서</li>
      <li>avoiding sequence <strong>length explosion</strong> in aligned IMTS (무슨 의미인지 1. introduction (3)에서 설명)</li>
    </ul>
  </li>
  <li>Time-adaptive graph neural networks으로 time-varying adaptive graphs를 학습해서
    <ul>
      <li>dynamic intertime series correlation를 표현</li>
    </ul>
  </li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>

<ul>
  <li>Multivariate Time Series (IMTS)의 특징은 irregular sampling intervals and missing data</li>
  <li>Irregularity within the series and asynchrony 때문에 다루기 어려움
    <ul>
      <li>ODE로 풀려고 한 적은 있지만 numerical integration process으로 인해 computationally expensive</li>
    </ul>
  </li>
  <li>IMTS forecasting의 어려움에는 3가지 이유가 있음</li>
  <li>첫번째는 (1) irregularity in intra-time series dependency modeling
    <ul>
      <li><strong>varying time intervals</strong> between adjacent observations이 the consistent flow of time series data를 방해</li>
    </ul>
  </li>
  <li>두번째는 (2) asynchrony in intertime series correlation modeling
    <ul>
      <li><strong>misaligned at time</strong> due to irregular sampling or missing data.</li>
    </ul>
  </li>
  <li>가장 중요한 건 (3) sequence length explosion with the increase of variables
    <ul>
      <li>아래 fig1처럼 “단 하나의 변수라도 기록된 time stamp”는 모두 존재하는 걸로 해버리면, 변수 개수가 늘어남에 다라 time stamps의 수가 너무 많아지는 문제. (이러한 방법을 canonical pre-alignment representation이라고 부름)</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/timeseries/TPatchGNN/fig1.png" alt="그림1" /></p>

<ul>
  <li>그래서 본 논문에서 제시하는 T-PATCHGNN의 장점은
    <ul>
      <li>첫째로 The independent patching process for each univariate irregular time series으로 representation에서 sequence length explosion의 risk를 없애고</li>
      <li>둘째로 local semantics를 잘 잡기 위해 putting each individual observation into patches with richer context</li>
      <li>셋째로 transformable patching 후에 IMTS is naturally aligned in a consistent patch-level temporal resolution</li>
    </ul>
  </li>
  <li>본 논문의 contribution은 :
    <ul>
      <li>New transformable patching method to transform each univariate irregular time series of IMTS into a series of variable-length yet time-aligned patches</li>
      <li>transformable patching outcomes을 바탕으로,  time-adaptive graph neural networks를 제안</li>
      <li>building a benchmark for IMTS forecasting evaluation</li>
    </ul>
  </li>
</ul>

<h2 id="2-related-works">2, Related Works</h2>

<h3 id="21-irregular-multivariate-time-series-forecasting">2.1. Irregular Multivariate Time Series Forecasting</h3>

<p>pass</p>

<h3 id="22-irregular-multivariate-time-series-representation">2.2. Irregular Multivariate Time Series Representation</h3>

<ul>
  <li>기존에는 time-aligned manner로 IMTS를 representation (pre-alignment representation method)
    <ul>
      <li>즉 하나의 변수라고 기록된 time stamp는 존재하는 걸로 생각하니</li>
      <li>sequence length that equals the number of all unique time stamps in IMTS</li>
      <li>예를 들어 변수 1은 1,3,5 시점에 기록되고 변수 2는 2,4,6 시점에 기록되면 unique time stamps의 개수는 6이 됨</li>
      <li>sequence length explosion problem 발생</li>
    </ul>
  </li>
</ul>

<h3 id="23-graph-neural-networks-for-multivariate-time-series">2.3. Graph Neural Networks for Multivariate Time Series</h3>

<ul>
  <li>
    <p>2018년 DCRNN, STGCN은 pre-defined graph structures를 사용해서 실제로 쓰기 어려웠고</p>
  </li>
  <li>2019년부터 data로부터 graph structures를 학습하는 방식을 사용
    <ul>
      <li>하지만 IMTS에서는 잘 작동을 안 함. mimisalignment at times으로 인해 inter-time series correlation modeling이 잘 안 됨</li>
    </ul>
  </li>
  <li>Raindrop(2021)[<a href="https://lpppj.github.io/timeseries/2024-02-09-Raindrop">paper review</a>]
    <ul>
      <li>이 문제를 propagation the asynchronous observations at all the timestamps로 해결하려고 했지만  sequence length explosion problem을 피할 수 없음</li>
    </ul>
  </li>
</ul>

<h2 id="3-preliminary">3. Preliminary</h2>

<h3 id="31-problem-definition">3.1. Problem Definition</h3>

<h3 id="definition-1">Definition 1</h3>

<ul>
  <li>Irregular Multivariate Time Series
    <ul>
      <li>\(\mathcal{O}=\left\{\mathbf{o}_{1: L_n}^n\right\}_{n=1}^N=\left\{\left[\left(t_i^n, x_i^n\right)\right]_{i=1}^{L_n}\right\}_{n=1}^N\), where</li>
      <li>\(N\)개의 변수가 있고 \(n\)번째 변수는 \(L_n\)개의 observations가 있고, \(n\)번째 변수의 \(i\)번째 변수의 값은 \(t_i^n\)</li>
    </ul>
  </li>
</ul>

<h3 id="definition-2">Definition 2</h3>

<ul>
  <li>Forecasting Query \(q_j^n\)
    <ul>
      <li>\(j\)-th query on \(n\)-th variable to predict its corresponding value at a future time \(q_j^n\)</li>
    </ul>
  </li>
</ul>

<h3 id="problem-1">Problem 1</h3>

<ul>
  <li>Irregular Multivariate Time Series Forecasting
    <ul>
      <li>IMTS \(\mathcal{O} =  \left\{\left[\left(t_i^n, x_i^n\right)\right]_{i=1}^{L_n}\right\}_{n=1}^N\)와 Forecasting query \(\mathcal{Q}=\left\{\left[q_j^n\right]_{j=1}^{Q_n}\right\}_{n=1}^N\)가 있을 때,</li>
      <li>problem은 accurately forecast recorded values \(\hat{\mathcal{X}}=\left\{\left[\hat{x}_j^n\right]_{j=1}^{Q_n}\right\}_{n=1}^N\) in correspondence to the forecasting queries</li>
      <li>\(\mathcal{F}(\mathcal{O}, \mathcal{Q}) \longrightarrow \hat{\mathcal{X}}\)로 표현됨</li>
    </ul>
  </li>
</ul>

<h3 id="32-canonical-pre-alignment-representation-for-imts">3.2. Canonical Pre-Alignment Representation for IMTS</h3>

<ul>
  <li>2.2. Irregular Multivariate Time Series Representation 참고</li>
</ul>

<h2 id="4-methodology">4. Methodology</h2>

<p><img src="/assets/img/timeseries/TPatchGNN/fig2.png" alt="그림1" /></p>

<h3 id="41-irregular-time-series-patching">4.1. Irregular Time Series Patching</h3>

<ul>
  <li>모든 univariate TS에 같은 patching operation을 하니까 변수 index 표기는 생략</li>
</ul>

<h3 id="411-transformable-patching">4.1.1. TRANSFORMABLE PATCHING</h3>

<ul>
  <li>Time series patching이 forecasting에 좋은 방법이라는 건 알려진 사실. benefits in :
    <ul>
      <li>capturing local semantic information,</li>
      <li>reducing computation and memory usage,</li>
      <li>modeling longer-range historical observations</li>
    </ul>
  </li>
  <li>일반적으로 time series patching은 하나의 patch에 같은 숫자의 observations가 있는데,
    <ul>
      <li>IMTS에서 time intervals는 다양하기 때문에 이러한 방식이 적절하지 않음</li>
    </ul>
  </li>
  <li>그래서 patch에 같은 개수의 observataions가 아니라, unified time horizon이 들어가도록 함
    <ul>
      <li>patch 안에 들어가는 observations의 개수는 다를 수 있지만, ex) 2시간인 건 동일하도록</li>
    </ul>
  </li>
  <li>patch는 \(\left[\mathbf{o}_{l_p: r_p}\right]_{p=1}^P\)로 표현되고 \(P\)</li>
</ul>

<h3 id="412-patch-encoding">4.1.2. PATCH ENCODING</h3>

<ul>
  <li><strong>Continuous time embedding</strong>
    <ul>
      <li>\(\phi(t)[d]=\left\{\begin{array}{lll}
\omega_0 \cdot t+\alpha_0, &amp; \text { if } &amp; d=0 \\
\sin \left(\omega_d \cdot t+\alpha_d\right), &amp; \text { if } &amp; 0&lt;d&lt;D_t
\end{array}\right.\).
        <ul>
          <li>where the \(\omega_d\) and \(\alpha_d\) are learnable parameters and \(D_t\) is embedding’s dimension</li>
        </ul>
      </li>
      <li>Concatenation하면 observations in the patch:
        <ul>
          <li>\(\mathbf{z}_{l_p: r_p}=\left[z_i\right]_{i=l_p}^{r_p}=\left[\phi\left(t_i\right) \| x_i\right]_{i=l_p}^{r_p}\).</li>
          <li>이건 하나의 patch에 대한 표현이 되는 것 !</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Transformable time-aware convolution</strong>
    <ul>
      <li>input sequence의 길이에 맞게 (adaptively), generated parameters와 transformable filter size를 사용</li>
      <li>\(\mathbf{f}_d=\left[\frac{\exp \left(\mathbf{F}_d\left(z_i\right)\right)}{\sum_{j=1}^{L_p} \exp \left(\mathbf{F}_d\left(z_j\right)\right)}\right]_{i=1}^{L_p}\)으로 표현됨
        <ul>
          <li>where \(L_p\) is the sequence length of patch \(\mathbf{z}_{l_p: r_p}, \mathbf{f}_d \in \mathbb{R}^{L_p \times D_{i n}}\) is the derived filter for \(d\)-th feature map, \(D_{i n}\) is dimension of inputs, and \(\mathbf{F}_d\) denotes the meta-filter that can be instantiated by learnable neural networks</li>
          <li>이건 filter의 parameters를 along the temporal dimension으로 normalizaing해서 consistent scaling 하겠다는 것</li>
        </ul>
      </li>
      <li>위 식으로 \(D-1\)개의 filters를 사용해서 <strong>latent patch embedding</strong> \(h_p^c \in \mathbb{R}^{D-1}\)를 얻음 :
        <ul>
          <li>\(h_p^c=\left[\sum_{i=1}^{L_p} \mathbf{f}_d[i]^{\top} \mathbf{z}_{l_p: r_p}[i]\right]_{d=1}^{D-1}\).</li>
          <li>이건  encoded transformable patches:
            <ul>
              <li>variable-length sequences에 따라 flexibility를 가지고</li>
              <li>parameterization for varying time intervals을 하면서</li>
              <li>additional learnable filter parameters 없이 더 긴 시퀀스를 처리할 수 있음</li>
            </ul>
          </li>
          <li>마지막으로 \(h_p=\left[h_p^c \| m_p\right]\) 이렇게 patch에 masking을 덧붙여주는데,
            <ul>
              <li>\(m_p\)는 이 patch 안에 observations가 하나 이상 있다~를 indicator로 표현</li>
            </ul>
          </li>
          <li>최종적으로 \(\mathbf{h}_{1: P}=\left[h_p\right]_{p=1}^P \in \mathbb{R}^{P \times D}\)를 얻는다.</li>
          <li>이건 \(P\)개의 patch를 \(D-1\)차원으로 표현하고 마지막에는 masking으로 indicator를 붙인 것</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="42-intra--and-inter-time-series-modeling">4.2. Intra- and Inter-Time Series Modeling</h3>

<ul>
  <li>이제 이  transformable patching을 irregular time series를 intra- and inter-time series modeling하는지 알아보자</li>
</ul>

<h3 id="421-transformer-to-model-sequential-patches">4.2.1. TRANSFORMER TO MODEL SEQUENTIAL PATCHES</h3>

<ul>
  <li>위에서 구한 \(\mathbf{h}_{1: P}=\left[h_p\right]_{p=1}^P \in \mathbb{R}^{P \times D}\)를 Transformer에 넣는다.</li>
  <li>먼저 positional encoding을 하고
    <ul>
      <li>\(\mathbf{x}_{1: P}^{t f, n}=\mathbf{h}_{1: P}^n+\mathbf{P E}_{1: P}\).</li>
    </ul>
  </li>
  <li>Q, K, V를 만들어서 MHA를 통과한다.
    <ul>
      <li>\(\mathbf{q}_h^n=\mathbf{x}_{1: P}^{t f, n} \mathbf{W}_h^Q\) / \(\mathbf{k}_h^n=\mathbf{x}_{1: P}^{t f, n} \mathbf{W}_h^K\) / \(\mathbf{v}_h^n=\mathbf{x}_{1: P}^{t f, n} \mathbf{W}_h^V\) where \(\mathbf{W}_h^Q, \mathbf{W}_h^K, \mathbf{W}_h^V \in \mathbb{R}^{D \times(D / H)}\)</li>
      <li>\(\mathbf{h}_{1: P}^{t f, n}=\|_{h=1}^H \operatorname{Softmax}\left(\frac{\mathbf{q}_h^n \mathbf{k}_h^{n T}}{\sqrt{D / H}}\right) \mathbf{v}_h^n \in \mathbb{R}^{P \times D}\),</li>
    </ul>
  </li>
</ul>

<h3 id="422-time-varying-adaptive-graph-structure-learning">4.2.2. TIME-VARYING ADAPTIVE GRAPH STRUCTURE LEARNING</h3>

<ul>
  <li>한 변수를 예측하기 위해서 다른 변수의 정보는 매우 유용할 수가 있음</li>
  <li>하지만 IMTS에서는 misaligned at times으로 인해 correlation modeling이 어려움
    <ul>
      <li>그렇다고 Raindrop처럼 하기엔 e sequence length explosion problem이 발생</li>
    </ul>
  </li>
  <li>그래서 <strong>transformable patching</strong>으로 해결
    <ul>
      <li>patch를 observations의 개수가 아니라 시간 길이를 기준으로 끊다보니</li>
      <li>각 변수는 같은 숫자의 patches로 이루어지니까</li>
      <li>time-adaptive graph neural networks로 inter-time series correlation를 modeling할 수 있음</li>
    </ul>
  </li>
  <li>즉 IMTS의  dynamic correlations를 파악하기 위해서는
    <ul>
      <li>series of time-varying adaptive graphs를 학습하겠다는 것이고</li>
      <li>지금 문제는 variable embedding이 training에서는 update 가능하지만 inference에서는 static</li>
      <li>그러니 learnable \(\mathbf{E}_1^s, \mathbf{E}_2^s \in \mathbb{R}^{N \times D_g}\)를 사용해서</li>
      <li>우리가 지금까지 만들었던  time-varying patch embedding \(\mathbf{H}_p^{t f}=\left[\mathbf{h}_p^{t f, n}\right]_{n=1}^N \in \mathbb{R}^{N \times D}\)을
        <ul>
          <li>static variable embedding으로 만들면 됨</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>그 gated adding operation은 다음과 같음
    <ul>
      <li>\(\begin{gathered}
\mathbf{E}_{p, k}=\mathbf{E}_k^s+g_{p, k} * \mathbf{E}_{p, k}^d, \\
\mathbf{E}_{p, k}^d=\mathbf{H}_p^{t f} \mathbf{W}_k^d, \\
g_{p, k}=\operatorname{ReLU}\left(\tanh \left(\left[\mathbf{H}_p^{t f} \| \mathbf{E}_k^s\right] \mathbf{W}_k^g\right)\right) \\
k=\{1,2\}
\end{gathered}\), where
        <ul>
          <li>\(\mathbf{W}_k^d \in \mathbb{R}^{D \times D_g}, \mathbf{W}_k^g \in \mathbb{R}^{\left(D+D_g\right) \times 1}\) are learnable parameters</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>이제 time-varying adaptive graph structure를 다음과 같이 얻음 : \(\mathbf{A}_p=\operatorname{Softmax}\left(\operatorname{ReLU}\left(\mathbf{E}_{p, 1} \mathbf{E}_{p, 2}^T\right)\right)\)</li>
</ul>

<h3 id="423-gnns-to-model-inter-time-series-correlation">4.2.3. GNNS TO MODEL INTER-TIME SERIES CORRELATION</h3>

<ul>
  <li>다음으로 dynamic inter-time series correlation at a patch-level resolution을 얻음
    <ul>
      <li>\(\mathbf{H}_p=\operatorname{ReLU}\left(\sum_{m=0}^M\left(\mathbf{A}_p\right)^m \mathbf{H}_p^{t f} \mathbf{W}_m^{g n n}\right) \in \mathbb{R}^{N \times D}\).</li>
      <li>where $M$ is the number of layers for GNNs, and $\mathbf{W}_m^{g n n} \in$ $\mathbb{R}^{D \times D}$ are learnable parameters at $m$-th layer.</li>
    </ul>
  </li>
</ul>

<h3 id="43-imts-forecasti">4.3. IMTS Forecasti</h3>

<ul>
  <li>이제 final latent representation을 얻는다 :
    <ul>
      <li>\(\mathbf{H}=\text { Flatten }\left(\left[\mathbf{H}_p\right]_{p=1}^P\right) \mathbf{W}^f \in \mathbb{R}^{N \times D_o}\), where  \(\mathbf{W}^f \in \mathbb{R}^{P D \times D_o}\) are learnable parameters.</li>
      <li>각 변수마다 이 representation을 얻는다</li>
    </ul>
  </li>
  <li>n-번째 변수의 final latent representation \(\mathbf{H}^n \in \mathbf{H}\)과, forecasting query \(\left\{\left[q_j^n\right]_{j=1}^{Q_n}\right\}_{n=1}^N\)를 가지고 MLP에 넣는다</li>
  <li>
    <p>\(\hat{x}_j^n=\operatorname{MLP}\left(\left[\mathbf{H}^n \| \phi\left(q_j^n\right)\right]\right)\).</p>
  </li>
  <li>모델은 각 변수의 예측의 MSE를 줄이는 방향으로 학습
    <ul>
      <li>\(\mathcal{L}=\frac{1}{N} \sum_{n=1}^N \frac{1}{Q_n} \sum_{j=1}^{Q_n}\left(\hat{x}_j^n-x_j^n\right)^2\).</li>
    </ul>
  </li>
</ul>

<h3 id="44-analysis-on-scalabil">4.4. Analysis on Scalabil</h3>

<ul>
  <li>The average sequence length : \(L_{t p}=L_{a v g} \leq L_{\max } \leq L_{c p r} \leq N \times L_{a v g}\), where
    <ul>
      <li>\(L_{\text {avg }}=\frac{1}{N} \sum_{n=1}^N L_n\).</li>
    </ul>
  </li>
</ul>

<h2 id="5-experiments">5. Experiments</h2>

<h3 id="51-experimental-setup">5.1. Experimental Setup</h3>

<ul>
  <li>Dataset :
    <ul>
      <li>PhysioNet, MIMIC, Human Activity, and USHCN</li>
      <li>training, validation, and test sets adhering to ratios of 60%, 20%, and 20%</li>
    </ul>
  </li>
  <li>Evaluation Metric :
    <ul>
      <li>\(\begin{aligned}
\text { MSE }&amp;=\frac{1}{N} \sum_{n=1}^N \frac{1}{Q_n} \sum_{j=1}^{Q_n}\left(\hat{x}_j^n-x_j^n\right)^2, \\\text { MAE }&amp;=
 \frac{1}{N} \sum_{n=1}^N \frac{1}{Q_n} \sum_{j=1}^{Q_n}\left|\hat{x}_j^n-x_j^n\right| .
\end{aligned}\).</li>
    </ul>
  </li>
</ul>

<h4 id="52-main-results">5.2. Main Results</h4>

<p><img src="/assets/img/timeseries/TPatchGNN/table1.png" alt="그림1" /></p>

<h3 id="53-ablation-study">5.3. Ablation Study</h3>

<p><img src="/assets/img/timeseries/TPatchGNN/table2.png" alt="그림1" /></p>

<h3 id="54-scalability-and-efficiency-analysis">5.4. Scalability and Efficiency Analysis</h3>

<p><img src="/assets/img/timeseries/TPatchGNN/table3.png" alt="그림1" /></p>

<h3 id="55-effect-of-patch-size">5.5. Effect of Patch Size</h3>

<p><img src="/assets/img/timeseries/TPatchGNN/fig4.png" alt="그림1" /></p>

<h2 id="6-conclusion">6. Conclusion</h2>

<ul>
  <li>Transformable Patching Graph Neural Networks (T-PATCHGNN)
    <ul>
      <li>achieved the alignment between asynchronous IMTS
        <ul>
          <li>by transforming each univariate irregular time series into a series of transformable patches with varying observation counts but maintaining unified time horizon resolution.</li>
          <li>without a canonical pre-alignment representation process, preventing the aligned sequence length from explosively growing</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

  
</article>



  <hr class="dingbat related mb6" />






  
     


  <aside class="about related mt4 mb4" role="complementary">
    
    

<div class="author mt4">
  

  
    


<img
  
    src="https://via.placeholder.com/128x128"
    srcset="/assets/img/me/me.JPG 1x,/assets/img/me/me.JPG 2x"
    
  
  alt="GW Jeong"
  class="avatar"
  
  width="120"
  height="120"
  loading="lazy"
/>

  

  
  
  <h2  class="page-title hr-bottom">
    About
  </h2>

  <p>Bachelor’s degree in Applied Statistics. Yonsei Univ. (2018~2024) <br />
DataScienceLab 8th 학회장 (2022~2023) <br />
Master’s degree in Statitstics. Yonsei Univ. (2024~)</p>


  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/lpppj" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="mailto:wjdrjsdn39@yonsei.ac.kr" title="Email" class="no-mark-external">
      <span class="icon-mail"></span>
      <span class="sr-only">Email</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>

  </aside>


  

  
  

  
    


  

  
  

  
    

  


  
<footer class="content" role="contentinfo">
  <hr/>
  
    <p><small class="copyright">© Geonwoo Jeong.
</small></p>
  
  
    <p><small>Powered by <a class="external" href="https://hydejack.com/">Hydejack</a> v<span id="_version">9.1.6</span></small></p>
  <hr class="sr-only"/>
</footer>


</main>

  <hy-drawer
  id="_drawer"
  class=""
  side="left"
  threshold="10"
  noscroll
  
>
  <header id="_sidebar" class="sidebar" role="banner">
    




<div class="sidebar-bg sidebar-overlay" style="background-color:rgb(230, 217, 195);background-image:url(/assets/img/me/sidebar.jpg)"></div>

    <div class="sidebar-sticky">
  <div class="sidebar-about">
    
      <a class="no-hover" href="/" tabindex="-1">
        <img src="/assets/img/me/logo.jpg" class="avatar" alt="LpppJ" width="120" height="120" loading="lazy" />
      </a>
    
    <a class="sidebar-title" href="/"><h2 class="h1">LpppJ</h2></a>
    
    
      <p class="">
        DataScience and AI

      </p>
    
  </div>

  <nav class="sidebar-nav heading" role="navigation">
    <span class="sr-only">Navigation:</span>
<ul>
  
    
      
      <li>
        <a
          id="_drawer--opened"
          href="/timeseries/"
          class="sidebar-nav-item "
          
        >
          TimeSeries
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/pytorch/"
          class="sidebar-nav-item "
          
        >
          Pytorch
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/stat/"
          class="sidebar-nav-item "
          
        >
          Statistics
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/project/"
          class="sidebar-nav-item "
          
        >
          Project
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/presentation/"
          class="sidebar-nav-item "
          
        >
          Presentation
        </a>
      </li>
    
  
</ul>

  </nav>

  
  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/lpppj" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="mailto:wjdrjsdn39@yonsei.ac.kr" title="Email" class="no-mark-external">
      <span class="icon-mail"></span>
      <span class="sr-only">Email</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>
  </header>
</hy-drawer>
<hr class="sr-only" hidden />

</hy-push-state>


  <!--[if gt IE 10]><!---->
  <script nomodule>!function(){var t,n=document.createElement("script");!("noModule"in n)&&"onbeforeload"in n&&(t=!1,document.addEventListener("beforeload",function(e){if(e.target===n)t=!0;else if(!e.target.hasAttribute("nomodule")||!t)return;e.preventDefault()},!0),n.type="module",n.src=".",document.head.appendChild(n),n.remove())}();
</script>
  <script src="/assets/js/hydejack-9.1.6.js" type="module"></script>
  <script src="/assets/js/LEGACY-hydejack-9.1.6.js" nomodule defer></script>
  

  

<!--<![endif]-->
  <!-- <script>
  document.querySelector('hy-push-state').setAttribute('prefetch', '');

  document.querySelectorAll('.sidebar a[href^="/"]').forEach(function (el) { 
    el.addEventListener('click', function (e) {
      if (el.pathname === window.location.pathname) {
        e.preventDefault();
        e.stopPropagation();
        document.querySelector('hy-drawer').close();
      }
    });
  });
</script> -->

<!--
Code for integrating CloudFlare's email protection with Hydejack's single page app loading.
-->
<script>
  document.getElementById('_pushState').addEventListener('hy-push-state-after', function (e) {
    function e(e){
      (console.error?console.error:console.log).call(console,e)
    }

    function t(e){
      return l.innerHTML='<a href="'+e.replace(/"/g,"&quot;")+'"></a>',l.childNodes[0].getAttribute("href")
    }

    function r(e,t){
      var r=e.substr(t,2);return parseInt(r,16)
    }

    function n(e,n){
      for(var o="",c=r(e,n),a=n+2;a<e.length;a+=2){
        var l=r(e,a)^c;
        o+=String.fromCharCode(l)
      }
      return t(o)
    }

    var o="/cdn-cgi/l/email-protection#",
        c=".__cf_email__",
        a="data-cfemail",
        l=document.createElement("div");

    !function(){
      for(var t=document.getElementsByTagName("a"),r=0;r<t.length;r++)
        try{
          var c=t[r],a=c.href.indexOf(o);
          a>-1&&(c.href="mailto:"+n(c.href,a+o.length))
        }catch(t){
          e(t)
        }
    }(),
    function(){
      for(var t=document.querySelectorAll(c),r=0;r<t.length;r++)
        try{
          var o=t[r],l=n(o.getAttribute(a),0),i=document.createTextNode(l);
          o.parentNode.replaceChild(i,o)
        }catch(t){
          e(t)
        }
    }()
  });
</script>





<div hidden>
  
  <h2 class="sr-only">Templates (for web app):</h2>

  <template id="_animation-template">
  <div class="animation-main fixed-top">
    <nav id="breadcrumbs" class="screen-only"><ul>
  
  
</ul></nav>
    <div class="content">
      <div class="page"></div>
    </div>
  </div>
</template>

  <template id="_loading-template">
  <div class="loading nav-btn fr">
    <span class="sr-only">Loading…</span>
    <span class="icon-cog"></span>
  </div>
</template>

  <template id="_error-template">
  <div class="page">
    <h1 class="page-title">Error</h1>
    
    
    <p class="lead">
      Sorry, an error occurred while loading <a class="this-link" href=""></a>.

    </p>
  </div>
</template>

  <template id="_permalink-template">
  <a href="#" class="permalink">
    <span class="sr-only">Permalink</span>
    <span class="content-hash"></span>
  </a>
</template>

</div>


</body>
</html>
